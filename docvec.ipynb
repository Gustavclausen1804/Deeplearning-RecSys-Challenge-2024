{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.1\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Current GPU device: NVIDIA GeForce RTX 3070\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "#import optuna\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL,\n",
    "    DEFAULT_TOTAL_READ_TIME_COL,\n",
    "    DEFAULT_SENTIMENT_SCORE_COL,\n",
    ")\n",
    "\n",
    "from utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from utils._articles import convert_text2encoding_with_transformers\n",
    "from utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from utils._articles import create_article_id_to_value_mapping\n",
    "from utils._nlp import get_transformers_word_embeddings, generate_embeddings_with_transformers\n",
    "from utils._python import write_submission_file, rank_predictions_by_score\n",
    "from models_pytorch.model_config import hparams_nrms\n",
    "\n",
    "from models_pytorch.nrms import NRMSModel\n",
    "from models_pytorch.NRMSDocVecModel import NRMSDocVecModel\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from models_pytorch.dataloader import NRMSDataSet\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at behaviours and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebnerd_small\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"./ebnerd_small\")  # Base path for your data directory\n",
    "print(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>datetime[μs]</td><td>list[i8]</td></tr></thead><tbody><tr><td>210330</td><td>[9765907, 9766625, … 9768850]</td><td>[9775402, 9482380, … 9775361]</td><td>[9482380]</td><td>184906883</td><td>2023-05-22 04:59:12</td><td>[0, 1, … 0]</td></tr><tr><td>2149447</td><td>[9770333, 9769641, … 9769580]</td><td>[9756169, 9775964, … 9758882]</td><td>[9775964]</td><td>152982387</td><td>2023-05-22 13:49:26</td><td>[0, 1, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆ u32          ┆ datetime[μs] ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 210330  ┆ [9765907,    ┆ [9775402,    ┆ [9482380]    ┆ 184906883    ┆ 2023-05-22   ┆ [0, 1, … 0] │\n",
       "│         ┆ 9766625, …   ┆ 9482380, …   ┆              ┆              ┆ 04:59:12     ┆             │\n",
       "│         ┆ 9768850]     ┆ 9775361]     ┆              ┆              ┆              ┆             │\n",
       "│ 2149447 ┆ [9770333,    ┆ [9756169,    ┆ [9775964]    ┆ 152982387    ┆ 2023-05-22   ┆ [0, 1, … 0] │\n",
       "│         ┆ 9769641, …   ┆ 9775964, …   ┆              ┆              ┆ 13:49:26     ┆             │\n",
       "│         ┆ 9769580]     ┆ 9758882]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "]\n",
    "HISTORY_SIZE = 20 # TODO: History size. \n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.with_columns([\n",
    "    (\n",
    "        (pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)\n",
    "        .dt.epoch(time_unit='s') / 3600)\n",
    "        .cast(pl.Int64)\n",
    "    ).alias(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "])\n",
    "\n",
    "df_validation = df_validation.with_columns([\n",
    "    (\n",
    "        (pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)\n",
    "        .dt.epoch(time_unit='s') / 3600)\n",
    "        .cast(pl.Int64)\n",
    "    ).alias(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>i64</td><td>list[i8]</td></tr></thead><tbody><tr><td>210330</td><td>[9765907, 9766625, … 9768850]</td><td>[9775402, 9482380, … 9775361]</td><td>[9482380]</td><td>184906883</td><td>467980</td><td>[0, 1, … 0]</td></tr><tr><td>2149447</td><td>[9770333, 9769641, … 9769580]</td><td>[9756169, 9775964, … 9758882]</td><td>[9775964]</td><td>152982387</td><td>467989</td><td>[0, 1, … 0]</td></tr><tr><td>2395789</td><td>[9762288, 9770594, … 9769366]</td><td>[9775430, 9775402, … 9754160]</td><td>[9775430]</td><td>10762119</td><td>467979</td><td>[1, 0, … 0]</td></tr><tr><td>814814</td><td>[9769472, 9770483, … 9770867]</td><td>[9771576, 9771235, … 9771235]</td><td>[9771151]</td><td>328293522</td><td>467897</td><td>[0, 0, … 0]</td></tr><tr><td>283047</td><td>[9762986, 9764361, … 9770541]</td><td>[9773248, 9772601, … 9773137]</td><td>[9773137]</td><td>3155674</td><td>467933</td><td>[0, 0, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆ u32          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 210330  ┆ [9765907,    ┆ [9775402,    ┆ [9482380]    ┆ 184906883    ┆ 467980       ┆ [0, 1, … 0] │\n",
       "│         ┆ 9766625, …   ┆ 9482380, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9768850]     ┆ 9775361]     ┆              ┆              ┆              ┆             │\n",
       "│ 2149447 ┆ [9770333,    ┆ [9756169,    ┆ [9775964]    ┆ 152982387    ┆ 467989       ┆ [0, 1, … 0] │\n",
       "│         ┆ 9769641, …   ┆ 9775964, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9769580]     ┆ 9758882]     ┆              ┆              ┆              ┆             │\n",
       "│ 2395789 ┆ [9762288,    ┆ [9775430,    ┆ [9775430]    ┆ 10762119     ┆ 467979       ┆ [1, 0, … 0] │\n",
       "│         ┆ 9770594, …   ┆ 9775402, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9769366]     ┆ 9754160]     ┆              ┆              ┆              ┆             │\n",
       "│ 814814  ┆ [9769472,    ┆ [9771576,    ┆ [9771151]    ┆ 328293522    ┆ 467897       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9770483, …   ┆ 9771235, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9770867]     ┆ 9771235]     ┆              ┆              ┆              ┆             │\n",
       "│ 283047  ┆ [9762986,    ┆ [9773248,    ┆ [9773137]    ┆ 3155674      ┆ 467933       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9764361, …   ┆ 9772601, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9770541]     ┆ 9773137]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>u32</td><td>i64</td><td>list[i8]</td></tr></thead><tbody><tr><td>2339228</td><td>[9776870, 9776985, … 9780271]</td><td>[9786222, 9786312, … 9785596]</td><td>[9782709]</td><td>356274980</td><td>468156</td><td>[0, 0, … 0]</td></tr><tr><td>2470415</td><td>[9779541, 9779511, … 9779777]</td><td>[9782884, 9783800, … 9784804]</td><td>[9784804]</td><td>294225186</td><td>468125</td><td>[0, 0, … 1]</td></tr><tr><td>2107296</td><td>[9767426, 9767274, … 9769679]</td><td>[9787593, 9787564, … 9787784]</td><td>[9787863]</td><td>299982984</td><td>468177</td><td>[0, 0, … 0]</td></tr><tr><td>1786197</td><td>[9744403, 9760091, … 9777026]</td><td>[9779417, 9781013, … 9781158]</td><td>[9780874]</td><td>544848965</td><td>468063</td><td>[0, 0, … 0]</td></tr><tr><td>2452793</td><td>[9778448, 9778422, … 9779538]</td><td>[9780993, 9780909, … 9780974]</td><td>[9780860]</td><td>77501579</td><td>468062</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i32]    ┆ list[i32]    ┆ u32          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 2339228 ┆ [9776870,    ┆ [9786222,    ┆ [9782709]    ┆ 356274980    ┆ 468156       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9776985, …   ┆ 9786312, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9780271]     ┆ 9785596]     ┆              ┆              ┆              ┆             │\n",
       "│ 2470415 ┆ [9779541,    ┆ [9782884,    ┆ [9784804]    ┆ 294225186    ┆ 468125       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9779511, …   ┆ 9783800, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779777]     ┆ 9784804]     ┆              ┆              ┆              ┆             │\n",
       "│ 2107296 ┆ [9767426,    ┆ [9787593,    ┆ [9787863]    ┆ 299982984    ┆ 468177       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9767274, …   ┆ 9787564, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9769679]     ┆ 9787784]     ┆              ┆              ┆              ┆             │\n",
       "│ 1786197 ┆ [9744403,    ┆ [9779417,    ┆ [9780874]    ┆ 544848965    ┆ 468063       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9760091, …   ┆ 9781013, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9777026]     ┆ 9781158]     ┆              ┆              ┆              ┆             │\n",
       "│ 2452793 ┆ [9778448,    ┆ [9780993,    ┆ [9780860]    ┆ 77501579     ┆ 468062       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778422, …   ┆ 9780909, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779538]     ┆ 9780974]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of article_ids_inview in df_train: 5.0\n",
      "Average length of article_ids_inview in df_validation: 12.010668737737083\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_length(df, column):\n",
    "    total_length = sum(len(row) for row in df[column])\n",
    "    average_length = total_length / len(df)\n",
    "    return average_length\n",
    "\n",
    "# Calculate average length for df_train\n",
    "average_length_inview_train = calculate_average_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_train: {average_length_inview_train}\")\n",
    "\n",
    "# Calculate average length for df_validation\n",
    "average_length_inview_validation = calculate_average_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_validation: {average_length_inview_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest inview article length in df_train: 5\n",
      "Longest inview article length in df_validation: 89\n",
      "Longest history length in df_train: 20\n",
      "Longest history length in df_validation: 20\n"
     ]
    }
   ],
   "source": [
    "# Function to find the maximum length of arrays in a column\n",
    "def find_max_length(df, column):\n",
    "    max_length = 0\n",
    "    for row in df[column]:\n",
    "        max_length = max(max_length, len(row))\n",
    "    return max_length\n",
    "\n",
    "# Find the longest inview article length in df_train\n",
    "max_inview_length_train = find_max_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "# Find the longest inview article length in df_validation\n",
    "max_inview_length_validation = find_max_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "print(f\"Longest inview article length in df_train: {max_inview_length_train}\")\n",
    "print(f\"Longest inview article length in df_validation: {max_inview_length_validation}\")\n",
    "\n",
    "max_history_length_train = find_max_length(df_train, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "max_history_length_validation = find_max_length(df_validation, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "\n",
    "print(f\"Longest history length in df_train: {max_history_length_train}\")\n",
    "print(f\"Longest history length in df_validation: {max_history_length_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with exactly one clicked article in df_train: 23427\n",
      "Number of rows with exactly one clicked article in df_validation: 24322\n"
     ]
    }
   ],
   "source": [
    "# Function to filter rows with exactly one clicked article\n",
    "def filter_rows_with_one_clicked_article(df, clicked_articles_col):\n",
    "    # Manually filter rows where the array has exactly one element\n",
    "    filtered_rows = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        if len(row[clicked_articles_col]) == 1:\n",
    "            filtered_rows.append(row)\n",
    "    return pl.DataFrame(filtered_rows)\n",
    "\n",
    "\n",
    "# Filter rows in df_train and df_validation\n",
    "df_train = filter_rows_with_one_clicked_article(df_train, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "df_validation = filter_rows_with_one_clicked_article(df_validation, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of rows with exactly one clicked article in df_train: {df_train.shape[0]}\")\n",
    "print(f\"Number of rows with exactly one clicked article in df_validation: {df_validation.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>2339228</td><td>[9776870, 9776985, … 9780271]</td><td>[9786222, 9786312, … 9785596]</td><td>[9782709]</td><td>356274980</td><td>468156</td><td>[0, 0, … 0]</td></tr><tr><td>2470415</td><td>[9779541, 9779511, … 9779777]</td><td>[9782884, 9783800, … 9784804]</td><td>[9784804]</td><td>294225186</td><td>468125</td><td>[0, 0, … 1]</td></tr><tr><td>2107296</td><td>[9767426, 9767274, … 9769679]</td><td>[9787593, 9787564, … 9787784]</td><td>[9787863]</td><td>299982984</td><td>468177</td><td>[0, 0, … 0]</td></tr><tr><td>1786197</td><td>[9744403, 9760091, … 9777026]</td><td>[9779417, 9781013, … 9781158]</td><td>[9780874]</td><td>544848965</td><td>468063</td><td>[0, 0, … 0]</td></tr><tr><td>2452793</td><td>[9778448, 9778422, … 9779538]</td><td>[9780993, 9780909, … 9780974]</td><td>[9780860]</td><td>77501579</td><td>468062</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ i64     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i64]   │\n",
       "│         ┆ list[i64]    ┆ list[i64]    ┆ list[i64]    ┆ i64          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 2339228 ┆ [9776870,    ┆ [9786222,    ┆ [9782709]    ┆ 356274980    ┆ 468156       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9776985, …   ┆ 9786312, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9780271]     ┆ 9785596]     ┆              ┆              ┆              ┆             │\n",
       "│ 2470415 ┆ [9779541,    ┆ [9782884,    ┆ [9784804]    ┆ 294225186    ┆ 468125       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9779511, …   ┆ 9783800, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779777]     ┆ 9784804]     ┆              ┆              ┆              ┆             │\n",
       "│ 2107296 ┆ [9767426,    ┆ [9787593,    ┆ [9787863]    ┆ 299982984    ┆ 468177       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9767274, …   ┆ 9787564, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9769679]     ┆ 9787784]     ┆              ┆              ┆              ┆             │\n",
       "│ 1786197 ┆ [9744403,    ┆ [9779417,    ┆ [9780874]    ┆ 544848965    ┆ 468063       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9760091, …   ┆ 9781013, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9777026]     ┆ 9781158]     ┆              ┆              ┆              ┆             │\n",
       "│ 2452793 ┆ [9778448,    ┆ [9780993,    ┆ [9780860]    ┆ 77501579     ┆ 468062       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778422, …   ┆ 9780909, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779538]     ┆ 9780974]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in df_train: 8941\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users in df_train: {df_train['user_id'].n_unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>2007-03-27 10:22:08</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>2001-10-19 12:30:00</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>2003-01-09 06:00:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>2003-06-17 07:10:00</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>2003-07-13 19:50:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = df_articles.with_columns([\n",
    "    (\n",
    "        pl.col(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)                   # Step 3: Cast to Datetime\n",
    "        .dt.epoch(time_unit='s')            # Step 4: Convert to Epoch Seconds\n",
    "        / 3600                               # Step 5: Convert Seconds to Hours\n",
    "    ).cast(pl.Int64)                         # Step 6: Cast to Integer\n",
    "    .alias(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL)  # Step 7: Alias the Column\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>i64</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>321392</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>318952</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>318470</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>326312</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>324754</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>326386</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>278748</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>289470</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>293287</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>293923</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCVEC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document vector parquet file\n",
    "document_vector_path = Path(\"./Ekstra_Bladet_word2vec/document_vector.parquet\")\n",
    "df_document_vector = pl.read_parquet(document_vector_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "\n",
    "article_mapping = create_article_id_to_value_mapping(df=df_document_vector, value_col=\"document_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>document_vector</th></tr><tr><td>i32</td><td>list[f32]</td></tr></thead><tbody><tr><td>3000022</td><td>[0.065424, -0.047425, … 0.035706]</td></tr><tr><td>3000063</td><td>[0.028815, -0.000166, … 0.027167]</td></tr><tr><td>3000613</td><td>[0.037971, 0.033923, … 0.063961]</td></tr><tr><td>3000700</td><td>[0.046524, 0.002913, … 0.023423]</td></tr><tr><td>3000840</td><td>[0.014737, 0.024068, … 0.045991]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────┬─────────────────────────────────┐\n",
       "│ article_id ┆ document_vector                 │\n",
       "│ ---        ┆ ---                             │\n",
       "│ i32        ┆ list[f32]                       │\n",
       "╞════════════╪═════════════════════════════════╡\n",
       "│ 3000022    ┆ [0.065424, -0.047425, … 0.0357… │\n",
       "│ 3000063    ┆ [0.028815, -0.000166, … 0.0271… │\n",
       "│ 3000613    ┆ [0.037971, 0.033923, … 0.06396… │\n",
       "│ 3000700    ┆ [0.046524, 0.002913, … 0.02342… │\n",
       "│ 3000840    ┆ [0.014737, 0.024068, … 0.04599… │\n",
       "└────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_vector.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding tokenized article title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uses existing function for both categories and topics\n",
    "* Handles array of topics by joining with separator\n",
    "* Limits to first 3 topics to avoid sequence length issues\n",
    "* Maintains consistent encoding approach across feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "MAX_TITLE_LENGTH = 30\n",
    "from transformers import ConvBertTokenizer, ConvBertModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "\n",
    "transformer_tokenizer = ConvBertTokenizer.from_pretrained(\"sarnikowski/convbert-small-da-cased\")\n",
    "transformer_model = ConvBertModel.from_pretrained(\"sarnikowski/convbert-small-da-cased\")\n",
    "\n",
    "\n",
    "# For categories (keep as is - works with single strings)\n",
    "df_articles, category_encoded_col_name = convert_text2encoding_with_transformers(\n",
    "    df_articles, \n",
    "    transformer_tokenizer,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# For topics - first join the array into single string\n",
    "df_articles = df_articles.with_columns(\n",
    "    pl.col(DEFAULT_TOPICS_COL).map_elements(lambda x: \" | \".join(x[:3])).alias(f\"{DEFAULT_TOPICS_COL}_joined\")\n",
    ")\n",
    "\n",
    "# Then encode the joined topics\n",
    "df_articles, topics_encoded_col_name = convert_text2encoding_with_transformers(\n",
    "    df_articles,\n",
    "    transformer_tokenizer, \n",
    "    f\"{DEFAULT_TOPICS_COL}_joined\",\n",
    "    max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# Create mappings with encoded columns\n",
    "category_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=category_encoded_col_name\n",
    ")\n",
    "\n",
    "topic_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=topics_encoded_col_name\n",
    ")\n",
    "# Create mappings for numerical features\n",
    "pageviews_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_TOTAL_PAGEVIEWS_COL\n",
    ")\n",
    "\n",
    "read_time_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_TOTAL_READ_TIME_COL\n",
    ")\n",
    "\n",
    "sentiment_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_SENTIMENT_SCORE_COL\n",
    ")\n",
    "\n",
    "timestamp_mapping = create_article_id_to_value_mapping(\n",
    "    df_articles,\n",
    "    value_col=DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(23427, 7)\n",
      "Data preprocessing completed in 8.69 seconds.\n",
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(24322, 7)\n",
      "Data preprocessing completed in 10.00 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NRMSDataSet(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    category_mapping=category_mapping,\n",
    "    topic_mapping=topic_mapping,\n",
    "    pageviews_mapping=pageviews_mapping,\n",
    "    read_time_mapping=read_time_mapping,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    timestamp_mapping=timestamp_mapping\n",
    "\n",
    ")\n",
    "val_dataset = NRMSDataSet(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    category_mapping=category_mapping,\n",
    "    topic_mapping=topic_mapping,\n",
    "    pageviews_mapping=pageviews_mapping,\n",
    "    read_time_mapping=read_time_mapping,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    timestamp_mapping=timestamp_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 184906883\n",
      "Sample 1:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 152982387\n",
      "Sample 2:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 10762119\n",
      "Sample 3:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 328293522\n",
      "Sample 4:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 3155674\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    sample = train_dataset[idx]\n",
    "    print(f\"Sample {idx}:\")\n",
    "    print(f\"his_input_title shape: {sample[0][0].shape}\")\n",
    "    print(f\"pred_input_title shape: {sample[0][1].shape} {sample[0][1].sum()}\")\n",
    "    print(f\"pred_input_category shape: {sample[0][2].shape} {sample[0][2].sum()}\")\n",
    "    print(f\"pred_input_topic shape: {sample[0][3].shape} {sample[0][3].sum()}\")\n",
    "    print(f\"pred_input_pageviews shape: {sample[0][4].shape} {sample[0][4].sum()}\")\n",
    "    print(f\"Targets shape: {sample[1].shape} , {sample[1].dtype} {sample[1].sum()}\")\n",
    "    print(f\"impression id: {sample[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def collate_fn_with_global_padding(batch, max_len_pred, apply_padding_to_targets=True):\n",
    "    try:\n",
    "        # Unpack all features including timestamps from dataset samples\n",
    "        his_input_titles = [item[0][0] for item in batch]\n",
    "        his_category_emb = [item[0][1] for item in batch]\n",
    "        his_topic_emb = [item[0][2] for item in batch]\n",
    "        his_sentiment_scores = [item[0][3] for item in batch]\n",
    "        his_read_times = [item[0][4] for item in batch]\n",
    "        his_pageviews = [item[0][5] for item in batch]\n",
    "        his_timestamps = [item[0][6] for item in batch]\n",
    "\n",
    "        pred_input_titles = [item[0][7] for item in batch]\n",
    "        pred_category_emb = [item[0][8] for item in batch]\n",
    "        pred_topic_emb = [item[0][9] for item in batch]\n",
    "        pred_sentiment_scores = [item[0][10] for item in batch]\n",
    "        pred_read_times = [item[0][11] for item in batch]\n",
    "        pred_pageviews = [item[0][12] for item in batch]\n",
    "        pred_timestamps = [item[0][13] for item in batch]\n",
    "        impression_timestamps = [item[0][14] for item in batch]\n",
    "\n",
    "        batch_ys = [item[1] for item in batch]\n",
    "        impression_id = torch.tensor([item[2] for item in batch], dtype=torch.int64)\n",
    "\n",
    "        # Pad user history features\n",
    "        his_input_titles_padded = pad_sequence(his_input_titles, batch_first=True, padding_value=0)\n",
    "        his_category_emb_padded = pad_sequence(his_category_emb, batch_first=True, padding_value=0)\n",
    "        his_topic_emb_padded = pad_sequence(his_topic_emb, batch_first=True, padding_value=0)\n",
    "        his_sentiment_padded = pad_sequence(his_sentiment_scores, batch_first=True, padding_value=0)\n",
    "        his_read_times_padded = pad_sequence(his_read_times, batch_first=True, padding_value=0)\n",
    "        his_pageviews_padded = pad_sequence(his_pageviews, batch_first=True, padding_value=0)\n",
    "        his_timestamps_padded = pad_sequence(his_timestamps, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Pad candidate features\n",
    "        pred_input_titles_padded = pad_sequence(pred_input_titles, batch_first=True, padding_value=0)\n",
    "        pred_category_emb_padded = pad_sequence(pred_category_emb, batch_first=True, padding_value=0)\n",
    "        pred_topic_emb_padded = pad_sequence(pred_topic_emb, batch_first=True, padding_value=0)\n",
    "        pred_sentiment_padded = pad_sequence(pred_sentiment_scores, batch_first=True, padding_value=0)\n",
    "        pred_read_times_padded = pad_sequence(pred_read_times, batch_first=True, padding_value=0)\n",
    "        pred_pageviews_padded = pad_sequence(pred_pageviews, batch_first=True, padding_value=0)\n",
    "        pred_timestamps_padded = pad_sequence(pred_timestamps, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # Convert impression timestamps to tensor\n",
    "        impression_timestamps = torch.stack(impression_timestamps)\n",
    "\n",
    "        # Handle max_len_pred for candidate sequences\n",
    "        if pred_input_titles_padded.size(1) < max_len_pred:\n",
    "            pad_size = max_len_pred - pred_input_titles_padded.size(1)\n",
    "            \n",
    "            pred_input_titles_padded = torch.nn.functional.pad(pred_input_titles_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_category_emb_padded = torch.nn.functional.pad(pred_category_emb_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_topic_emb_padded = torch.nn.functional.pad(pred_topic_emb_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_sentiment_padded = torch.nn.functional.pad(pred_sentiment_padded, (0, pad_size), value=0)\n",
    "            pred_read_times_padded = torch.nn.functional.pad(pred_read_times_padded, (0, pad_size), value=0)\n",
    "            pred_pageviews_padded = torch.nn.functional.pad(pred_pageviews_padded, (0, pad_size), value=0)\n",
    "            pred_timestamps_padded = torch.nn.functional.pad(pred_timestamps_padded, (0, pad_size), value=0)\n",
    "\n",
    "        elif pred_input_titles_padded.size(1) > max_len_pred:\n",
    "            pred_input_titles_padded = pred_input_titles_padded[:, :max_len_pred, :]\n",
    "            pred_category_emb_padded = pred_category_emb_padded[:, :max_len_pred, :]\n",
    "            pred_topic_emb_padded = pred_topic_emb_padded[:, :max_len_pred, :]\n",
    "            pred_sentiment_padded = pred_sentiment_padded[:, :max_len_pred]\n",
    "            pred_read_times_padded = pred_read_times_padded[:, :max_len_pred]\n",
    "            pred_pageviews_padded = pred_pageviews_padded[:, :max_len_pred]\n",
    "            pred_timestamps_padded = pred_timestamps_padded[:, :max_len_pred]\n",
    "\n",
    "        # Handle targets padding\n",
    "        if apply_padding_to_targets:\n",
    "            batch_ys_padded = pad_sequence(batch_ys, batch_first=True, padding_value=-1)\n",
    "            if batch_ys_padded.size(1) < max_len_pred:\n",
    "                pad_size = max_len_pred - batch_ys_padded.size(1)\n",
    "                batch_ys_padded = torch.nn.functional.pad(batch_ys_padded, (0, pad_size), value=-1)\n",
    "            elif batch_ys_padded.size(1) > max_len_pred:\n",
    "                batch_ys_padded = batch_ys_padded[:, :max_len_pred]\n",
    "\n",
    "            return (\n",
    "                his_input_titles_padded,\n",
    "                his_category_emb_padded,\n",
    "                his_topic_emb_padded, \n",
    "                his_sentiment_padded,\n",
    "                his_read_times_padded,\n",
    "                his_pageviews_padded,\n",
    "                his_timestamps_padded,\n",
    "                pred_input_titles_padded,\n",
    "                pred_category_emb_padded,\n",
    "                pred_topic_emb_padded,\n",
    "                pred_sentiment_padded,\n",
    "                pred_read_times_padded,\n",
    "                pred_pageviews_padded,\n",
    "                pred_timestamps_padded,\n",
    "                impression_timestamps\n",
    "            ), batch_ys_padded, impression_id\n",
    "        else:\n",
    "            return (\n",
    "                his_input_titles_padded,\n",
    "                his_category_emb_padded,\n",
    "                his_topic_emb_padded,\n",
    "                his_sentiment_padded,\n",
    "                his_read_times_padded,\n",
    "                his_pageviews_padded,\n",
    "                his_timestamps_padded,\n",
    "                pred_input_titles_padded,\n",
    "                pred_category_emb_padded,\n",
    "                pred_topic_emb_padded,\n",
    "                pred_sentiment_padded,\n",
    "                pred_read_times_padded,\n",
    "                pred_pageviews_padded,\n",
    "                pred_timestamps_padded,\n",
    "                impression_timestamps\n",
    "            ), batch_ys, impression_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the dataset with DataLoader\n",
    "train_dataloader_temp = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,    # Set your desired batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_train)\n",
    ")\n",
    "\n",
    "val_dataloader_temp = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,    # Set your desired batch size\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History features shapes:\n",
      "his_input_titles: torch.Size([64, 20, 300])\n",
      "his_category_emb: torch.Size([64, 20, 128])\n",
      "his_topic_emb: torch.Size([64, 20, 128])\n",
      "his_sentiment: torch.Size([64, 20])\n",
      "his_read_times: torch.Size([64, 20])\n",
      "his_pageviews: torch.Size([64, 20])\n",
      "his_timestamps: torch.Size([64, 20])\n",
      "\n",
      "Candidate features shapes:\n",
      "pred_input_titles: torch.Size([64, 89, 300])\n",
      "pred_category_emb: torch.Size([64, 89, 128])\n",
      "pred_topic_emb: torch.Size([64, 89, 128])\n",
      "pred_sentiment: torch.Size([64, 89])\n",
      "pred_read_times: torch.Size([64, 89])\n",
      "pred_pageviews: torch.Size([64, 89])\n",
      "pred_timestamps: torch.Size([64, 89])\n",
      "\n",
      "Other tensors:\n",
      "impression_timestamps: torch.Size([64])\n",
      "batch_ys: torch.Size([64, 89])\n",
      "impression_id: torch.Size([64])\n",
      "\n",
      "Batch loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataloader_temp:\n",
    "    (\n",
    "        his_input_titles_padded, \n",
    "        his_category_emb_padded,\n",
    "        his_topic_emb_padded,\n",
    "        his_sentiment_padded,\n",
    "        his_read_times_padded,\n",
    "        his_pageviews_padded,\n",
    "        his_timestamps_padded,\n",
    "        pred_input_titles_padded,\n",
    "        pred_category_emb_padded,\n",
    "        pred_topic_emb_padded,\n",
    "        pred_sentiment_padded,\n",
    "        pred_read_times_padded,\n",
    "        pred_pageviews_padded,\n",
    "        pred_timestamps_padded,\n",
    "        impression_timestamps\n",
    "    ), batch_ys_padded, impression_id = batch\n",
    "\n",
    "    # Original tensor shapes\n",
    "    print(\"History features shapes:\")\n",
    "    print(f\"his_input_titles: {his_input_titles_padded.shape}\")\n",
    "    print(f\"his_category_emb: {his_category_emb_padded.shape}\")\n",
    "    print(f\"his_topic_emb: {his_topic_emb_padded.shape}\")\n",
    "    print(f\"his_sentiment: {his_sentiment_padded.shape}\")\n",
    "    print(f\"his_read_times: {his_read_times_padded.shape}\")\n",
    "    print(f\"his_pageviews: {his_pageviews_padded.shape}\")\n",
    "    print(f\"his_timestamps: {his_timestamps_padded.shape}\")\n",
    "\n",
    "    print(\"\\nCandidate features shapes:\")\n",
    "    print(f\"pred_input_titles: {pred_input_titles_padded.shape}\")\n",
    "    print(f\"pred_category_emb: {pred_category_emb_padded.shape}\")\n",
    "    print(f\"pred_topic_emb: {pred_topic_emb_padded.shape}\")\n",
    "    print(f\"pred_sentiment: {pred_sentiment_padded.shape}\")\n",
    "    print(f\"pred_read_times: {pred_read_times_padded.shape}\")\n",
    "    print(f\"pred_pageviews: {pred_pageviews_padded.shape}\")\n",
    "    print(f\"pred_timestamps: {pred_timestamps_padded.shape}\")\n",
    "    \n",
    "    print(\"\\nOther tensors:\")\n",
    "    print(f\"impression_timestamps: {impression_timestamps.shape}\")\n",
    "    print(f\"batch_ys: {batch_ys_padded.shape}\")\n",
    "    print(f\"impression_id: {impression_id.shape}\")\n",
    "\n",
    "    print(\"\\nBatch loaded successfully!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the shapes.\n",
    "\n",
    "1. `his_input_titles_padded: [128, 20, 300]`\n",
    "   - 128: batch size\n",
    "   - 20: max history length (user's reading history)\n",
    "   - 300: title embedding dimension from ConvBERT\n",
    "\n",
    "2. `pred_input_titles_padded: [128, 90, 300]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles to predict\n",
    "   - 300: title embedding dimension from ConvBERT\n",
    "\n",
    "3. `pred_category_emb_padded: [128, 90, 128]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - 128: category embedding dimension from ConvBERT\n",
    "\n",
    "4. `pred_topic_emb_padded: [128, 90, 128]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - 128: topic embedding dimension from ConvBERT\n",
    "\n",
    "5. `pred_sentiment_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single sentiment score per article\n",
    "\n",
    "6. `pred_read_times_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single read time value per article\n",
    "\n",
    "7. `pred_pageviews_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single pageview count per article\n",
    "\n",
    "8. `batch_ys_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Binary labels (1 for clicked, 0 for not clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'models_pytorch.model_config', '__annotations__': {'title_size': <class 'int'>, 'embedding_dim': <class 'int'>, 'word_emb_dim': <class 'int'>, 'vocab_size': <class 'int'>, 'head_num': <class 'int'>, 'head_dim': <class 'int'>, 'attention_hidden_dim': <class 'int'>, 'optimizer': <class 'str'>, 'loss': <class 'str'>, 'dropout': <class 'float'>, 'learning_rate': <class 'float'>, 'weight_decay': <class 'float'>, 'units_per_layer': list[int], 'use_category': <class 'bool'>, 'use_topic': <class 'bool'>, 'use_numeric': <class 'bool'>, 'use_session_discount': <class 'bool'>, 'use_publication_discount': <class 'bool'>, 'doc_out_dim': <class 'int'>, 'cat_out_dim': <class 'int'>, 'top_out_dim': <class 'int'>, 'numeric_proj_dim': <class 'int'>}, 'title_size': 300, 'embedding_dim': 32, 'word_emb_dim': 8, 'vocab_size': 10000, 'head_num': 16, 'head_dim': 128, 'attention_hidden_dim': 128, 'hidden_dim': 4, 'optimizer': 'adam', 'loss': 'cross_entropy_loss', 'dropout': 0.3, 'learning_rate': 0.0001, 'weight_decay': 0.001, 'news_output_dim': 128, 'units_per_layer': [512, 256], 'use_category': True, 'use_topic': True, 'use_numeric': True, 'use_session_discount': True, 'use_publication_discount': True, 'doc_out_dim': 128, 'cat_out_dim': 128, 'top_out_dim': 128, 'numeric_proj_dim': 16, '__dict__': <attribute '__dict__' of 'hparams_nrms' objects>, '__weakref__': <attribute '__weakref__' of 'hparams_nrms' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# see the model parameters: \n",
    "hparams_nrms.attention_hidden_dim = 128\n",
    "hparams_nrms.title_size = 300\n",
    "hparams_nrms.head_num = 16\n",
    "hparams_nrms.head_dim = 128\n",
    "hparams_nrms.units_per_layer = [512,256]\n",
    "hparams_nrms.news_output_dim = 128\n",
    "hparams_nrms.dropout = 0.3\n",
    "hparams_nrms.learning_rate = 1e-4\n",
    "hparams_nrms.use_category = True\n",
    "hparams_nrms.use_topic = True\n",
    "hparams_nrms.use_numeric = True\n",
    "hparams_nrms.use_publication_discount = True\n",
    "hparams_nrms.use_session_discount = True\n",
    "print(hparams_nrms.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "  Value:  3.8567059058842696\n",
    "  Params: \n",
    "    head_num: 16\n",
    "    shared_dim: 99\n",
    "    dropout: 0.17498541169326048\n",
    "    learning_rate: 1.0454050068420554e-05\n",
    "    weight_decay: 0.006587407554797856\n",
    "    unit_layer_1: 421\n",
    "    unit_layer_2: 386\n",
    "    use_category: False\n",
    "    use_topic: False\n",
    "    use_numeric: True\n",
    "    use_publication_discount: False\n",
    "    use_session_discount: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters with best trial results\n",
    "\n",
    "# Keep original parameters\n",
    "hparams_nrms.title_size = 300\n",
    "\n",
    "# Update with optimized parameters\n",
    "hparams_nrms.head_num = 4\n",
    "shared_dim = 140  # Rounded up 137 to nearest multiple of head_num\n",
    "hparams_nrms.head_dim = shared_dim\n",
    "hparams_nrms.attention_hidden_dim = shared_dim\n",
    "hparams_nrms.news_output_dim = shared_dim\n",
    "\n",
    "# Update layers\n",
    "hparams_nrms.units_per_layer = [257, 475]  # From optimization\n",
    "\n",
    "# Update learning parameters\n",
    "hparams_nrms.dropout = 0.208\n",
    "hparams_nrms.learning_rate = 8.486e-4\n",
    "hparams_nrms.weight_decay = 1.697e-3\n",
    "\n",
    "# Update feature flags based on optimization\n",
    "hparams_nrms.use_category = True\n",
    "hparams_nrms.use_topic = False\n",
    "hparams_nrms.use_numeric = False\n",
    "hparams_nrms.use_publication_discount = False\n",
    "hparams_nrms.use_session_discount = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters with best trial results\n",
    "\n",
    "# Keep original parameters\n",
    "hparams_nrms.title_size = 300\n",
    "\n",
    "# Update with optimized parameters\n",
    "hparams_nrms.head_num = 16\n",
    "shared_dim = 96  # Rounded up 137 to nearest multiple of head_num\n",
    "hparams_nrms.head_dim = shared_dim\n",
    "hparams_nrms.attention_hidden_dim = shared_dim\n",
    "hparams_nrms.news_output_dim = shared_dim\n",
    "\n",
    "# Update layers\n",
    "hparams_nrms.units_per_layer = [421, 386]  # From optimization\n",
    "\n",
    "# Update learning parameters\n",
    "hparams_nrms.dropout = 0.1749\n",
    "hparams_nrms.learning_rate = 1.0454050068420554e-05\n",
    "hparams_nrms.weight_decay = 0.006587407554797856\n",
    "\n",
    "# Update feature flags based on optimization\n",
    "hparams_nrms.use_category = False\n",
    "hparams_nrms.use_topic = False\n",
    "hparams_nrms.use_numeric = False\n",
    "hparams_nrms.use_publication_discount = True\n",
    "hparams_nrms.use_session_discount = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\models_pytorch\\NRMSDocVecModel.py:300: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define paths\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = os.path.join(\"downloads\", \"runs\", MODEL_NAME)\n",
    "MODEL_WEIGHTS = os.path.join(\"downloads\", \"data\", \"state_dict\", MODEL_NAME, \"weights.pth\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_WEIGHTS), exist_ok=True)\n",
    "\n",
    "# Define ModelCheckpoint class\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Saves the model after every epoch if it has the best performance so far.\"\"\"\n",
    "    def __init__(self, filepath, verbose=False, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath (str): Path to save the model checkpoint.\n",
    "            verbose (bool): If True, prints a message when the model is saved.\n",
    "            save_best_only (bool): If True, saves only when the model is better than before.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_loss = None\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.filepath)\n",
    "        if self.verbose:\n",
    "            print(f\"Model saved to {self.filepath}\")\n",
    "\n",
    "# Define EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve by a given percentage over a patience period.\"\"\"\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after last time validation loss improved by min_delta.\n",
    "            min_delta (float): Minimum percentage improvement required to reset patience.\n",
    "            verbose (bool): If True, prints a message when early stopping is triggered.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta  # Minimum percentage improvement\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            # Initialize best_loss with the first validation loss\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss < self.best_loss * (1 - self.min_delta):\n",
    "            # Significant improvement found\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved by at least {self.min_delta*100:.1f}%\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No significant improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "# Initialize callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_WEIGHTS, verbose=True, save_best_only=True)\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "\n",
    "# Initialize your model\n",
    "# Ensure that NRMSModel is a PyTorch nn.Module\n",
    "\n",
    "# CUDA checks\n",
    "#print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "#print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "#print(f\"Device Name: {torch.cuda.get_device_name()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "# model = NRMSModel(\n",
    "#     hparams=hparams_nrms.__dict__,\n",
    "#     word2vec_embedding=word2vec_embedding,\n",
    "#     vocab_size=30000,\n",
    "#     word_emb_dim=8,\n",
    "#     device=device,\n",
    "#     feed_forward_layers_after_3rd_layer=False,\n",
    "# )\n",
    "\n",
    "model = NRMSDocVecModel(hparams=hparams_nrms.__dict__,\n",
    "                        device=device)\n",
    "\n",
    "# model = NRMSModel(hparams=hparams_nrms.__dict__,\n",
    "#                   word2vec_embedding=word2vec_embedding,\n",
    "#                         device=device)\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSDocVecModel(\n",
      "  (newsencoder): NewsEncoderDocVec(\n",
      "    (doc_encoder): DocEncoder(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Dropout(p=0.1749, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (feature_fusion): FeatureFusion(\n",
      "      (linears): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "      )\n",
      "      (gates): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "      )\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (time_discount): TimeDiscount(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (userencoder): UserEncoderDocVec(\n",
      "    (titleencoder): NewsEncoderDocVec(\n",
      "      (doc_encoder): DocEncoder(\n",
      "        (layer): Sequential(\n",
      "          (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Dropout(p=0.1749, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (feature_fusion): FeatureFusion(\n",
      "        (linears): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "        )\n",
      "        (gates): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "        )\n",
      "        (activation): Sigmoid()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (time_discount): TimeDiscount(\n",
      "        (layer): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (multihead_attention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (attention_layer): AttLayer2(\n",
      "      (V_w): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (q_w): Linear(in_features=96, out_features=1, bias=False)\n",
      "    )\n",
      "    (user_projection): Linear(in_features=96, out_features=96, bias=True)\n",
      "    (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (time_discount): TimeDiscount(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer: newsencoder.doc_encoder.layer.0.weight | Size: torch.Size([128, 300])\n",
      "Layer: newsencoder.doc_encoder.layer.0.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.doc_encoder.layer.2.weight | Size: torch.Size([128])\n",
      "Layer: newsencoder.doc_encoder.layer.2.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.feature_fusion.linears.0.weight | Size: torch.Size([96, 128])\n",
      "Layer: newsencoder.feature_fusion.linears.0.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.feature_fusion.gates.0.weight | Size: torch.Size([96, 128])\n",
      "Layer: newsencoder.feature_fusion.gates.0.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.layer_norm.weight | Size: torch.Size([96])\n",
      "Layer: newsencoder.layer_norm.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.time_discount.layer.0.weight | Size: torch.Size([1, 1])\n",
      "Layer: newsencoder.time_discount.layer.0.bias | Size: torch.Size([1])\n",
      "Layer: userencoder.self_attention.multihead_attention.in_proj_weight | Size: torch.Size([288, 96])\n",
      "Layer: userencoder.self_attention.multihead_attention.in_proj_bias | Size: torch.Size([288])\n",
      "Layer: userencoder.self_attention.multihead_attention.out_proj.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.self_attention.multihead_attention.out_proj.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.attention_layer.V_w.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.attention_layer.V_w.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.attention_layer.q_w.weight | Size: torch.Size([1, 96])\n",
      "Layer: userencoder.user_projection.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.user_projection.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.layer_norm.weight | Size: torch.Size([96])\n",
      "Layer: userencoder.layer_norm.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.time_discount.layer.0.weight | Size: torch.Size([1, 1])\n",
      "Layer: userencoder.time_discount.layer.0.bias | Size: torch.Size([1])\n",
      "\n",
      "Total parameters: 119,908\n"
     ]
    }
   ],
   "source": [
    "# 1. Print model architecture\n",
    "print(model)\n",
    "\n",
    "# 2. Print specific layer sizes\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")\n",
    "\n",
    "# 3. Get total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "\n",
    "# 4. Print layer by layer with shapes\n",
    "def print_model_structure(model):\n",
    "    print(\"\\nDetailed Model Structure:\")\n",
    "    for name, module in model.named_children():\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Type: {type(module).__name__}\")\n",
    "        if hasattr(module, 'weight'):\n",
    "            print(f\"Shape: {module.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Added gradient clipping to avoid exploiding gradients. The paramter MAX_GRAD_NORM is set to 5.0 as this is a common value used in transformers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperoptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# NUM_EPOCHS = 8\n",
    "# WEIGHT_DECAY = 1e-3\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define fixed valid head numbers\n",
    "#     possible_head_nums = [2, 4, 8, 16, 32]\n",
    "    \n",
    "#     # First suggest head_num from fixed choices\n",
    "#     head_num = trial.suggest_categorical('head_num', possible_head_nums)\n",
    "    \n",
    "#     # Suggest shared_dim that's divisible by head_num\n",
    "#     min_dim = max(64, head_num)  # Ensure minimum dimension works with head_num\n",
    "#     max_dim = 256\n",
    "#     shared_dim = trial.suggest_int('shared_dim', min_dim, max_dim)\n",
    "    \n",
    "#     # Round shared_dim to nearest multiple of head_num\n",
    "#     shared_dim = (shared_dim // head_num) * head_num\n",
    "    \n",
    "#     # Skip if dimensions don't work\n",
    "#     if shared_dim < head_num:\n",
    "#         raise optuna.TrialPruned()\n",
    "    \n",
    "#     hparams = {\n",
    "#         'title_size': 300,\n",
    "#         'head_num': head_num,\n",
    "#         'head_dim': shared_dim,\n",
    "#         'attention_hidden_dim':shared_dim,\n",
    "#         'news_output_dim': shared_dim,\n",
    "#         'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n",
    "#         'weight_decay': trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True),\n",
    "#         'units_per_layer': [\n",
    "#             trial.suggest_int('unit_layer_1', 256, 512),\n",
    "#             trial.suggest_int('unit_layer_2', 256, 512),\n",
    "#         ],\n",
    "#         'use_category': trial.suggest_categorical('use_category', [True, False]),\n",
    "#         'use_topic': trial.suggest_categorical('use_topic', [True, False]),\n",
    "#         'use_numeric': trial.suggest_categorical('use_numeric', [True, False]),\n",
    "#         'use_publication_discount': trial.suggest_categorical('use_publication_discount', [True, False]),\n",
    "#         'use_session_discount': trial.suggest_categorical('use_session_discount', [True, False])\n",
    "#     }\n",
    "\n",
    "#     # Initialize model and training components\n",
    "#     model = NRMSDocVecModel(hparams=hparams, device=device)\n",
    "#     criterion = model.get_loss().to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), \n",
    "#                           lr=hparams['learning_rate'], \n",
    "#                           weight_decay=hparams['weight_decay'])\n",
    "    \n",
    "#     # Initialize EarlyStopping\n",
    "#     early_stopping = EarlyStopping(patience=4, min_delta=0.025, verbose=True)\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         train_batch_count = 0\n",
    "\n",
    "#         for batch in train_dataloader_temp:\n",
    "#             inputs, targets, impression_id = batch\n",
    "#             inputs = [inp.to(device) for inp in inputs]\n",
    "#             targets = targets.to(device)\n",
    "#             positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#             targets = positive_indices[:, 1].long()\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(*inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             train_batch_count += 1\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         val_batch_count = 0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_dataloader_temp:\n",
    "#                 inputs, targets, impression_id = batch\n",
    "#                 inputs = [inp.to(device) for inp in inputs]\n",
    "#                 targets = targets.to(device)\n",
    "#                 positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#                 targets = positive_indices[:, 1].long()\n",
    "#                 outputs = model(*inputs)\n",
    "#                 loss = criterion(outputs, targets)\n",
    "#                 val_loss += loss.item()\n",
    "#                 val_batch_count += 1\n",
    "\n",
    "#         avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "\n",
    "#         # Update best validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "\n",
    "#         # Early stopping check\n",
    "#         early_stopping(avg_val_loss)\n",
    "#         if early_stopping.early_stop:\n",
    "#             break\n",
    "\n",
    "#         # Report to Optuna\n",
    "#         trial.report(avg_val_loss, epoch)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "\n",
    "#     return best_val_loss\n",
    "\n",
    "# # Create study and optimize\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=15)  # Increased from 3 to 50 trials\n",
    "\n",
    "# # Print results\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Training Progress:   0%|          | 0/15 [00:00<?, ?it/s]c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\models_pytorch\\NRMSDocVecModel.py:325: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Training Progress:  67%|██████▋   | 10/15 [03:42<01:48, 21.70s/it, train_loss=1.6400, val_loss=2.5672]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at epoch 10 with validation loss: 2.5672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  73%|███████▎  | 11/15 [04:01<01:23, 20.95s/it, train_loss=1.5923, val_loss=2.5837]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 12/15 [04:20<01:01, 20.37s/it, train_loss=1.5636, val_loss=2.6070]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  87%|████████▋ | 13/15 [04:40<00:40, 20.06s/it, train_loss=1.5505, val_loss=2.5642]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  87%|████████▋ | 13/15 [04:58<00:45, 22.97s/it, train_loss=1.5238, val_loss=2.6231]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 4\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure you have defined or imported the EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif current_score < self.best_score - self.min_delta:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Define model_checkpoint function if not already defined\n",
    "def model_checkpoint(model, val_loss, epoch, path='model_checkpoint.pth'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "    }, path)\n",
    "    print(f\"Model checkpoint saved at epoch {epoch} with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "# Initialize components\n",
    "NUM_EPOCHS = 15\n",
    "early_stopping = EarlyStopping(patience=4, min_delta=0.025, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Use appropriate loss function\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=hparams_nrms.learning_rate,  # Ensure hparams_nrms is defined and has learning_rate\n",
    "    weight_decay=hparams_nrms.weight_decay  # Ensure hparams_nrms has weight_decay\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Ensure your dataloaders are defined\n",
    "# train_dataloader_temp = ...\n",
    "# val_dataloader_temp = ...\n",
    "\n",
    "epoch_pbar = tqdm(range(1, NUM_EPOCHS + 1), desc=\"Training Progress\", dynamic_ncols=True)\n",
    "for epoch in epoch_pbar:\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch in train_dataloader_temp:\n",
    "        inputs, targets, _ = batch  # Assuming the third element is not used\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Extract positive indices\n",
    "        positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "        if positive_indices.numel() == 0:\n",
    "            raise ValueError(\"No positive samples in the batch\")\n",
    "            continue  # Skip if no positive samples in the batch\n",
    "        targets = positive_indices[:, 1].long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs)  # Shape: (N, C)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    avg_train_loss = running_loss / train_batch_count if train_batch_count > 0 else float('inf')\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader_temp:\n",
    "            inputs, targets, _ = batch\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "            if positive_indices.numel() == 0:\n",
    "                continue\n",
    "            targets = positive_indices[:, 1].long()\n",
    "\n",
    "            outputs = model(*inputs)  # Shape: (N, C)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_batch_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Logging\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "\n",
    "    # Update Progress Bar\n",
    "    epoch_pbar.set_postfix({\n",
    "        'train_loss': f'{avg_train_loss:.4f}',\n",
    "        'val_loss': f'{avg_val_loss:.4f}',\n",
    "    })\n",
    "\n",
    "    # Save Checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        model_checkpoint(model, avg_val_loss, epoch)\n",
    "\n",
    "    # Scheduler Step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Summary:\n",
      "Initial Training Loss: 7.0651\n",
      "Final Training Loss: 1.5238\n",
      "Best Training Loss: 1.5238\n",
      "\n",
      "Initial Validation Loss: 9.3543\n",
      "Final Validation Loss: 2.6231\n",
      "Best Validation Loss: 2.5642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"nrms_training_loss.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print final statistics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Initial Training Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Training Loss: {min(train_losses):.4f}\")\n",
    "print(f\"\\nInitial Validation Loss: {val_losses[0]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Validation Loss: {min(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def evaluate_model(model, dataloader, device):\n",
    "#     \"\"\"Evaluate the model and return predictions and labels for metric calculation.\"\"\"\n",
    "#     model.eval()\n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     print(\"\\nEvaluating DataLoader...\")\n",
    "#     total_samples = len(dataloader.dataset)\n",
    "#     print(f\"Total samples in DataLoader: {total_samples}\")\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets, impression_ids) in enumerate(dataloader):\n",
    "#             his_input_title, pred_input_title = inputs\n",
    "\n",
    "#             if batch_idx == 0:  # Debug first batch shapes\n",
    "#                 print(\"\\nFirst batch shapes:\")\n",
    "#                 print(f\"  - his_input_title: {his_input_title.shape}\")\n",
    "#                 print(f\"  - pred_input_title: {pred_input_title.shape}\")\n",
    "#                 print(f\"  - targets: {targets.shape}\")\n",
    "\n",
    "#             # Move data to device\n",
    "#             his_input_title = his_input_title.to(device)\n",
    "#             pred_input_title = pred_input_title.to(device)\n",
    "#             targets = targets.to(device)\n",
    "\n",
    "#             # Get predictions\n",
    "#             predictions = model.predict(his_input_title, pred_input_title)\n",
    "#             predictions = predictions.cpu().numpy()\n",
    "#             targets = targets.cpu().numpy()\n",
    "\n",
    "#             # Process each sample in the batch\n",
    "#             batch_size = predictions.shape[0]\n",
    "#             for sample_idx in range(batch_size):\n",
    "#                 pred = predictions[sample_idx]\n",
    "#                 label = targets[sample_idx]\n",
    "\n",
    "#                 # Create valid_mask where label is not equal to the padding value (-1)\n",
    "#                 valid_mask = (label != -1)\n",
    "#                 sample_preds = pred[valid_mask]\n",
    "#                 sample_labels = label[valid_mask]\n",
    "\n",
    "#                 if len(sample_labels) == 0:\n",
    "#                     continue  # Skip empty samples\n",
    "\n",
    "#                 # Ensure that there is at least one positive and one negative label\n",
    "#                 if len(np.unique(sample_labels)) < 2:\n",
    "#                     continue  # Skip samples with only one class\n",
    "\n",
    "#                 all_predictions.append(sample_preds.tolist())\n",
    "#                 all_labels.append(sample_labels.tolist())\n",
    "\n",
    "#     print(\"\\nEvaluation completed.\")\n",
    "#     print(f\"Total predictions generated: {len(all_predictions)}\")\n",
    "#     print(f\"First few prediction lengths: {[len(x) for x in all_predictions[:15]]}\")\n",
    "#     return all_labels, all_predictions\n",
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# labels_list, scores_list = evaluate_model(model, val_dataloader_temp, device)\n",
    "\n",
    "# # Validate predictions against the DataFrame\n",
    "# print(\"\\nValidation against DataFrame:\")\n",
    "# if len(scores_list) != len(df_validation):\n",
    "#     print(\"WARNING: Length mismatch!\")\n",
    "#     print(f\"  - Number of predictions: {len(scores_list)}\")\n",
    "#     print(f\"  - Number of rows in DataFrame: {len(df_validation)}\")\n",
    "\n",
    "# # Compute metrics\n",
    "# metrics = MetricEvaluator(\n",
    "#     labels=labels_list,\n",
    "#     predictions=scores_list,\n",
    "#     metric_functions=[\n",
    "#         AucScore(),\n",
    "#         MrrScore(),\n",
    "#         NdcgScore(k=5),\n",
    "#         NdcgScore(k=10)\n",
    "#     ],\n",
    "# )\n",
    "# results = metrics.evaluate()\n",
    "# print(\"\\nMetrics:\", results.evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRACTION: 0.1, HISTORY_SIZE: 20\n",
      "Hyperparameters:\n",
      "title_size: 300\n",
      "embedding_dim: 32\n",
      "word_emb_dim: 8\n",
      "vocab_size: 10000\n",
      "head_num: 16\n",
      "head_dim: 96\n",
      "attention_hidden_dim: 96\n",
      "hidden_dim: 4\n",
      "optimizer: adam\n",
      "loss: cross_entropy_loss\n",
      "dropout: 0.1749\n",
      "learning_rate: 1.0454050068420554e-05\n",
      "weight_decay: 0.006587407554797856\n",
      "news_output_dim: 96\n",
      "units_per_layer: [421, 386]\n",
      "use_category: False\n",
      "use_topic: False\n",
      "use_numeric: False\n",
      "use_session_discount: True\n",
      "use_publication_discount: True\n",
      "doc_out_dim: 128\n",
      "cat_out_dim: 128\n",
      "top_out_dim: 128\n",
      "numeric_proj_dim: 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"FRACTION: {FRACTION}, HISTORY_SIZE: {HISTORY_SIZE}\")\n",
    "\n",
    "# Filter out special Python attributes and print parameters\n",
    "params = {k: v for k, v in hparams_nrms.__dict__.items() if not k.startswith('__')}\n",
    "print(\"Hyperparameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_labels(df: pl.DataFrame, impression_id: int) -> int:\n",
    "    # Filter for matching impression_id\n",
    "    filtered = df.filter(pl.col('impression_id') == impression_id)\n",
    "    \n",
    "    if filtered.height == 0:\n",
    "        raise ValueError(f\"No row found for impression_id {impression_id}\")\n",
    "    \n",
    "    # Get labels from first row\n",
    "    labels = filtered.select('labels').row(0)[0]\n",
    "    \n",
    "    return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_length_of_labels(df_validation, 349992000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [0, 0, 0, 1, 0, 0, 0, 0]\n",
      "Label 1: [0, 0, 0, 0, 0, 1]\n",
      "Label 2: [0, 0, 0, 0, 1, 0]\n",
      "Label 3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label 4: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 labels\n",
    "first_5_labels = df_validation.select('labels').head(5)\n",
    "\n",
    "# Print each label with index\n",
    "for i, row in enumerate(first_5_labels.iter_rows()):\n",
    "    print(f\"Label {i}: {row[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples with only one class\n",
      "Remaining valid samples: 24322\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize lists\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "skipped_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader_temp:\n",
    "        inputs, targets, impression_ids = batch\n",
    "        \n",
    "        # Move to device\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(*inputs)\n",
    "        \n",
    "        # Convert to probabilities if needed\n",
    "        if not torch.is_floating_point(predictions):\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Convert to lists while preserving structure\n",
    "        batch_preds = predictions.cpu().numpy().tolist()\n",
    "        batch_labels = targets.cpu().numpy().tolist()\n",
    "        impression_ids = impression_ids.cpu().numpy().tolist()\n",
    "        \n",
    "        batch_preds_without_padding = []\n",
    "        batch_labels_without_padding = []\n",
    "        \n",
    "        for pred_sample, label_sample, impression_id_sample in zip(batch_preds, batch_labels, impression_ids):\n",
    "            # Remove padding\n",
    "            actual_length = get_length_of_labels(df_validation, impression_id_sample)\n",
    "            pred_sample = pred_sample[:actual_length]\n",
    "            \n",
    "            # Check if sample has both classes before adding\n",
    "            if 1 in label_sample[:actual_length] and 0 in label_sample[:actual_length]:\n",
    "                batch_preds_without_padding.append(pred_sample)\n",
    "                batch_labels_without_padding.append(label_sample[:actual_length])\n",
    "            else:\n",
    "                skipped_samples += 1\n",
    "        \n",
    "        # Add batch predictions and labels\n",
    "        all_predictions.extend(batch_preds_without_padding)\n",
    "        all_labels.extend(batch_labels_without_padding)\n",
    "\n",
    "print(f\"Skipped {skipped_samples} samples with only one class\")\n",
    "print(f\"Remaining valid samples: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug: Print label distribution for first 5 samples\n",
    "# for i, (preds, labels) in enumerate(zip(all_predictions[:5], all_labels[:5])):\n",
    "#     print(f\"\\nSample {i}:\")\n",
    "#     print(f\"Labels length:      {len(labels)}\")\n",
    "#     print(f\"Predictions length: {len(preds)}\")\n",
    "#     print(f\"Num positives: {sum(labels)}\")\n",
    "#     print(f\"Num negatives: {len(labels) - sum(labels)}\")\n",
    "#     print(f\"Label distribution: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(all_predictions))\n",
    "# print(type(all_labels))\n",
    "\n",
    "# print(f\"Number of predictions: {len(all_predictions)}\")\n",
    "# print(f\"example prediction: {all_predictions[0:2]}\")\n",
    "# print(f\"Number of labels: {len(all_labels)}\")\n",
    "# print(f\"example label: {all_labels[0:2]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1728\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "correct_predictions = 0\n",
    "total_samples = len(all_predictions)\n",
    "\n",
    "# Iterate over samples\n",
    "for idx, _ in enumerate(all_predictions):\n",
    "    # print(f\"Sample {idx}: Prediction: {all_predictions[idx]}\")\n",
    "    # print(f\"Sample {idx}: Label:      {all_labels[idx]}\")\n",
    "    \n",
    "    # Extract index of maximum value in predictions and labels\n",
    "    pred_max_index = np.argmax(all_predictions[idx])\n",
    "    label_max_index = np.argmax(all_labels[idx])\n",
    "    \n",
    "    # Compare indices to determine if the prediction was correct\n",
    "    if pred_max_index == label_max_index:\n",
    "        # print(f\"Sample {idx}: Prediction was correct.\")\n",
    "        correct_predictions += 1\n",
    "  #  else:\n",
    "        # print(f\"Sample {idx}: Prediction was wrong.\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.5933\n",
      "Number of valid AUC calculations: 24322\n"
     ]
    }
   ],
   "source": [
    "from evaluation import AucScore\n",
    "\n",
    "# auc_score = AucScore()\n",
    "\n",
    "# auc_score.calculate(all_predictions, all_labels)\n",
    "# print(f\"AUC: {auc_score.score}\")\n",
    "# # Calculate AUC per sample\n",
    "aucs = []\n",
    "for preds, labels in zip(all_predictions, all_labels):\n",
    "    try:\n",
    "        # Only calculate if we have both positive and negative samples\n",
    "        if sum(labels) > 0 and sum(labels) < len(labels):\n",
    "            auc = roc_auc_score(labels, preds)\n",
    "            aucs.append(auc)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Only one class present in labels. Cannot calculate AUC.\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(aucs):.4f}\")\n",
    "print(f\"Number of valid AUC calculations: {len(aucs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
