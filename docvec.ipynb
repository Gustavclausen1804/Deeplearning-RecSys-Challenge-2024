{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Python version: 3.12.1\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Current GPU device: NVIDIA GeForce RTX 3070\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "#import optuna\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL,\n",
    "    DEFAULT_TOTAL_READ_TIME_COL,\n",
    "    DEFAULT_SENTIMENT_SCORE_COL,\n",
    "    DEFAULT_SENTIMENT_LABEL_COL,\n",
    ")\n",
    "\n",
    "from utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from utils._articles import convert_text2encoding_with_transformers\n",
    "from utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from utils._articles import create_article_id_to_value_mapping\n",
    "from utils._nlp import get_transformers_word_embeddings, generate_embeddings_with_transformers\n",
    "from utils._python import write_submission_file, rank_predictions_by_score\n",
    "from models_pytorch.model_config import hparams_nrms\n",
    "\n",
    "from models_pytorch.nrms import NRMSModel\n",
    "from models_pytorch.NRMSDocVecModel import NRMSDocVecModel\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from models_pytorch.dataloader import NRMSDataSet\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at behaviours and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebnerd_small\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"./ebnerd_small\")  # Base path for your data directory\n",
    "print(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>datetime[μs]</td><td>list[i8]</td></tr></thead><tbody><tr><td>1602802</td><td>[9759476, 9766805, … 9770327]</td><td>[9777397, 9778845, … 9778917]</td><td>[9778917]</td><td>415012583</td><td>2023-05-24 12:44:51</td><td>[0, 0, … 1]</td></tr><tr><td>2479907</td><td>[9768802, 9768819, … 9770538]</td><td>[9775908, 9747329, … 9777565]</td><td>[9775908]</td><td>119113694</td><td>2023-05-23 16:34:59</td><td>[1, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆ u32          ┆ datetime[μs] ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 1602802 ┆ [9759476,    ┆ [9777397,    ┆ [9778917]    ┆ 415012583    ┆ 2023-05-24   ┆ [0, 0, … 1] │\n",
       "│         ┆ 9766805, …   ┆ 9778845, …   ┆              ┆              ┆ 12:44:51     ┆             │\n",
       "│         ┆ 9770327]     ┆ 9778917]     ┆              ┆              ┆              ┆             │\n",
       "│ 2479907 ┆ [9768802,    ┆ [9775908,    ┆ [9775908]    ┆ 119113694    ┆ 2023-05-23   ┆ [1, 0, … 0] │\n",
       "│         ┆ 9768819, …   ┆ 9747329, …   ┆              ┆              ┆ 16:34:59     ┆             │\n",
       "│         ┆ 9770538]     ┆ 9777565]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "]\n",
    "HISTORY_SIZE = 20 # TODO: History size. \n",
    "FRACTION = 0.1\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.with_columns([\n",
    "    (\n",
    "        (pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)\n",
    "        .dt.epoch(time_unit='s') / 3600)\n",
    "        .cast(pl.Int64)\n",
    "    ).alias(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "])\n",
    "\n",
    "df_validation = df_validation.with_columns([\n",
    "    (\n",
    "        (pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)\n",
    "        .dt.epoch(time_unit='s') / 3600)\n",
    "        .cast(pl.Int64)\n",
    "    ).alias(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>i64</td><td>list[i8]</td></tr></thead><tbody><tr><td>1602802</td><td>[9759476, 9766805, … 9770327]</td><td>[9777397, 9778845, … 9778917]</td><td>[9778917]</td><td>415012583</td><td>468036</td><td>[0, 0, … 1]</td></tr><tr><td>2479907</td><td>[9768802, 9768819, … 9770538]</td><td>[9775908, 9747329, … 9777565]</td><td>[9775908]</td><td>119113694</td><td>468016</td><td>[1, 0, … 0]</td></tr><tr><td>2445823</td><td>[9767989, 9767975, … 9769883]</td><td>[9776968, 9776929, … 9776929]</td><td>[9776968]</td><td>354523915</td><td>468010</td><td>[1, 0, … 0]</td></tr><tr><td>1813382</td><td>[9766886, 9765326, … 9735909]</td><td>[9769135, 9767534, … 9768820]</td><td>[9771842]</td><td>2919485</td><td>467912</td><td>[0, 0, … 0]</td></tr><tr><td>614568</td><td>[9766560, 9767545, … 8912755]</td><td>[9769996, 9660631, … 9745661]</td><td>[9717601]</td><td>225697416</td><td>467892</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆ u32          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 1602802 ┆ [9759476,    ┆ [9777397,    ┆ [9778917]    ┆ 415012583    ┆ 468036       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9766805, …   ┆ 9778845, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9770327]     ┆ 9778917]     ┆              ┆              ┆              ┆             │\n",
       "│ 2479907 ┆ [9768802,    ┆ [9775908,    ┆ [9775908]    ┆ 119113694    ┆ 468016       ┆ [1, 0, … 0] │\n",
       "│         ┆ 9768819, …   ┆ 9747329, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9770538]     ┆ 9777565]     ┆              ┆              ┆              ┆             │\n",
       "│ 2445823 ┆ [9767989,    ┆ [9776968,    ┆ [9776968]    ┆ 354523915    ┆ 468010       ┆ [1, 0, … 0] │\n",
       "│         ┆ 9767975, …   ┆ 9776929, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9769883]     ┆ 9776929]     ┆              ┆              ┆              ┆             │\n",
       "│ 1813382 ┆ [9766886,    ┆ [9769135,    ┆ [9771842]    ┆ 2919485      ┆ 467912       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9765326, …   ┆ 9767534, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9735909]     ┆ 9768820]     ┆              ┆              ┆              ┆             │\n",
       "│ 614568  ┆ [9766560,    ┆ [9769996,    ┆ [9717601]    ┆ 225697416    ┆ 467892       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9767545, …   ┆ 9660631, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 8912755]     ┆ 9745661]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>u32</td><td>i64</td><td>list[i8]</td></tr></thead><tbody><tr><td>1422749</td><td>[9775722, 9775568, … 9778219]</td><td>[9788841, 9788524, … 9789125]</td><td>[9788524]</td><td>370301228</td><td>468190</td><td>[0, 1, … 0]</td></tr><tr><td>1168252</td><td>[9772557, 9773341, … 9779860]</td><td>[9783379, 9785645, … 9783865]</td><td>[9746499]</td><td>507072763</td><td>468137</td><td>[0, 0, … 0]</td></tr><tr><td>1890742</td><td>[9779045, 9779705, … 9778902]</td><td>[9778732, 9783056, … 9782652]</td><td>[9783051]</td><td>352775765</td><td>468091</td><td>[0, 0, … 0]</td></tr><tr><td>1767745</td><td>[9773868, 9775983, … 9778939]</td><td>[9780769, 9780648, … 9777858]</td><td>[9778939]</td><td>144355330</td><td>468059</td><td>[0, 0, … 0]</td></tr><tr><td>1417057</td><td>[9778262, 9778102, … 9779263]</td><td>[9789327, 9780374, … 9788947]</td><td>[9786549]</td><td>160245775</td><td>468196</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i32]    ┆ list[i32]    ┆ u32          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 1422749 ┆ [9775722,    ┆ [9788841,    ┆ [9788524]    ┆ 370301228    ┆ 468190       ┆ [0, 1, … 0] │\n",
       "│         ┆ 9775568, …   ┆ 9788524, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778219]     ┆ 9789125]     ┆              ┆              ┆              ┆             │\n",
       "│ 1168252 ┆ [9772557,    ┆ [9783379,    ┆ [9746499]    ┆ 507072763    ┆ 468137       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9773341, …   ┆ 9785645, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779860]     ┆ 9783865]     ┆              ┆              ┆              ┆             │\n",
       "│ 1890742 ┆ [9779045,    ┆ [9778732,    ┆ [9783051]    ┆ 352775765    ┆ 468091       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9779705, …   ┆ 9783056, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778902]     ┆ 9782652]     ┆              ┆              ┆              ┆             │\n",
       "│ 1767745 ┆ [9773868,    ┆ [9780769,    ┆ [9778939]    ┆ 144355330    ┆ 468059       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9775983, …   ┆ 9780648, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778939]     ┆ 9777858]     ┆              ┆              ┆              ┆             │\n",
       "│ 1417057 ┆ [9778262,    ┆ [9789327,    ┆ [9786549]    ┆ 160245775    ┆ 468196       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778102, …   ┆ 9780374, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779263]     ┆ 9788947]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of article_ids_inview in df_train: 5.0\n",
      "Average length of article_ids_inview in df_validation: 11.933289731850882\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_length(df, column):\n",
    "    total_length = sum(len(row) for row in df[column])\n",
    "    average_length = total_length / len(df)\n",
    "    return average_length\n",
    "\n",
    "# Calculate average length for df_train\n",
    "average_length_inview_train = calculate_average_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_train: {average_length_inview_train}\")\n",
    "\n",
    "# Calculate average length for df_validation\n",
    "average_length_inview_validation = calculate_average_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_validation: {average_length_inview_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest inview article length in df_train: 5\n",
      "Longest inview article length in df_validation: 90\n",
      "Longest history length in df_train: 20\n",
      "Longest history length in df_validation: 20\n"
     ]
    }
   ],
   "source": [
    "# Function to find the maximum length of arrays in a column\n",
    "def find_max_length(df, column):\n",
    "    max_length = 0\n",
    "    for row in df[column]:\n",
    "        max_length = max(max_length, len(row))\n",
    "    return max_length\n",
    "\n",
    "# Find the longest inview article length in df_train\n",
    "max_inview_length_train = find_max_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "# Find the longest inview article length in df_validation\n",
    "max_inview_length_validation = find_max_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "print(f\"Longest inview article length in df_train: {max_inview_length_train}\")\n",
    "print(f\"Longest inview article length in df_validation: {max_inview_length_validation}\")\n",
    "\n",
    "max_history_length_train = find_max_length(df_train, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "max_history_length_validation = find_max_length(df_validation, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "\n",
    "print(f\"Longest history length in df_train: {max_history_length_train}\")\n",
    "print(f\"Longest history length in df_validation: {max_history_length_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with exactly one clicked article in df_train: 23427\n",
      "Number of rows with exactly one clicked article in df_validation: 24302\n"
     ]
    }
   ],
   "source": [
    "# Function to filter rows with exactly one clicked article\n",
    "def filter_rows_with_one_clicked_article(df, clicked_articles_col):\n",
    "    # Manually filter rows where the array has exactly one element\n",
    "    filtered_rows = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        if len(row[clicked_articles_col]) == 1:\n",
    "            filtered_rows.append(row)\n",
    "    return pl.DataFrame(filtered_rows)\n",
    "\n",
    "\n",
    "# Filter rows in df_train and df_validation\n",
    "df_train = filter_rows_with_one_clicked_article(df_train, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "df_validation = filter_rows_with_one_clicked_article(df_validation, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of rows with exactly one clicked article in df_train: {df_train.shape[0]}\")\n",
    "print(f\"Number of rows with exactly one clicked article in df_validation: {df_validation.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>1422749</td><td>[9775722, 9775568, … 9778219]</td><td>[9788841, 9788524, … 9789125]</td><td>[9788524]</td><td>370301228</td><td>468190</td><td>[0, 1, … 0]</td></tr><tr><td>1168252</td><td>[9772557, 9773341, … 9779860]</td><td>[9783379, 9785645, … 9783865]</td><td>[9746499]</td><td>507072763</td><td>468137</td><td>[0, 0, … 0]</td></tr><tr><td>1890742</td><td>[9779045, 9779705, … 9778902]</td><td>[9778732, 9783056, … 9782652]</td><td>[9783051]</td><td>352775765</td><td>468091</td><td>[0, 0, … 0]</td></tr><tr><td>1767745</td><td>[9773868, 9775983, … 9778939]</td><td>[9780769, 9780648, … 9777858]</td><td>[9778939]</td><td>144355330</td><td>468059</td><td>[0, 0, … 0]</td></tr><tr><td>1417057</td><td>[9778262, 9778102, … 9779263]</td><td>[9789327, 9780374, … 9788947]</td><td>[9786549]</td><td>160245775</td><td>468196</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ i64     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i64]   │\n",
       "│         ┆ list[i64]    ┆ list[i64]    ┆ list[i64]    ┆ i64          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 1422749 ┆ [9775722,    ┆ [9788841,    ┆ [9788524]    ┆ 370301228    ┆ 468190       ┆ [0, 1, … 0] │\n",
       "│         ┆ 9775568, …   ┆ 9788524, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778219]     ┆ 9789125]     ┆              ┆              ┆              ┆             │\n",
       "│ 1168252 ┆ [9772557,    ┆ [9783379,    ┆ [9746499]    ┆ 507072763    ┆ 468137       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9773341, …   ┆ 9785645, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779860]     ┆ 9783865]     ┆              ┆              ┆              ┆             │\n",
       "│ 1890742 ┆ [9779045,    ┆ [9778732,    ┆ [9783051]    ┆ 352775765    ┆ 468091       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9779705, …   ┆ 9783056, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778902]     ┆ 9782652]     ┆              ┆              ┆              ┆             │\n",
       "│ 1767745 ┆ [9773868,    ┆ [9780769,    ┆ [9778939]    ┆ 144355330    ┆ 468059       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9775983, …   ┆ 9780648, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778939]     ┆ 9777858]     ┆              ┆              ┆              ┆             │\n",
       "│ 1417057 ┆ [9778262,    ┆ [9789327,    ┆ [9786549]    ┆ 160245775    ┆ 468196       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778102, …   ┆ 9780374, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779263]     ┆ 9788947]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in df_train: 8906\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users in df_train: {df_train['user_id'].n_unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>3042022</td><td>&quot;Steffen Nielsen stopper karrie…</td><td>&quot;BOKSNING: Sværvægteren Steffen…</td><td>2023-06-29 06:21:11</td><td>false</td><td>&quot;Team Palle blev fredag aften i…</td><td>2005-04-15 19:25:00</td><td>[3132301]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[&quot;Nielsen&quot;, &quot;Arias&quot;, &quot;Nielsen&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kendt&quot;, &quot;Begivenhed&quot;, … &quot;Sportsbegivenhed&quot;]</td><td>142</td><td>[327, 331]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.6762</td><td>&quot;Negative&quot;</td></tr><tr><td>3043233</td><td>&quot;Verdens længste ægteskab&quot;</td><td>&quot;Et britisk ægtepar, der har ho…</td><td>2023-06-29 06:21:14</td><td>false</td><td>&quot;Hr. og Fru Arrowsmith er indeh…</td><td>2005-06-02 09:00:00</td><td>[3021691]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Livsstil&quot;, … &quot;Partnerskab&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.5833</td><td>&quot;Positive&quot;</td></tr><tr><td>3044020</td><td>&quot;Prins Harry tvunget til dna-te…</td><td>&quot;Hoffet tvang Prins Harry til a…</td><td>2023-06-29 06:21:16</td><td>false</td><td>&quot;Den britiske tabloidavis The S…</td><td>2005-06-29 08:47:00</td><td>[3097307, 3097197, 3104927]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[&quot;Harry&quot;, &quot;James Hewitt&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Personfarlig kriminalitet&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7084</td><td>&quot;Negative&quot;</td></tr><tr><td>3054881</td><td>&quot;Jude Law taget på sengen&quot;</td><td>&quot;Det var det ene af hans børn, …</td><td>2023-06-29 06:21:18</td><td>false</td><td>&quot;Jude Law har offentligt undsky…</td><td>2005-07-19 09:37:00</td><td>[3108388]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Partnerskab&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8204</td><td>&quot;Negative&quot;</td></tr><tr><td>3055529</td><td>&quot;Lykketofts kostbare kærlighed&quot;</td><td>&quot;Har betalt 6,1 mio. kr. for si…</td><td>2023-06-29 06:21:19</td><td>false</td><td>&quot;Socialdemokraternes tidligere …</td><td>2005-08-10 05:44:00</td><td>[3045566, 3045568]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Økonomi&quot;, … &quot;Køb og salg&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.987</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 3042022   ┆ Steffen   ┆ BOKSNING: ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.6762    ┆ Negative │\n",
       "│           ┆ Nielsen   ┆ Sværvægte ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ stopper   ┆ ren       ┆ 06:21:11  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ karrie…   ┆ Steffen…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3043233   ┆ Verdens   ┆ Et        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.5833    ┆ Positive │\n",
       "│           ┆ længste   ┆ britisk   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ ægteskab  ┆ ægtepar,  ┆ 06:21:14  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ der har   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ ho…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3044020   ┆ Prins     ┆ Hoffet    ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7084    ┆ Negative │\n",
       "│           ┆ Harry     ┆ tvang     ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tvunget   ┆ Prins     ┆ 06:21:16  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ til       ┆ Harry til ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dna-te…   ┆ a…        ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3054881   ┆ Jude Law  ┆ Det var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8204    ┆ Negative │\n",
       "│           ┆ taget på  ┆ det ene   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sengen    ┆ af hans   ┆ 06:21:18  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ børn, …   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3055529   ┆ Lykketoft ┆ Har       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.987     ┆ Negative │\n",
       "│           ┆ s         ┆ betalt    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ kostbare  ┆ 6,1 mio.  ┆ 06:21:19  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ kærlighed ┆ kr. for   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ si…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3449000120162964, 0.9983000159263611)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# range of sentiment score\n",
    "df_articles[DEFAULT_SENTIMENT_SCORE_COL].min(), df_articles[DEFAULT_SENTIMENT_SCORE_COL].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 218175552.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# range of total_read_time\n",
    "df_articles[DEFAULT_TOTAL_READ_TIME_COL].min(), df_articles[DEFAULT_TOTAL_READ_TIME_COL].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1637751)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# range of total_pageviews\n",
    "df_articles[DEFAULT_TOTAL_PAGEVIEWS_COL].min(), df_articles[DEFAULT_TOTAL_PAGEVIEWS_COL].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def preprocess_articles(df_articles, sentiment_mapping, pageview_thresholds, read_time_thresholds):\n",
    "    \"\"\"\n",
    "    Preprocess the Polars DataFrame for use in the model.\n",
    "\n",
    "    Args:\n",
    "        df_articles (pl.DataFrame): The input DataFrame with article data.\n",
    "        sentiment_mapping (dict): Mapping from sentiment labels to sentiment scores.\n",
    "        pageview_thresholds (list): Thresholds for bucketing pageviews.\n",
    "        read_time_thresholds (list): Thresholds for bucketing read times.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Preprocessed DataFrame with added bucket columns.\n",
    "    \"\"\"\n",
    "    # Constants for column names\n",
    "\n",
    "\n",
    "    # Replace missing values with 0\n",
    "    df_articles = df_articles.with_columns([\n",
    "        pl.col(DEFAULT_TOTAL_PAGEVIEWS_COL).fill_null(0),\n",
    "        pl.col(DEFAULT_TOTAL_READ_TIME_COL).fill_null(0),\n",
    "    ])\n",
    "\n",
    "    # Map sentiment labels to sentiment scores (using plain Python)\n",
    "    sentiment_scores = [sentiment_mapping.get(label, 0.0) for label in df_articles[DEFAULT_SENTIMENT_LABEL_COL].to_list()]\n",
    "\n",
    "    # Add sentiment scores as a new column\n",
    "    df_articles = df_articles.with_columns(\n",
    "        pl.Series(DEFAULT_SENTIMENT_SCORE_COL, sentiment_scores)\n",
    "    )\n",
    "\n",
    "    # Log-transform total pageviews and total read time using math.log\n",
    "    log_pageviews = [math.log(value + 1) for value in df_articles[DEFAULT_TOTAL_PAGEVIEWS_COL].to_list()]\n",
    "    log_read_time = [math.log(value + 1) for value in df_articles[DEFAULT_TOTAL_READ_TIME_COL].to_list()]\n",
    "\n",
    "    df_articles = df_articles.with_columns([\n",
    "        pl.Series(\"log_pageviews\", log_pageviews),\n",
    "        pl.Series(\"log_read_time\", log_read_time),\n",
    "    ])\n",
    "\n",
    "    # Bucketize total pageviews\n",
    "    pageview_buckets = [\n",
    "        0 if x < pageview_thresholds[0] else 1 if x < pageview_thresholds[1] else 2\n",
    "        for x in log_pageviews\n",
    "    ]\n",
    "    df_articles = df_articles.with_columns(\n",
    "        pl.Series(\"pageview_buckets\", pageview_buckets)\n",
    "    )\n",
    "\n",
    "    # Bucketize total read time\n",
    "    read_time_buckets = [\n",
    "        0 if x < read_time_thresholds[0] else 1 if x < read_time_thresholds[1] else 2\n",
    "        for x in log_read_time\n",
    "    ]\n",
    "    df_articles = df_articles.with_columns(\n",
    "        pl.Series(\"read_time_buckets\", read_time_buckets)\n",
    "    )\n",
    "\n",
    "    return df_articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "\n",
    "\n",
    "# Define your thresholds and mapping\n",
    "pageview_thresholds = [np.log(10), np.log(10000)]\n",
    "read_time_thresholds = [np.log(100), np.log(10000)]\n",
    "sentiment_mapping = {\"Negative\": 0.2, \"Neutral\": 0.5, \"Positive\": 0.8}\n",
    "\n",
    "\n",
    "# Preprocess the articles\n",
    "df_processed = preprocess_articles(\n",
    "    df_articles,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    pageview_thresholds=pageview_thresholds,\n",
    "    read_time_thresholds=read_time_thresholds\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#print(df_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = df_articles.with_columns([\n",
    "    pl.Series(DEFAULT_TOTAL_PAGEVIEWS_COL, df_processed[\"log_pageviews\"]),\n",
    "    pl.Series(DEFAULT_TOTAL_READ_TIME_COL, df_processed[\"log_read_time\"]),\n",
    "    pl.Series(DEFAULT_SENTIMENT_SCORE_COL, df_processed[DEFAULT_SENTIMENT_SCORE_COL]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.2</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.8</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.2</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.5</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.5</td><td>&quot;Neutral&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ f64       ┆ f64       ┆ f64       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.2       ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.8       ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.2       ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.5       ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.5       ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pageview Buckets Count:\n",
      "{0: 11247, 2: 7500, 1: 1991}\n",
      "\n",
      "Read Time Buckets Count:\n",
      "{0: 10971, 2: 8351, 1: 1416}\n"
     ]
    }
   ],
   "source": [
    "def count_articles_in_buckets(df_articles):\n",
    "    \"\"\"\n",
    "    Count the number of articles in each bucket manually.\n",
    "\n",
    "    Args:\n",
    "        df_articles (pl.DataFrame): The preprocessed DataFrame with bucket columns.\n",
    "\n",
    "    Returns:\n",
    "        dict: Counts of articles in each bucket for `pageview_buckets` and `read_time_buckets`.\n",
    "    \"\"\"\n",
    "    # Initialize dictionaries to store counts\n",
    "    pageview_counts = {}\n",
    "    read_time_counts = {}\n",
    "\n",
    "    # Extract column values as lists\n",
    "    pageview_buckets = df_articles[\"pageview_buckets\"].to_list()\n",
    "    read_time_buckets = df_articles[\"read_time_buckets\"].to_list()\n",
    "\n",
    "    # Count occurrences in `pageview_buckets`\n",
    "    for bucket in pageview_buckets:\n",
    "        if bucket not in pageview_counts:\n",
    "            pageview_counts[bucket] = 0\n",
    "        pageview_counts[bucket] += 1\n",
    "\n",
    "    # Count occurrences in `read_time_buckets`\n",
    "    for bucket in read_time_buckets:\n",
    "        if bucket not in read_time_counts:\n",
    "            read_time_counts[bucket] = 0\n",
    "        read_time_counts[bucket] += 1\n",
    "\n",
    "    return pageview_counts, read_time_counts\n",
    "\n",
    "\n",
    "\n",
    "# Count articles in each bucket\n",
    "pageview_counts, read_time_counts = count_articles_in_buckets(df_processed)\n",
    "\n",
    "print(\"Pageview Buckets Count:\")\n",
    "print(pageview_counts)\n",
    "\n",
    "print(\"\\nRead Time Buckets Count:\")\n",
    "print(read_time_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = df_articles.with_columns([\n",
    "    (\n",
    "        pl.col(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)                   # Step 3: Cast to Datetime\n",
    "        .dt.epoch(time_unit='s')            # Step 4: Convert to Epoch Seconds\n",
    "        / 3600                               # Step 5: Convert Seconds to Hours\n",
    "    ).cast(pl.Int64)                         # Step 6: Cast to Integer\n",
    "    .alias(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL)  # Step 7: Alias the Column\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles published after January 1, 2023: 2180\n"
     ]
    }
   ],
   "source": [
    "# count how many articles are published after 2023\n",
    "from datetime import datetime\n",
    "\n",
    "epoch_hour_2023 = int(datetime(2023, 5, 22).timestamp() / 3600)\n",
    "\n",
    "count = df_articles.filter(\n",
    "    pl.col(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL) >= epoch_hour_2023\n",
    ").height\n",
    "\n",
    "print(f\"Number of articles published after January 1, 2023: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>i64</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>321392</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.2</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>318952</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.8</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>318470</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.2</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>326312</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.5</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>324754</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.5</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>326386</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.5</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>278748</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.2</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>289470</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.5</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>293287</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.5</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>293923</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>0.0</td><td>0.0</td><td>0.2</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ f64       ┆ f64       ┆ f64       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.2       ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.8       ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.2       ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.5       ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.5       ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.5       ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.2       ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.5       ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.5       ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.2       ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCVEC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document vector parquet file\n",
    "document_vector_path = Path(\"./Ekstra_Bladet_word2vec/document_vector.parquet\")\n",
    "df_document_vector = pl.read_parquet(document_vector_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "\n",
    "article_mapping = create_article_id_to_value_mapping(df=df_document_vector, value_col=\"document_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>document_vector</th></tr><tr><td>i32</td><td>list[f32]</td></tr></thead><tbody><tr><td>3000022</td><td>[0.065424, -0.047425, … 0.035706]</td></tr><tr><td>3000063</td><td>[0.028815, -0.000166, … 0.027167]</td></tr><tr><td>3000613</td><td>[0.037971, 0.033923, … 0.063961]</td></tr><tr><td>3000700</td><td>[0.046524, 0.002913, … 0.023423]</td></tr><tr><td>3000840</td><td>[0.014737, 0.024068, … 0.045991]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────┬─────────────────────────────────┐\n",
       "│ article_id ┆ document_vector                 │\n",
       "│ ---        ┆ ---                             │\n",
       "│ i32        ┆ list[f32]                       │\n",
       "╞════════════╪═════════════════════════════════╡\n",
       "│ 3000022    ┆ [0.065424, -0.047425, … 0.0357… │\n",
       "│ 3000063    ┆ [0.028815, -0.000166, … 0.0271… │\n",
       "│ 3000613    ┆ [0.037971, 0.033923, … 0.06396… │\n",
       "│ 3000700    ┆ [0.046524, 0.002913, … 0.02342… │\n",
       "│ 3000840    ┆ [0.014737, 0.024068, … 0.04599… │\n",
       "└────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_vector.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding tokenized article title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uses existing function for both categories and topics\n",
    "* Handles array of topics by joining with separator\n",
    "* Limits to first 3 topics to avoid sequence length issues\n",
    "* Maintains consistent encoding approach across feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gusta\\AppData\\Local\\Temp\\ipykernel_568\\2581056626.py:21: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  df_articles = df_articles.with_columns(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "MAX_TITLE_LENGTH = 30\n",
    "from transformers import ConvBertTokenizer, ConvBertModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "\n",
    "transformer_tokenizer = ConvBertTokenizer.from_pretrained(\"sarnikowski/convbert-small-da-cased\")\n",
    "transformer_model = ConvBertModel.from_pretrained(\"sarnikowski/convbert-small-da-cased\")\n",
    "\n",
    "\n",
    "# For categories (keep as is - works with single strings)\n",
    "df_articles, category_encoded_col_name = convert_text2encoding_with_transformers(\n",
    "    df_articles, \n",
    "    transformer_tokenizer,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# For topics - first join the array into single string\n",
    "df_articles = df_articles.with_columns(\n",
    "    pl.col(DEFAULT_TOPICS_COL).map_elements(lambda x: \" | \".join(x[:3])).alias(f\"{DEFAULT_TOPICS_COL}_joined\")\n",
    ")\n",
    "\n",
    "# Then encode the joined topics\n",
    "df_articles, topics_encoded_col_name = convert_text2encoding_with_transformers(\n",
    "    df_articles,\n",
    "    transformer_tokenizer, \n",
    "    f\"{DEFAULT_TOPICS_COL}_joined\",\n",
    "    max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# Create mappings with encoded columns\n",
    "category_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=category_encoded_col_name\n",
    ")\n",
    "\n",
    "topic_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=topics_encoded_col_name\n",
    ")\n",
    "# Create mappings for numerical features\n",
    "pageviews_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_TOTAL_PAGEVIEWS_COL\n",
    ")\n",
    "\n",
    "read_time_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_TOTAL_READ_TIME_COL\n",
    ")\n",
    "\n",
    "sentiment_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_SENTIMENT_SCORE_COL\n",
    ")\n",
    "\n",
    "timestamp_mapping = create_article_id_to_value_mapping(\n",
    "    df_articles,\n",
    "    value_col=DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(23427, 7)\n",
      "Data preprocessing completed in 5.51 seconds.\n",
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(24302, 7)\n",
      "Data preprocessing completed in 7.36 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NRMSDataSet(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    category_mapping=category_mapping,\n",
    "    topic_mapping=topic_mapping,\n",
    "    pageviews_mapping=pageviews_mapping,\n",
    "    read_time_mapping=read_time_mapping,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    timestamp_mapping=timestamp_mapping\n",
    "\n",
    ")\n",
    "val_dataset = NRMSDataSet(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    category_mapping=category_mapping,\n",
    "    topic_mapping=topic_mapping,\n",
    "    pageviews_mapping=pageviews_mapping,\n",
    "    read_time_mapping=read_time_mapping,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    timestamp_mapping=timestamp_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 415012583\n",
      "Sample 1:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 119113694\n",
      "Sample 2:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 354523915\n",
      "Sample 3:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 2919485\n",
      "Sample 4:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 225697416\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    sample = train_dataset[idx]\n",
    "    print(f\"Sample {idx}:\")\n",
    "    print(f\"his_input_title shape: {sample[0][0].shape}\")\n",
    "    print(f\"pred_input_title shape: {sample[0][1].shape} {sample[0][1].sum()}\")\n",
    "    print(f\"pred_input_category shape: {sample[0][2].shape} {sample[0][2].sum()}\")\n",
    "    print(f\"pred_input_topic shape: {sample[0][3].shape} {sample[0][3].sum()}\")\n",
    "    print(f\"pred_input_pageviews shape: {sample[0][4].shape} {sample[0][4].sum()}\")\n",
    "    print(f\"Targets shape: {sample[1].shape} , {sample[1].dtype} {sample[1].sum()}\")\n",
    "    print(f\"impression id: {sample[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def collate_fn_with_global_padding(batch, max_len_pred, apply_padding_to_targets=True):\n",
    "    try:\n",
    "        # Unpack all features including timestamps from dataset samples\n",
    "        his_input_titles = [item[0][0] for item in batch]\n",
    "        his_category_emb = [item[0][1] for item in batch]\n",
    "        his_topic_emb = [item[0][2] for item in batch]\n",
    "        his_sentiment_scores = [item[0][3] for item in batch]\n",
    "        his_read_times = [item[0][4] for item in batch]\n",
    "        his_pageviews = [item[0][5] for item in batch]\n",
    "        his_timestamps = [item[0][6] for item in batch]\n",
    "\n",
    "        pred_input_titles = [item[0][7] for item in batch]\n",
    "        pred_category_emb = [item[0][8] for item in batch]\n",
    "        pred_topic_emb = [item[0][9] for item in batch]\n",
    "        pred_sentiment_scores = [item[0][10] for item in batch]\n",
    "        pred_read_times = [item[0][11] for item in batch]\n",
    "        pred_pageviews = [item[0][12] for item in batch]\n",
    "        pred_timestamps = [item[0][13] for item in batch]\n",
    "        impression_timestamps = [item[0][14] for item in batch]\n",
    "\n",
    "        batch_ys = [item[1] for item in batch]\n",
    "        impression_id = torch.tensor([item[2] for item in batch], dtype=torch.int64)\n",
    "\n",
    "        # Pad user history features\n",
    "        his_input_titles_padded = pad_sequence(his_input_titles, batch_first=True, padding_value=0)\n",
    "        his_category_emb_padded = pad_sequence(his_category_emb, batch_first=True, padding_value=0)\n",
    "        his_topic_emb_padded = pad_sequence(his_topic_emb, batch_first=True, padding_value=0)\n",
    "        his_sentiment_padded = pad_sequence(his_sentiment_scores, batch_first=True, padding_value=0)\n",
    "        his_read_times_padded = pad_sequence(his_read_times, batch_first=True, padding_value=0)\n",
    "        his_pageviews_padded = pad_sequence(his_pageviews, batch_first=True, padding_value=0)\n",
    "        his_timestamps_padded = pad_sequence(his_timestamps, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Pad candidate features\n",
    "        pred_input_titles_padded = pad_sequence(pred_input_titles, batch_first=True, padding_value=0)\n",
    "        pred_category_emb_padded = pad_sequence(pred_category_emb, batch_first=True, padding_value=0)\n",
    "        pred_topic_emb_padded = pad_sequence(pred_topic_emb, batch_first=True, padding_value=0)\n",
    "        pred_sentiment_padded = pad_sequence(pred_sentiment_scores, batch_first=True, padding_value=0)\n",
    "        pred_read_times_padded = pad_sequence(pred_read_times, batch_first=True, padding_value=0)\n",
    "        pred_pageviews_padded = pad_sequence(pred_pageviews, batch_first=True, padding_value=0)\n",
    "        pred_timestamps_padded = pad_sequence(pred_timestamps, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # Convert impression timestamps to tensor\n",
    "        impression_timestamps = torch.stack(impression_timestamps)\n",
    "\n",
    "        # Handle max_len_pred for candidate sequences\n",
    "        if pred_input_titles_padded.size(1) < max_len_pred:\n",
    "            pad_size = max_len_pred - pred_input_titles_padded.size(1)\n",
    "            \n",
    "            pred_input_titles_padded = torch.nn.functional.pad(pred_input_titles_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_category_emb_padded = torch.nn.functional.pad(pred_category_emb_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_topic_emb_padded = torch.nn.functional.pad(pred_topic_emb_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_sentiment_padded = torch.nn.functional.pad(pred_sentiment_padded, (0, pad_size), value=0)\n",
    "            pred_read_times_padded = torch.nn.functional.pad(pred_read_times_padded, (0, pad_size), value=0)\n",
    "            pred_pageviews_padded = torch.nn.functional.pad(pred_pageviews_padded, (0, pad_size), value=0)\n",
    "            pred_timestamps_padded = torch.nn.functional.pad(pred_timestamps_padded, (0, pad_size), value=0)\n",
    "\n",
    "        elif pred_input_titles_padded.size(1) > max_len_pred:\n",
    "            pred_input_titles_padded = pred_input_titles_padded[:, :max_len_pred, :]\n",
    "            pred_category_emb_padded = pred_category_emb_padded[:, :max_len_pred, :]\n",
    "            pred_topic_emb_padded = pred_topic_emb_padded[:, :max_len_pred, :]\n",
    "            pred_sentiment_padded = pred_sentiment_padded[:, :max_len_pred]\n",
    "            pred_read_times_padded = pred_read_times_padded[:, :max_len_pred]\n",
    "            pred_pageviews_padded = pred_pageviews_padded[:, :max_len_pred]\n",
    "            pred_timestamps_padded = pred_timestamps_padded[:, :max_len_pred]\n",
    "\n",
    "        # Handle targets padding\n",
    "        if apply_padding_to_targets:\n",
    "            batch_ys_padded = pad_sequence(batch_ys, batch_first=True, padding_value=-1)\n",
    "            if batch_ys_padded.size(1) < max_len_pred:\n",
    "                pad_size = max_len_pred - batch_ys_padded.size(1)\n",
    "                batch_ys_padded = torch.nn.functional.pad(batch_ys_padded, (0, pad_size), value=-1)\n",
    "            elif batch_ys_padded.size(1) > max_len_pred:\n",
    "                batch_ys_padded = batch_ys_padded[:, :max_len_pred]\n",
    "\n",
    "            return (\n",
    "                his_input_titles_padded,\n",
    "                his_category_emb_padded,\n",
    "                his_topic_emb_padded, \n",
    "                his_sentiment_padded,\n",
    "                his_read_times_padded,\n",
    "                his_pageviews_padded,\n",
    "                his_timestamps_padded,\n",
    "                pred_input_titles_padded,\n",
    "                pred_category_emb_padded,\n",
    "                pred_topic_emb_padded,\n",
    "                pred_sentiment_padded,\n",
    "                pred_read_times_padded,\n",
    "                pred_pageviews_padded,\n",
    "                pred_timestamps_padded,\n",
    "                impression_timestamps\n",
    "            ), batch_ys_padded, impression_id\n",
    "        else:\n",
    "            return (\n",
    "                his_input_titles_padded,\n",
    "                his_category_emb_padded,\n",
    "                his_topic_emb_padded,\n",
    "                his_sentiment_padded,\n",
    "                his_read_times_padded,\n",
    "                his_pageviews_padded,\n",
    "                his_timestamps_padded,\n",
    "                pred_input_titles_padded,\n",
    "                pred_category_emb_padded,\n",
    "                pred_topic_emb_padded,\n",
    "                pred_sentiment_padded,\n",
    "                pred_read_times_padded,\n",
    "                pred_pageviews_padded,\n",
    "                pred_timestamps_padded,\n",
    "                impression_timestamps\n",
    "            ), batch_ys, impression_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the dataset with DataLoader\n",
    "train_dataloader_temp = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,    # Set your desired batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_train)\n",
    ")\n",
    "\n",
    "val_dataloader_temp = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,    # Set your desired batch size\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History features shapes:\n",
      "his_input_titles: torch.Size([64, 20, 300])\n",
      "his_category_emb: torch.Size([64, 20, 128])\n",
      "his_topic_emb: torch.Size([64, 20, 128])\n",
      "his_sentiment: torch.Size([64, 20])\n",
      "his_read_times: torch.Size([64, 20])\n",
      "his_pageviews: torch.Size([64, 20])\n",
      "his_timestamps: torch.Size([64, 20])\n",
      "\n",
      "Candidate features shapes:\n",
      "pred_input_titles: torch.Size([64, 90, 300])\n",
      "pred_category_emb: torch.Size([64, 90, 128])\n",
      "pred_topic_emb: torch.Size([64, 90, 128])\n",
      "pred_sentiment: torch.Size([64, 90])\n",
      "pred_read_times: torch.Size([64, 90])\n",
      "pred_pageviews: torch.Size([64, 90])\n",
      "pred_timestamps: torch.Size([64, 90])\n",
      "\n",
      "Other tensors:\n",
      "impression_timestamps: torch.Size([64])\n",
      "batch_ys: torch.Size([64, 90])\n",
      "impression_id: torch.Size([64])\n",
      "\n",
      "Batch loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataloader_temp:\n",
    "    (\n",
    "        his_input_titles_padded, \n",
    "        his_category_emb_padded,\n",
    "        his_topic_emb_padded,\n",
    "        his_sentiment_padded,\n",
    "        his_read_times_padded,\n",
    "        his_pageviews_padded,\n",
    "        his_timestamps_padded,\n",
    "        pred_input_titles_padded,\n",
    "        pred_category_emb_padded,\n",
    "        pred_topic_emb_padded,\n",
    "        pred_sentiment_padded,\n",
    "        pred_read_times_padded,\n",
    "        pred_pageviews_padded,\n",
    "        pred_timestamps_padded,\n",
    "        impression_timestamps\n",
    "    ), batch_ys_padded, impression_id = batch\n",
    "\n",
    "    # Original tensor shapes\n",
    "    print(\"History features shapes:\")\n",
    "    print(f\"his_input_titles: {his_input_titles_padded.shape}\")\n",
    "    print(f\"his_category_emb: {his_category_emb_padded.shape}\")\n",
    "    print(f\"his_topic_emb: {his_topic_emb_padded.shape}\")\n",
    "    print(f\"his_sentiment: {his_sentiment_padded.shape}\")\n",
    "    print(f\"his_read_times: {his_read_times_padded.shape}\")\n",
    "    print(f\"his_pageviews: {his_pageviews_padded.shape}\")\n",
    "    print(f\"his_timestamps: {his_timestamps_padded.shape}\")\n",
    "\n",
    "    print(\"\\nCandidate features shapes:\")\n",
    "    print(f\"pred_input_titles: {pred_input_titles_padded.shape}\")\n",
    "    print(f\"pred_category_emb: {pred_category_emb_padded.shape}\")\n",
    "    print(f\"pred_topic_emb: {pred_topic_emb_padded.shape}\")\n",
    "    print(f\"pred_sentiment: {pred_sentiment_padded.shape}\")\n",
    "    print(f\"pred_read_times: {pred_read_times_padded.shape}\")\n",
    "    print(f\"pred_pageviews: {pred_pageviews_padded.shape}\")\n",
    "    print(f\"pred_timestamps: {pred_timestamps_padded.shape}\")\n",
    "    \n",
    "    print(\"\\nOther tensors:\")\n",
    "    print(f\"impression_timestamps: {impression_timestamps.shape}\")\n",
    "    print(f\"batch_ys: {batch_ys_padded.shape}\")\n",
    "    print(f\"impression_id: {impression_id.shape}\")\n",
    "\n",
    "    print(\"\\nBatch loaded successfully!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the shapes.\n",
    "\n",
    "1. `his_input_titles_padded: [128, 20, 300]`\n",
    "   - 128: batch size\n",
    "   - 20: max history length (user's reading history)\n",
    "   - 300: title embedding dimension from ConvBERT\n",
    "\n",
    "2. `pred_input_titles_padded: [128, 90, 300]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles to predict\n",
    "   - 300: title embedding dimension from ConvBERT\n",
    "\n",
    "3. `pred_category_emb_padded: [128, 90, 128]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - 128: category embedding dimension from ConvBERT\n",
    "\n",
    "4. `pred_topic_emb_padded: [128, 90, 128]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - 128: topic embedding dimension from ConvBERT\n",
    "\n",
    "5. `pred_sentiment_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single sentiment score per article\n",
    "\n",
    "6. `pred_read_times_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single read time value per article\n",
    "\n",
    "7. `pred_pageviews_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single pageview count per article\n",
    "\n",
    "8. `batch_ys_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Binary labels (1 for clicked, 0 for not clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'models_pytorch.model_config', '__annotations__': {'title_size': <class 'int'>, 'embedding_dim': <class 'int'>, 'word_emb_dim': <class 'int'>, 'vocab_size': <class 'int'>, 'head_num': <class 'int'>, 'head_dim': <class 'int'>, 'attention_hidden_dim': <class 'int'>, 'optimizer': <class 'str'>, 'loss': <class 'str'>, 'dropout': <class 'float'>, 'learning_rate': <class 'float'>, 'weight_decay': <class 'float'>, 'units_per_layer': list[int], 'use_category': <class 'bool'>, 'use_topic': <class 'bool'>, 'use_numeric': <class 'bool'>, 'use_session_discount': <class 'bool'>, 'use_publication_discount': <class 'bool'>, 'doc_out_dim': <class 'int'>, 'cat_out_dim': <class 'int'>, 'top_out_dim': <class 'int'>, 'numeric_proj_dim': <class 'int'>}, 'title_size': 300, 'embedding_dim': 32, 'word_emb_dim': 8, 'vocab_size': 10000, 'head_num': 16, 'head_dim': 128, 'attention_hidden_dim': 128, 'hidden_dim': 4, 'optimizer': 'adam', 'loss': 'cross_entropy_loss', 'dropout': 0.3, 'learning_rate': 0.0001, 'weight_decay': 0.001, 'news_output_dim': 128, 'units_per_layer': [512, 256], 'use_category': True, 'use_topic': True, 'use_numeric': True, 'use_session_discount': True, 'use_publication_discount': True, 'doc_out_dim': 128, 'cat_out_dim': 128, 'top_out_dim': 128, 'numeric_proj_dim': 16, '__dict__': <attribute '__dict__' of 'hparams_nrms' objects>, '__weakref__': <attribute '__weakref__' of 'hparams_nrms' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# see the model parameters: \n",
    "hparams_nrms.attention_hidden_dim = 128\n",
    "hparams_nrms.title_size = 300\n",
    "hparams_nrms.head_num = 16\n",
    "hparams_nrms.head_dim = 128\n",
    "hparams_nrms.units_per_layer = [512,256]\n",
    "hparams_nrms.news_output_dim = 128\n",
    "hparams_nrms.dropout = 0.3\n",
    "hparams_nrms.learning_rate = 1e-4\n",
    "hparams_nrms.use_category = True\n",
    "hparams_nrms.use_topic = True\n",
    "hparams_nrms.use_numeric = True\n",
    "hparams_nrms.use_publication_discount = True\n",
    "hparams_nrms.use_session_discount = True\n",
    "print(hparams_nrms.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "  Value:  3.8567059058842696\n",
    "  Params: \n",
    "    head_num: 16\n",
    "    shared_dim: 99\n",
    "    dropout: 0.17498541169326048\n",
    "    learning_rate: 1.0454050068420554e-05\n",
    "    weight_decay: 0.006587407554797856\n",
    "    unit_layer_1: 421\n",
    "    unit_layer_2: 386\n",
    "    use_category: False\n",
    "    use_topic: False\n",
    "    use_numeric: True\n",
    "    use_publication_discount: False\n",
    "    use_session_discount: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters with best trial results\n",
    "\n",
    "# Keep original parameters\n",
    "hparams_nrms.title_size = 300\n",
    "\n",
    "# Update with optimized parameters\n",
    "hparams_nrms.head_num = 4\n",
    "shared_dim = 140  # Rounded up 137 to nearest multiple of head_num\n",
    "hparams_nrms.head_dim = shared_dim\n",
    "hparams_nrms.attention_hidden_dim = shared_dim\n",
    "hparams_nrms.news_output_dim = shared_dim\n",
    "\n",
    "# Update layers\n",
    "hparams_nrms.units_per_layer = [257, 475]  # From optimization\n",
    "\n",
    "# Update learning parameters\n",
    "hparams_nrms.dropout = 0.208\n",
    "hparams_nrms.learning_rate = 8.486e-4\n",
    "hparams_nrms.weight_decay = 1.697e-3\n",
    "\n",
    "# Update feature flags based on optimization\n",
    "hparams_nrms.use_category = True\n",
    "hparams_nrms.use_topic = False\n",
    "hparams_nrms.use_numeric = False\n",
    "hparams_nrms.use_publication_discount = False\n",
    "hparams_nrms.use_session_discount = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters with best trial results\n",
    "\n",
    "# Keep original parameters\n",
    "hparams_nrms.title_size = 300\n",
    "\n",
    "# Update with optimized parameters\n",
    "hparams_nrms.head_num = 16\n",
    "shared_dim = 96  # Rounded up 137 to nearest multiple of head_num\n",
    "hparams_nrms.head_dim = shared_dim\n",
    "hparams_nrms.attention_hidden_dim = shared_dim\n",
    "hparams_nrms.news_output_dim = shared_dim\n",
    "\n",
    "# Update layers\n",
    "hparams_nrms.units_per_layer = [421, 386]  # From optimization\n",
    "\n",
    "# Update learning parameters\n",
    "hparams_nrms.dropout = 0.1749\n",
    "hparams_nrms.learning_rate = 1.0454050068420554e-05\n",
    "hparams_nrms.weight_decay = 0.006587407554797856\n",
    "\n",
    "# Update feature flags based on optimization\n",
    "hparams_nrms.use_category = False\n",
    "hparams_nrms.use_topic = False\n",
    "hparams_nrms.use_numeric = True\n",
    "hparams_nrms.use_publication_discount = True\n",
    "hparams_nrms.use_session_discount = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "  Value:  2.5971557366220575\n",
    "  Params: \n",
    "    head_num: 2\n",
    "    shared_dim: 250\n",
    "    dropout: 0.1684601185173818\n",
    "    learning_rate: 0.0005340885454472421\n",
    "    weight_decay: 0.00015676583811214713\n",
    "    unit_layer_1: 492\n",
    "    unit_layer_2: 263\n",
    "    use_category: False\n",
    "    use_topic: False\n",
    "    use_numeric: False\n",
    "    use_publication_discount: False\n",
    "    use_session_discount: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\models_pytorch\\NRMSDocVecModel.py:338: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define paths\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = os.path.join(\"downloads\", \"runs\", MODEL_NAME)\n",
    "MODEL_WEIGHTS = os.path.join(\"downloads\", \"data\", \"state_dict\", MODEL_NAME, \"weights.pth\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_WEIGHTS), exist_ok=True)\n",
    "\n",
    "# Define ModelCheckpoint class\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Saves the model after every epoch if it has the best performance so far.\"\"\"\n",
    "    def __init__(self, filepath, verbose=False, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath (str): Path to save the model checkpoint.\n",
    "            verbose (bool): If True, prints a message when the model is saved.\n",
    "            save_best_only (bool): If True, saves only when the model is better than before.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_loss = None\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.filepath)\n",
    "        if self.verbose:\n",
    "            print(f\"Model saved to {self.filepath}\")\n",
    "\n",
    "# Define EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve by a given percentage over a patience period.\"\"\"\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after last time validation loss improved by min_delta.\n",
    "            min_delta (float): Minimum percentage improvement required to reset patience.\n",
    "            verbose (bool): If True, prints a message when early stopping is triggered.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta  # Minimum percentage improvement\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            # Initialize best_loss with the first validation loss\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss < self.best_loss * (1 - self.min_delta):\n",
    "            # Significant improvement found\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved by at least {self.min_delta*100:.1f}%\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No significant improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "# Initialize callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_WEIGHTS, verbose=True, save_best_only=True)\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "\n",
    "# Initialize your model\n",
    "# Ensure that NRMSModel is a PyTorch nn.Module\n",
    "\n",
    "# CUDA checks\n",
    "#print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "#print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "#print(f\"Device Name: {torch.cuda.get_device_name()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "# model = NRMSModel(\n",
    "#     hparams=hparams_nrms.__dict__,\n",
    "#     word2vec_embedding=word2vec_embedding,\n",
    "#     vocab_size=30000,\n",
    "#     word_emb_dim=8,\n",
    "#     device=device,\n",
    "#     feed_forward_layers_after_3rd_layer=False,\n",
    "# )\n",
    "\n",
    "model = NRMSDocVecModel(hparams=hparams_nrms.__dict__,\n",
    "                        device=device)\n",
    "\n",
    "# model = NRMSModel(hparams=hparams_nrms.__dict__,\n",
    "#                   word2vec_embedding=word2vec_embedding,\n",
    "#                         device=device)\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSDocVecModel(\n",
      "  (newsencoder): NewsEncoderDocVec(\n",
      "    (doc_encoder): DocEncoder(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Dropout(p=0.1749, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (numeric_encoder): NumericEncoder(\n",
      "      (sentiment_embedding): Embedding(3, 96)\n",
      "      (read_time_embedding): Embedding(3, 96)\n",
      "      (pageview_embedding): Embedding(3, 96)\n",
      "      (output_projection): Linear(in_features=288, out_features=96, bias=True)\n",
      "    )\n",
      "    (feature_fusion): FeatureFusion(\n",
      "      (linears): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (1): Linear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (gates): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "        (1): Linear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (time_discount): TimeDiscount(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (userencoder): UserEncoderDocVec(\n",
      "    (titleencoder): NewsEncoderDocVec(\n",
      "      (doc_encoder): DocEncoder(\n",
      "        (layer): Sequential(\n",
      "          (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Dropout(p=0.1749, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (numeric_encoder): NumericEncoder(\n",
      "        (sentiment_embedding): Embedding(3, 96)\n",
      "        (read_time_embedding): Embedding(3, 96)\n",
      "        (pageview_embedding): Embedding(3, 96)\n",
      "        (output_projection): Linear(in_features=288, out_features=96, bias=True)\n",
      "      )\n",
      "      (feature_fusion): FeatureFusion(\n",
      "        (linears): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "          (1): Linear(in_features=96, out_features=96, bias=True)\n",
      "        )\n",
      "        (gates): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "          (1): Linear(in_features=96, out_features=96, bias=True)\n",
      "        )\n",
      "        (activation): Sigmoid()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (time_discount): TimeDiscount(\n",
      "        (layer): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (multihead_attention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (attention_layer): AttLayer2(\n",
      "      (V_w): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (q_w): Linear(in_features=96, out_features=1, bias=False)\n",
      "    )\n",
      "    (user_projection): Linear(in_features=96, out_features=96, bias=True)\n",
      "    (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (time_discount): TimeDiscount(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer: newsencoder.doc_encoder.layer.0.weight | Size: torch.Size([128, 300])\n",
      "Layer: newsencoder.doc_encoder.layer.0.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.doc_encoder.layer.2.weight | Size: torch.Size([128])\n",
      "Layer: newsencoder.doc_encoder.layer.2.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.numeric_encoder.sentiment_embedding.weight | Size: torch.Size([3, 96])\n",
      "Layer: newsencoder.numeric_encoder.read_time_embedding.weight | Size: torch.Size([3, 96])\n",
      "Layer: newsencoder.numeric_encoder.pageview_embedding.weight | Size: torch.Size([3, 96])\n",
      "Layer: newsencoder.numeric_encoder.output_projection.weight | Size: torch.Size([96, 288])\n",
      "Layer: newsencoder.numeric_encoder.output_projection.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.feature_fusion.linears.0.weight | Size: torch.Size([96, 128])\n",
      "Layer: newsencoder.feature_fusion.linears.0.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.feature_fusion.linears.1.weight | Size: torch.Size([96, 96])\n",
      "Layer: newsencoder.feature_fusion.linears.1.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.feature_fusion.gates.0.weight | Size: torch.Size([96, 128])\n",
      "Layer: newsencoder.feature_fusion.gates.0.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.feature_fusion.gates.1.weight | Size: torch.Size([96, 96])\n",
      "Layer: newsencoder.feature_fusion.gates.1.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.layer_norm.weight | Size: torch.Size([96])\n",
      "Layer: newsencoder.layer_norm.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.time_discount.layer.0.weight | Size: torch.Size([1, 1])\n",
      "Layer: newsencoder.time_discount.layer.0.bias | Size: torch.Size([1])\n",
      "Layer: userencoder.self_attention.multihead_attention.in_proj_weight | Size: torch.Size([288, 96])\n",
      "Layer: userencoder.self_attention.multihead_attention.in_proj_bias | Size: torch.Size([288])\n",
      "Layer: userencoder.self_attention.multihead_attention.out_proj.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.self_attention.multihead_attention.out_proj.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.attention_layer.V_w.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.attention_layer.V_w.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.attention_layer.q_w.weight | Size: torch.Size([1, 96])\n",
      "Layer: userencoder.user_projection.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.user_projection.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.layer_norm.weight | Size: torch.Size([96])\n",
      "Layer: userencoder.layer_norm.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.time_discount.layer.0.weight | Size: torch.Size([1, 1])\n",
      "Layer: userencoder.time_discount.layer.0.bias | Size: torch.Size([1])\n",
      "\n",
      "Total parameters: 167,140\n"
     ]
    }
   ],
   "source": [
    "# 1. Print model architecture\n",
    "print(model)\n",
    "\n",
    "# 2. Print specific layer sizes\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")\n",
    "\n",
    "# 3. Get total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "\n",
    "# 4. Print layer by layer with shapes\n",
    "def print_model_structure(model):\n",
    "    print(\"\\nDetailed Model Structure:\")\n",
    "    for name, module in model.named_children():\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Type: {type(module).__name__}\")\n",
    "        if hasattr(module, 'weight'):\n",
    "            print(f\"Shape: {module.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Added gradient clipping to avoid exploiding gradients. The paramter MAX_GRAD_NORM is set to 5.0 as this is a common value used in transformers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperoptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# NUM_EPOCHS = 15\n",
    "# WEIGHT_DECAY = 1e-3\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define fixed valid head numbers\n",
    "#     possible_head_nums = [2, 4, 8, 16, 32]\n",
    "    \n",
    "#     # First suggest head_num from fixed choices\n",
    "#     head_num = trial.suggest_categorical('head_num', possible_head_nums)\n",
    "    \n",
    "#     # Suggest shared_dim that's divisible by head_num\n",
    "#     min_dim = max(64, head_num)  # Ensure minimum dimension works with head_num\n",
    "#     max_dim = 256\n",
    "#     shared_dim = trial.suggest_int('shared_dim', min_dim, max_dim)\n",
    "    \n",
    "#     # Round shared_dim to nearest multiple of head_num\n",
    "#     shared_dim = (shared_dim // head_num) * head_num\n",
    "    \n",
    "#     # Skip if dimensions don't work\n",
    "#     if shared_dim < head_num:\n",
    "#         raise optuna.TrialPruned()\n",
    "    \n",
    "#     hparams = {\n",
    "#         'title_size': 300,\n",
    "#         'head_num': head_num,\n",
    "#         'head_dim': shared_dim,\n",
    "#         'attention_hidden_dim':shared_dim,\n",
    "#         'news_output_dim': shared_dim,\n",
    "#         'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n",
    "#         'weight_decay': trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True),\n",
    "#         'units_per_layer': [\n",
    "#             trial.suggest_int('unit_layer_1', 256, 512),\n",
    "#             trial.suggest_int('unit_layer_2', 256, 512),\n",
    "#         ],\n",
    "#         'use_category': trial.suggest_categorical('use_category', [True, False]),\n",
    "#         'use_topic': trial.suggest_categorical('use_topic', [True, False]),\n",
    "#         'use_numeric': trial.suggest_categorical('use_numeric', [True, False]),\n",
    "#         'use_publication_discount': trial.suggest_categorical('use_publication_discount', [True, False]),\n",
    "#         'use_session_discount': trial.suggest_categorical('use_session_discount', [True, False])\n",
    "#     }\n",
    "\n",
    "#     # Initialize model and training components\n",
    "#     model = NRMSDocVecModel(hparams=hparams, device=device)\n",
    "#     criterion = model.get_loss().to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), \n",
    "#                           lr=hparams['learning_rate'], \n",
    "#                           weight_decay=hparams['weight_decay'])\n",
    "    \n",
    "#     # Initialize EarlyStopping\n",
    "#     early_stopping = EarlyStopping(patience=4, min_delta=0.025, verbose=True)\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         train_batch_count = 0\n",
    "\n",
    "#         for batch in train_dataloader_temp:\n",
    "#             inputs, targets, impression_id = batch\n",
    "#             inputs = [inp.to(device) for inp in inputs]\n",
    "#             targets = targets.to(device)\n",
    "#             positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#             targets = positive_indices[:, 1].long()\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(*inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             train_batch_count += 1\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         val_batch_count = 0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_dataloader_temp:\n",
    "#                 inputs, targets, impression_id = batch\n",
    "#                 inputs = [inp.to(device) for inp in inputs]\n",
    "#                 targets = targets.to(device)\n",
    "#                 positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#                 targets = positive_indices[:, 1].long()\n",
    "#                 outputs = model(*inputs)\n",
    "#                 loss = criterion(outputs, targets)\n",
    "#                 val_loss += loss.item()\n",
    "#                 val_batch_count += 1\n",
    "\n",
    "#         avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "\n",
    "#         # Update best validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "\n",
    "#         # Early stopping check\n",
    "#         early_stopping(avg_val_loss)\n",
    "#         if early_stopping.early_stop:\n",
    "#             break\n",
    "\n",
    "#         # Report to Optuna\n",
    "#         trial.report(avg_val_loss, epoch)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "\n",
    "#     return best_val_loss\n",
    "\n",
    "# # Create study and optimize\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=20)  # Increased from 3 to 50 trials\n",
    "\n",
    "# # Print results\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value) #\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/50 [00:00<?, ?it/s]c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\models_pytorch\\NRMSDocVecModel.py:363: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Training Progress:   4%|▍         | 2/50 [00:41<16:28, 20.60s/it, train_loss=1.6765, val_loss=4.3079]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 3/50 [01:01<16:00, 20.43s/it, train_loss=1.5858, val_loss=4.3782]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 4/50 [01:22<15:37, 20.38s/it, train_loss=1.5564, val_loss=4.2728]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  14%|█▍        | 7/50 [02:23<14:35, 20.36s/it, train_loss=1.5203, val_loss=3.6150]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 8/50 [02:43<14:15, 20.36s/it, train_loss=1.5099, val_loss=4.1574]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  16%|█▌        | 8/50 [02:47<14:39, 20.95s/it, train_loss=1.5099, val_loss=4.1574]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 87\u001b[0m\n\u001b[0;32m     85\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     86\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 87\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Gradient clipping\u001b[39;00m\n\u001b[0;32m     88\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     90\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\.venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:30\u001b[0m, in \u001b[0;36m_no_grad.<locals>._no_grad_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_no_grad_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\.venv\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:86\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_grads], _) \u001b[38;5;129;01min\u001b[39;00m grouped_grads\u001b[38;5;241m.\u001b[39mitems():  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_grads, device)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     84\u001b[0m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[0;32m     85\u001b[0m     ):\n\u001b[1;32m---> 86\u001b[0m         norms\u001b[38;5;241m.\u001b[39mextend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     89\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforeach=True was passed, but can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure you have defined or imported the EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif current_score < self.best_score - self.min_delta:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Define model_checkpoint function if not already defined\n",
    "def model_checkpoint(model, val_loss, epoch, path='model_checkpoint.pth'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "    }, path)\n",
    "    print(f\"Model checkpoint saved at epoch {epoch} with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "# Initialize components\n",
    "NUM_EPOCHS = 50\n",
    "early_stopping = EarlyStopping(patience=4, min_delta=0.025, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Use appropriate loss function\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=hparams_nrms.learning_rate,  # Ensure hparams_nrms is defined and has learning_rate\n",
    "    weight_decay=hparams_nrms.weight_decay  # Ensure hparams_nrms has weight_decay\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Ensure your dataloaders are defined\n",
    "# train_dataloader_temp = ...\n",
    "# val_dataloader_temp = ...\n",
    "\n",
    "epoch_pbar = tqdm(range(1, NUM_EPOCHS + 1), desc=\"Training Progress\", dynamic_ncols=True)\n",
    "for epoch in epoch_pbar:\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch in train_dataloader_temp:\n",
    "        inputs, targets, _ = batch  # Assuming the third element is not used\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Extract positive indices\n",
    "        positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "        if positive_indices.numel() == 0:\n",
    "            raise ValueError(\"No positive samples in the batch\")\n",
    "            continue  # Skip if no positive samples in the batch\n",
    "        targets = positive_indices[:, 1].long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs)  # Shape: (N, C)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    avg_train_loss = running_loss / train_batch_count if train_batch_count > 0 else float('inf')\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader_temp:\n",
    "            inputs, targets, _ = batch\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "            if positive_indices.numel() == 0:\n",
    "                continue\n",
    "            targets = positive_indices[:, 1].long()\n",
    "\n",
    "            outputs = model(*inputs)  # Shape: (N, C)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_batch_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Logging\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "\n",
    "    # Update Progress Bar\n",
    "    epoch_pbar.set_postfix({\n",
    "        'train_loss': f'{avg_train_loss:.4f}',\n",
    "        'val_loss': f'{avg_val_loss:.4f}',\n",
    "    })\n",
    "\n",
    "    # Save Checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        model_checkpoint(model, avg_val_loss, epoch)\n",
    "\n",
    "    # Scheduler Step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Summary:\n",
      "Initial Training Loss: 3.3091\n",
      "Final Training Loss: 1.5099\n",
      "Best Training Loss: 1.5099\n",
      "\n",
      "Initial Validation Loss: 4.1673\n",
      "Final Validation Loss: 4.1574\n",
      "Best Validation Loss: 3.4326\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"nrms_training_loss.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print final statistics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Initial Training Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Training Loss: {min(train_losses):.4f}\")\n",
    "print(f\"\\nInitial Validation Loss: {val_losses[0]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Validation Loss: {min(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def evaluate_model(model, dataloader, device):\n",
    "#     \"\"\"Evaluate the model and return predictions and labels for metric calculation.\"\"\"\n",
    "#     model.eval()\n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     print(\"\\nEvaluating DataLoader...\")\n",
    "#     total_samples = len(dataloader.dataset)\n",
    "#     print(f\"Total samples in DataLoader: {total_samples}\")\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets, impression_ids) in enumerate(dataloader):\n",
    "#             his_input_title, pred_input_title = inputs\n",
    "\n",
    "#             if batch_idx == 0:  # Debug first batch shapes\n",
    "#                 print(\"\\nFirst batch shapes:\")\n",
    "#                 print(f\"  - his_input_title: {his_input_title.shape}\")\n",
    "#                 print(f\"  - pred_input_title: {pred_input_title.shape}\")\n",
    "#                 print(f\"  - targets: {targets.shape}\")\n",
    "\n",
    "#             # Move data to device\n",
    "#             his_input_title = his_input_title.to(device)\n",
    "#             pred_input_title = pred_input_title.to(device)\n",
    "#             targets = targets.to(device)\n",
    "\n",
    "#             # Get predictions\n",
    "#             predictions = model.predict(his_input_title, pred_input_title)\n",
    "#             predictions = predictions.cpu().numpy()\n",
    "#             targets = targets.cpu().numpy()\n",
    "\n",
    "#             # Process each sample in the batch\n",
    "#             batch_size = predictions.shape[0]\n",
    "#             for sample_idx in range(batch_size):\n",
    "#                 pred = predictions[sample_idx]\n",
    "#                 label = targets[sample_idx]\n",
    "\n",
    "#                 # Create valid_mask where label is not equal to the padding value (-1)\n",
    "#                 valid_mask = (label != -1)\n",
    "#                 sample_preds = pred[valid_mask]\n",
    "#                 sample_labels = label[valid_mask]\n",
    "\n",
    "#                 if len(sample_labels) == 0:\n",
    "#                     continue  # Skip empty samples\n",
    "\n",
    "#                 # Ensure that there is at least one positive and one negative label\n",
    "#                 if len(np.unique(sample_labels)) < 2:\n",
    "#                     continue  # Skip samples with only one class\n",
    "\n",
    "#                 all_predictions.append(sample_preds.tolist())\n",
    "#                 all_labels.append(sample_labels.tolist())\n",
    "\n",
    "#     print(\"\\nEvaluation completed.\")\n",
    "#     print(f\"Total predictions generated: {len(all_predictions)}\")\n",
    "#     print(f\"First few prediction lengths: {[len(x) for x in all_predictions[:15]]}\")\n",
    "#     return all_labels, all_predictions\n",
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# labels_list, scores_list = evaluate_model(model, val_dataloader_temp, device)\n",
    "\n",
    "# # Validate predictions against the DataFrame\n",
    "# print(\"\\nValidation against DataFrame:\")\n",
    "# if len(scores_list) != len(df_validation):\n",
    "#     print(\"WARNING: Length mismatch!\")\n",
    "#     print(f\"  - Number of predictions: {len(scores_list)}\")\n",
    "#     print(f\"  - Number of rows in DataFrame: {len(df_validation)}\")\n",
    "\n",
    "# # Compute metrics\n",
    "# metrics = MetricEvaluator(\n",
    "#     labels=labels_list,\n",
    "#     predictions=scores_list,\n",
    "#     metric_functions=[\n",
    "#         AucScore(),\n",
    "#         MrrScore(),\n",
    "#         NdcgScore(k=5),\n",
    "#         NdcgScore(k=10)\n",
    "#     ],\n",
    "# )\n",
    "# results = metrics.evaluate()\n",
    "# print(\"\\nMetrics:\", results.evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRACTION: 0.1, HISTORY_SIZE: 20\n",
      "Hyperparameters:\n",
      "title_size: 300\n",
      "embedding_dim: 32\n",
      "word_emb_dim: 8\n",
      "vocab_size: 10000\n",
      "head_num: 16\n",
      "head_dim: 96\n",
      "attention_hidden_dim: 96\n",
      "hidden_dim: 4\n",
      "optimizer: adam\n",
      "loss: cross_entropy_loss\n",
      "dropout: 0.1749\n",
      "learning_rate: 1.0454050068420554e-05\n",
      "weight_decay: 0.006587407554797856\n",
      "news_output_dim: 96\n",
      "units_per_layer: [421, 386]\n",
      "use_category: False\n",
      "use_topic: False\n",
      "use_numeric: True\n",
      "use_session_discount: True\n",
      "use_publication_discount: True\n",
      "doc_out_dim: 128\n",
      "cat_out_dim: 128\n",
      "top_out_dim: 128\n",
      "numeric_proj_dim: 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"FRACTION: {FRACTION}, HISTORY_SIZE: {HISTORY_SIZE}\")\n",
    "\n",
    "# Filter out special Python attributes and print parameters\n",
    "params = {k: v for k, v in hparams_nrms.__dict__.items() if not k.startswith('__')}\n",
    "print(\"Hyperparameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_labels(df: pl.DataFrame, impression_id: int) -> int:\n",
    "    # Filter for matching impression_id\n",
    "    filtered = df.filter(pl.col('impression_id') == impression_id)\n",
    "    \n",
    "    if filtered.height == 0:\n",
    "        raise ValueError(f\"No row found for impression_id {impression_id}\")\n",
    "    \n",
    "    # Get labels from first row\n",
    "    labels = filtered.select('labels').row(0)[0]\n",
    "    \n",
    "    return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_length_of_labels(df_validation, 349992000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [0, 1, 0, 0, 0]\n",
      "Label 1: [0, 0, 0, 1, 0]\n",
      "Label 2: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label 3: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "Label 4: [0, 0, 0, 0, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 labels\n",
    "first_5_labels = df_validation.select('labels').head(5)\n",
    "\n",
    "# Print each label with index\n",
    "for i, row in enumerate(first_5_labels.iter_rows()):\n",
    "    print(f\"Label {i}: {row[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples with only one class\n",
      "Remaining valid samples: 24302\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize lists\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "skipped_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader_temp:\n",
    "        inputs, targets, impression_ids = batch\n",
    "        \n",
    "        # Move to device\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(*inputs)\n",
    "        \n",
    "        # Convert to probabilities if needed\n",
    "        if not torch.is_floating_point(predictions):\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Convert to lists while preserving structure\n",
    "        batch_preds = predictions.cpu().numpy().tolist()\n",
    "        batch_labels = targets.cpu().numpy().tolist()\n",
    "        impression_ids = impression_ids.cpu().numpy().tolist()\n",
    "        \n",
    "        batch_preds_without_padding = []\n",
    "        batch_labels_without_padding = []\n",
    "        \n",
    "        for pred_sample, label_sample, impression_id_sample in zip(batch_preds, batch_labels, impression_ids):\n",
    "            # Remove padding\n",
    "            actual_length = get_length_of_labels(df_validation, impression_id_sample)\n",
    "            pred_sample = pred_sample[:actual_length]\n",
    "            \n",
    "            # Check if sample has both classes before adding\n",
    "            if 1 in label_sample[:actual_length] and 0 in label_sample[:actual_length]:\n",
    "                batch_preds_without_padding.append(pred_sample)\n",
    "                batch_labels_without_padding.append(label_sample[:actual_length])\n",
    "            else:\n",
    "                skipped_samples += 1\n",
    "        \n",
    "        # Add batch predictions and labels\n",
    "        all_predictions.extend(batch_preds_without_padding)\n",
    "        all_labels.extend(batch_labels_without_padding)\n",
    "\n",
    "print(f\"Skipped {skipped_samples} samples with only one class\")\n",
    "print(f\"Remaining valid samples: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug: Print label distribution for first 5 samples\n",
    "# for i, (preds, labels) in enumerate(zip(all_predictions[:5], all_labels[:5])):\n",
    "#     print(f\"\\nSample {i}:\")\n",
    "#     print(f\"Labels length:      {len(labels)}\")\n",
    "#     print(f\"Predictions length: {len(preds)}\")\n",
    "#     print(f\"Num positives: {sum(labels)}\")\n",
    "#     print(f\"Num negatives: {len(labels) - sum(labels)}\")\n",
    "#     print(f\"Label distribution: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(all_predictions))\n",
    "# print(type(all_labels))\n",
    "\n",
    "# print(f\"Number of predictions: {len(all_predictions)}\")\n",
    "# print(f\"example prediction: {all_predictions[0:2]}\")\n",
    "# print(f\"Number of labels: {len(all_labels)}\")\n",
    "# print(f\"example label: {all_labels[0:2]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1166\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "correct_predictions = 0\n",
    "total_samples = len(all_predictions)\n",
    "\n",
    "# Iterate over samples\n",
    "for idx, _ in enumerate(all_predictions):\n",
    "    # print(f\"Sample {idx}: Prediction: {all_predictions[idx]}\")\n",
    "    # print(f\"Sample {idx}: Label:      {all_labels[idx]}\")\n",
    "    \n",
    "    # Extract index of maximum value in predictions and labels\n",
    "    pred_max_index = np.argmax(all_predictions[idx])\n",
    "    label_max_index = np.argmax(all_labels[idx])\n",
    "    \n",
    "    # Compare indices to determine if the prediction was correct\n",
    "    if pred_max_index == label_max_index:\n",
    "        # print(f\"Sample {idx}: Prediction was correct.\")\n",
    "        correct_predictions += 1\n",
    "  #  else:\n",
    "        # print(f\"Sample {idx}: Prediction was wrong.\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.5001\n",
      "Number of valid AUC calculations: 24302\n"
     ]
    }
   ],
   "source": [
    "from evaluation import AucScore\n",
    "\n",
    "# auc_score = AucScore()\n",
    "\n",
    "# auc_score.calculate(all_predictions, all_labels)\n",
    "# print(f\"AUC: {auc_score.score}\")\n",
    "# # Calculate AUC per sample\n",
    "aucs = []\n",
    "for preds, labels in zip(all_predictions, all_labels):\n",
    "    try:\n",
    "        # Only calculate if we have both positive and negative samples\n",
    "        if sum(labels) > 0 and sum(labels) < len(labels):\n",
    "            auc = roc_auc_score(labels, preds)\n",
    "            aucs.append(auc)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Only one class present in labels. Cannot calculate AUC.\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(aucs):.4f}\")\n",
    "print(f\"Number of valid AUC calculations: {len(aucs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
