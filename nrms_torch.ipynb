{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Python version: 3.10.12\n",
      "PyTorch version: 2.4.1+cu124\n",
      "CUDA available: True\n",
      "Current GPU device: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL\n",
    ")\n",
    "\n",
    "from utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from utils._articles import convert_text2encoding_with_transformers\n",
    "from utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from utils._articles import create_article_id_to_value_mapping\n",
    "from utils._nlp import get_transformers_word_embeddings, generate_embeddings_with_transformers\n",
    "from utils._python import write_submission_file, rank_predictions_by_score\n",
    "from models_pytorch.model_config import hparams_nrms\n",
    "\n",
    "from models_pytorch.nrms import NRMSModel\n",
    "from models_pytorch.NRMSDocVecModel import NRMSDocVecModel\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from models_pytorch.dataloader import NRMSDataSet\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 64\n",
    "\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at behaviours and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebnerd_small\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"./ebnerd_small\")  # Base path for your data directory\n",
    "print(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>1786598</td><td>[9767268, 9766949, … 9768150]</td><td>[9774541, 8054212, … 9771197]</td><td>[9758424]</td><td>115321442</td><td>[0, 0, … 0]</td></tr><tr><td>956287</td><td>[9769553, 9770867, … 9769712]</td><td>[9432542, 9432542, … 9770051]</td><td>[9770051]</td><td>57777590</td><td>[0, 0, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 1786598 ┆ [9767268,         ┆ [9774541,         ┆ [9758424]        ┆ 115321442     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9766949, …        ┆ 8054212, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9768150]          ┆ 9771197]          ┆                  ┆               ┆             │\n",
       "│ 956287  ┆ [9769553,         ┆ [9432542,         ┆ [9770051]        ┆ 57777590      ┆ [0, 0, … 1] │\n",
       "│         ┆ 9770867, …        ┆ 9432542, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9769712]          ┆ 9770051]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 90 # TODO: History size. \n",
    "FRACTION = 0.1\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of article_ids_inview in df_train: 5.0\n",
      "Average length of article_ids_inview in df_validation: 12.000449631098121\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_length(df, column):\n",
    "    total_length = sum(len(row) for row in df[column])\n",
    "    average_length = total_length / len(df)\n",
    "    return average_length\n",
    "\n",
    "# Calculate average length for df_train\n",
    "average_length_inview_train = calculate_average_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_train: {average_length_inview_train}\")\n",
    "\n",
    "# Calculate average length for df_validation\n",
    "average_length_inview_validation = calculate_average_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_validation: {average_length_inview_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest inview article length in df_train: 5\n",
      "Longest inview article length in df_validation: 91\n",
      "Longest history length in df_train: 10\n",
      "Longest history length in df_validation: 10\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Function to find the maximum length of arrays in a column\n",
    "def find_max_length(df, column):\n",
    "    max_length = 0\n",
    "    for row in df[column]:\n",
    "        max_length = max(max_length, len(row))\n",
    "    return max_length\n",
    "\n",
    "# Find the longest inview article length in df_train\n",
    "max_inview_length_train = find_max_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "# Find the longest inview article length in df_validation\n",
    "max_inview_length_validation = find_max_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "print(f\"Longest inview article length in df_train: {max_inview_length_train}\")\n",
    "print(f\"Longest inview article length in df_validation: {max_inview_length_validation}\")\n",
    "\n",
    "max_history_length_train = find_max_length(df_train, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "max_history_length_validation = find_max_length(df_validation, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "\n",
    "print(f\"Longest history length in df_train: {max_history_length_train}\")\n",
    "print(f\"Longest history length in df_validation: {max_history_length_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with exactly one clicked article in df_train: 46855\n",
      "Number of rows with exactly one clicked article in df_validation: 48635\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Function to filter rows with exactly one clicked article\n",
    "def filter_rows_with_one_clicked_article(df, clicked_articles_col):\n",
    "    # Manually filter rows where the array has exactly one element\n",
    "    filtered_rows = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        if len(row[clicked_articles_col]) == 1:\n",
    "            filtered_rows.append(row)\n",
    "    return pl.DataFrame(filtered_rows)\n",
    "\n",
    "\n",
    "# Filter rows in df_train and df_validation\n",
    "df_train = filter_rows_with_one_clicked_article(df_train, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "df_validation = filter_rows_with_one_clicked_article(df_validation, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of rows with exactly one clicked article in df_train: {df_train.shape[0]}\")\n",
    "print(f\"Number of rows with exactly one clicked article in df_validation: {df_validation.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>2364288</td><td>[9779867, 9778939, … 9779427]</td><td>[9780195, 9787767, … 9788797]</td><td>[9788038]</td><td>489703093</td><td>[0, 0, … 0]</td></tr><tr><td>1608694</td><td>[9778645, 9778915, … 9777910]</td><td>[9783904, 9782770, … 9783752]</td><td>[9783655]</td><td>289124204</td><td>[0, 0, … 0]</td></tr><tr><td>692325</td><td>[9776099, 9775673, … 9779186]</td><td>[9782745, 9782973, … 9783019]</td><td>[9782899]</td><td>573164560</td><td>[0, 0, … 0]</td></tr><tr><td>333882</td><td>[9778939, 9779705, … 9777910]</td><td>[9784662, 9783865, … 9784559]</td><td>[9784662]</td><td>364662416</td><td>[1, 0, … 0]</td></tr><tr><td>874547</td><td>[9775596, 9778915, … 9779538]</td><td>[9787243, 9787098, … 9787332]</td><td>[9787301]</td><td>362860503</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ i64     ┆ list[i64]         ┆ ---               ┆ ---              ┆ i64           ┆ list[i64]   │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 2364288 ┆ [9779867,         ┆ [9780195,         ┆ [9788038]        ┆ 489703093     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778939, …        ┆ 9787767, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9779427]          ┆ 9788797]          ┆                  ┆               ┆             │\n",
       "│ 1608694 ┆ [9778645,         ┆ [9783904,         ┆ [9783655]        ┆ 289124204     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778915, …        ┆ 9782770, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9777910]          ┆ 9783752]          ┆                  ┆               ┆             │\n",
       "│ 692325  ┆ [9776099,         ┆ [9782745,         ┆ [9782899]        ┆ 573164560     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9775673, …        ┆ 9782973, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9779186]          ┆ 9783019]          ┆                  ┆               ┆             │\n",
       "│ 333882  ┆ [9778939,         ┆ [9784662,         ┆ [9784662]        ┆ 364662416     ┆ [1, 0, … 0] │\n",
       "│         ┆ 9779705, …        ┆ 9783865, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9777910]          ┆ 9784559]          ┆                  ┆               ┆             │\n",
       "│ 874547  ┆ [9775596,         ┆ [9787243,         ┆ [9787301]        ┆ 362860503     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778915, …        ┆ 9787098, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9779538]          ┆ 9787332]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in df_train: 11323\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users in df_train: {df_train['user_id'].n_unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>2007-03-27 10:22:08</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>2001-10-19 12:30:00</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>2003-01-09 06:00:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>2003-06-17 07:10:00</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>2003-07-13 19:50:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "DataFrame after tokenization:\n",
      "shape: (20_738, 21)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
      "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
      "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
      "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
      "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
      "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
      "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
      "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
      "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ 9803492   ┆ Vilde     ┆ Der er    ┆ 2023-06-2 ┆ … ┆ 100120    ┆ 4.112624e ┆ 0.6095    ┆ Neutral  │\n",
      "│           ┆ billeder: ┆ gang i    ┆ 9         ┆   ┆           ┆ 6         ┆           ┆          │\n",
      "│           ┆ Vulkan i  ┆ vulkanen  ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ udbru…    ┆ på Hawa…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803505   ┆ Flyvende  ┆ Verdens   ┆ 2023-06-2 ┆ … ┆ 959       ┆ 55691.0   ┆ 0.8884    ┆ Positive │\n",
      "│           ┆ Antonsen  ┆ nummer    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ knuser    ┆ syv, Chou ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ topsp…    ┆ Tien-…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803525   ┆ Dansk sku ┆ Julie R.  ┆ 2023-06-2 ┆ … ┆ 50361     ┆ 2.550671e ┆ 0.7737    ┆ Negative │\n",
      "│           ┆ espiller: ┆ Ølgaard   ┆ 9         ┆   ┆           ┆ 6         ┆           ┆          │\n",
      "│           ┆ - Jeg     ┆ fik akut  ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ nægte…    ┆ kejs…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803560   ┆ Så slemt  ┆ Tusindvis ┆ 2023-06-2 ┆ … ┆ 1237      ┆ 67514.0   ┆ 0.9927    ┆ Negative │\n",
      "│           ┆ er det:   ┆ af huse   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ 14.000    ┆ står      ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ huse e…   ┆ under v…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803607   ┆ Aktion    ┆ Flere     ┆ 2023-06-2 ┆ … ┆ 79590     ┆ 3.69476e6 ┆ 0.9948    ┆ Negative │\n",
      "│           ┆ mod svind ┆ kvinder   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ lere:     ┆ er ifølge ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Seks per… ┆ politi…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# LOAD HUGGINGFACE and move to device immediately:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME).to(device)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# # We'll init the word embeddings using the\n",
    "# word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "\n",
    "# # Concatenate text columns\n",
    "# df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "\n",
    "# # Get tokenized version\n",
    "# df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "#     df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    "# )\n",
    "\n",
    "print(\"DataFrame after tokenization:\")\n",
    "print(df_articles)\n",
    "\n",
    "# print(df_articles[token_col_title][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding tokenized article title + subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 649/649 [00:20<00:00, 31.98text/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from utils._python import batch_items_generator\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "n_batches = int(np.ceil(df_articles.height / BATCH_SIZE))\n",
    "\n",
    "chunked_text_list = batch_items_generator(df_articles[DEFAULT_TITLE_COL].to_list(), BATCH_SIZE)\n",
    "embeddings = (\n",
    "    generate_embeddings_with_transformers(\n",
    "        model=transformer_model,\n",
    "        tokenizer=transformer_tokenizer,\n",
    "        text_list=text_list,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "    for text_list in tqdm(\n",
    "        chunked_text_list, desc=\"Encoding\", total=n_batches, unit=\"text\"\n",
    "    )\n",
    ")\n",
    "embeddings = torch.vstack(list(embeddings))\n",
    "\n",
    "embedded_title = f\"{DEFAULT_TITLE_COL}_embedded\"\n",
    "\n",
    "df_articles = df_articles.with_columns(pl.Series(embedded_title, embeddings.to(\"cpu\").numpy()))\n",
    "\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=embedded_title\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset_selective -f torch*  # Clears torch-related variables\n",
    "# %reset_selective -f batch*  # Clears batch-related variables\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# import gc\n",
    "\n",
    "# # Define batch size based on your GPU memory\n",
    "# batch_size = 128  \n",
    "# token_list = df_articles[token_col_title].to_list()\n",
    "\n",
    "# # Calculate total number of batches\n",
    "# num_batches = (len(token_list) + batch_size - 1) // batch_size\n",
    "\n",
    "# # Create progress bar for batches\n",
    "# batch_pbar = tqdm(range(0, len(token_list), batch_size), \n",
    "#                   desc=\"Processing Batches\", \n",
    "#                   total=num_batches,\n",
    "#                   dynamic_ncols=True)\n",
    "\n",
    "# all_embeddings = []\n",
    "\n",
    "# # Function to clear GPU memory\n",
    "# def clear_gpu():\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect()\n",
    "\n",
    "# from contextlib import contextmanager\n",
    "\n",
    "# @contextmanager\n",
    "# def gpu_cleanup():\n",
    "#     try:\n",
    "#         yield\n",
    "#     finally:\n",
    "#         torch.cuda.empty_cache()\n",
    "#         gc.collect()\n",
    "\n",
    "# with gpu_cleanup():\n",
    "#     for i in batch_pbar:\n",
    "#         # Get batch tokens\n",
    "#         batch_tokens = token_list[i:i + batch_size]\n",
    "#         # Convert to tensor and move to GPU\n",
    "#         batch_tensor = torch.tensor(batch_tokens, device=device)\n",
    "        \n",
    "#         # Get embeddings\n",
    "#         with torch.no_grad():\n",
    "#             outputs = transformer_model(batch_tensor)\n",
    "#             # Apply mean pooling over sequence length dimension\n",
    "#             batch_embeddings = outputs.last_hidden_state.mean(dim=1)  # Shape: (batch_size, hidden_size)\n",
    "#             batch_embeddings = batch_embeddings.cpu().numpy()\n",
    "        \n",
    "#         all_embeddings.append(batch_embeddings)\n",
    "        \n",
    "#         # Update progress bar\n",
    "#         batch_pbar.set_description(f\"Processing Batch {i//batch_size + 1}/{num_batches}\")\n",
    "\n",
    "# # Concatenate all embeddings into a single NumPy array\n",
    "# all_embeddings = np.concatenate(all_embeddings, axis=0)  # Shape: (num_articles, hidden_size)\n",
    "\n",
    "# embedded_title = f\"{token_col_title}_embedded\"\n",
    "\n",
    "# # Convert embeddings to list of lists\n",
    "# embedding_list = all_embeddings.tolist()\n",
    "\n",
    "# Add embeddings as a new column to the DataFrame\n",
    "# df_articles = df_articles.with_columns(pl.Series(embedded_title, embeddings))\n",
    "\n",
    "# print(\"\\nDataFrame after adding embeddings:\")\n",
    "# print(df_articles)\n",
    "\n",
    "# article_mapping = create_article_id_to_value_mapping(\n",
    "    # df=df_articles, value_col=embedded_title\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 20738\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of articles: {len(article_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"word embeddings shape: {word2vec_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "Data preprocessing completed in 6.84 seconds.\n",
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "Data preprocessing completed in 9.02 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NRMSDataSet(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    ")\n",
    "val_dataset = NRMSDataSet(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(5):\n",
    "#     sample = train_dataset[idx]\n",
    "#     print(f\"Sample {idx}:\")\n",
    "#     print(f\"his_input_title shape: {sample[0][0].shape}\")\n",
    "#     print(f\"pred_input_title shape: {sample[0][1].shape} {sample[0][1].sum()}\")\n",
    "#     print(f\"Targets shape: {sample[1].shape} , {sample[1].dtype} {sample[1].sum()}\")\n",
    "#     print(f\"impression id: {sample[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_fn_with_global_padding(batch, max_len_pred, apply_padding_to_targets : bool = True):\n",
    "    try:\n",
    "        his_input_titles = [item[0][0] for item in batch]  # History inputs\n",
    "        pred_input_titles = [item[0][1] for item in batch]  # Prediction inputs\n",
    "        batch_ys = [item[1] for item in batch]  # Targets\n",
    "        impression_id = torch.tensor([item[2] for item in batch], dtype=torch.int64)  # Impression ID\n",
    "        \n",
    "\n",
    "        # Pad sequences to the global maximum length\n",
    "        his_input_titles_padded = pad_sequence(his_input_titles, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Pad prediction inputs and adjust to the global maximum length\n",
    "        pred_input_titles_padded = pad_sequence(pred_input_titles, batch_first=True, padding_value=0)\n",
    "        if pred_input_titles_padded.size(1) < max_len_pred:\n",
    "            # Add padding if sequence length is shorter than max_len_pred\n",
    "            pad_size = max_len_pred - pred_input_titles_padded.size(1)\n",
    "            pred_input_titles_padded = torch.nn.functional.pad(\n",
    "                pred_input_titles_padded, (0, 0, 0, pad_size), value=0\n",
    "            )\n",
    "        elif pred_input_titles_padded.size(1) > max_len_pred:\n",
    "            # Trim if sequence length exceeds max_len_pred\n",
    "            pred_input_titles_padded = pred_input_titles_padded[:, :max_len_pred, :]\n",
    "\n",
    "        # Pad targets to the global maximum length\n",
    "        if apply_padding_to_targets:\n",
    "            batch_ys_padded = pad_sequence(batch_ys, batch_first=True, padding_value=-1)\n",
    "            if batch_ys_padded.size(1) < max_len_pred:\n",
    "                pad_size = max_len_pred - batch_ys_padded.size(1)\n",
    "                batch_ys_padded = torch.nn.functional.pad(batch_ys_padded, (0, pad_size), value=-1)\n",
    "            elif batch_ys_padded.size(1) > max_len_pred:\n",
    "                batch_ys_padded = batch_ys_padded[:, :max_len_pred]\n",
    "\n",
    "            return (his_input_titles_padded, pred_input_titles_padded), batch_ys_padded, impression_id\n",
    "        else:\n",
    "            return (his_input_titles_padded, pred_input_titles_padded), batch_ys, impression_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the dataset with DataLoader\n",
    "train_dataloader_temp = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,    # Set your desired batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")\n",
    "\n",
    "val_dataloader_temp = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,    # Set your desired batch size\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82, 768])\n",
      "torch.Size([64, 82])\n",
      "tensor([272248569, 244102092, 282629049, 255062578, 496453064, 416293304,\n",
      "        220814840, 354954895,  99099289, 466420914, 420860314, 126381635,\n",
      "        242490747,  82509878, 426705383, 384285653, 544129306, 242323251,\n",
      "        161831124,  31021320, 281368155, 126549607, 494559532, 519313083,\n",
      "        356491099, 374413742, 359431804, 168005081, 520099744,  71883164,\n",
      "        298575960, 315626192, 335236482, 390786051, 353344666, 401453725,\n",
      "        452306163, 151575796, 506698533, 188655914,  66529269,  11409516,\n",
      "        569025947, 328430408, 444809230, 163541058,  69142042, 454353983,\n",
      "        226481666, 221439700, 529621200, 336650316,  50931981, 257465304,\n",
      "        126476704, 479787178,  87112347, 240093657,  63710044, 215154058,\n",
      "        337136967, 317556509, 470834486, 184896457])\n",
      "Batch loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataloader_temp:\n",
    "    (his_input_titles_padded, pred_input_titles_padded), batch_ys_padded, impression_id = batch\n",
    "    print(pred_input_titles_padded.shape)  # Look at one padded sequence\n",
    "    print(batch_ys_padded.shape)  # Look at one padded sequence\n",
    "    print(impression_id)\n",
    "\n",
    "    print(\"Batch loaded successfully!\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data: 100%|██████████| 10/10 [00:00<00:00, 19.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to val_data_small_dataset_with_impression_ids.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Data: 100%|██████████| 10/10 [00:00<00:00, 41.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to train_data_small_dataset_with_impression_ids.pt\n"
     ]
    }
   ],
   "source": [
    "# THIS CODE SHOULD ONLY RUN WHEN GENERATING THE DATA FOR THE FIRST TIME\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to preprocess and save data\n",
    "def preprocess_and_save(dataloader, filepath, device=\"cuda\"):\n",
    "    all_inputs_his = []\n",
    "    all_inputs_pred = []\n",
    "    all_targets = []\n",
    "    all_impression_ids = []\n",
    "\n",
    "    # Iterate over DataLoader and collect data\n",
    "    for (his_inputs, pred_inputs), targets, impressionID in tqdm(dataloader, desc=\"Processing Data\"):\n",
    "        all_inputs_his.append(his_inputs)\n",
    "        all_inputs_pred.append(pred_inputs)\n",
    "        all_targets.append(targets)\n",
    "        all_impression_ids.append(impressionID)\n",
    "\n",
    "    # Concatenate all batches into a single tensor\n",
    "    all_inputs_his = torch.cat(all_inputs_his).to(device)\n",
    "    all_inputs_pred = torch.cat(all_inputs_pred).to(device)\n",
    "    all_targets = torch.cat(all_targets).to(device)\n",
    "    all_impression_ids = torch.cat(all_impression_ids).to(device)\n",
    "\n",
    "    # Save the preprocessed data as a tuple\n",
    "    torch.save((all_inputs_his, all_inputs_pred, all_targets, all_impression_ids), filepath)\n",
    "    print(f\"Data saved to {filepath}\")\n",
    "\n",
    "# Save train and validation data\n",
    "preprocess_and_save(val_dataloader_temp, \"val_data_small_dataset_with_impression_ids.pt\", device=\"cuda\")\n",
    "\n",
    "preprocess_and_save(train_dataloader_temp, \"train_data_small_dataset_with_impression_ids.pt\", device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12021/2176084448.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(filepath)\n"
     ]
    }
   ],
   "source": [
    "def load_preprocessed_data(filepath, device=\"cuda\"):\n",
    "    # Load the data from the .pt file\n",
    "    data = torch.load(filepath)\n",
    "\n",
    "    # Unpack the data\n",
    "    his_inputs, pred_inputs, targets, impression_ids = data\n",
    "\n",
    "    # Move the data to the specified device\n",
    "    his_inputs = his_inputs.to(device, non_blocking=True)\n",
    "    pred_inputs = pred_inputs.to(device, non_blocking=True)\n",
    "    targets = targets.to(device, non_blocking=True)\n",
    "    impression_ids = impression_ids.to(device, non_blocking=True)\n",
    "\n",
    "    return his_inputs, pred_inputs, targets, impression_ids\n",
    "\n",
    "# Example: Load train and validation data\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_his_inputs, train_pred_inputs, train_targets, impression_ids = load_preprocessed_data(\"train_data_small_dataset_with_impression_ids.pt\", device)\n",
    "val_his_inputs, val_pred_inputs, val_targets, impression_ids = load_preprocessed_data(\"val_data_small_dataset_with_impression_ids.pt\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(inputs, targets, impression_ids, batch_size):\n",
    "    his_inputs, pred_inputs = inputs\n",
    "    for i in range(0, his_inputs.size(0), batch_size):\n",
    "        his_batch = his_inputs[i:i+batch_size]\n",
    "        pred_batch = pred_inputs[i:i+batch_size]\n",
    "        target_batch = targets[i:i+batch_size]\n",
    "        impression_id_batch = impression_ids[i:i+batch_size]\n",
    "        yield (his_batch, pred_batch), target_batch, impression_id_batch\n",
    "\n",
    "# Set the batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Example: Create batches for train and validation data\n",
    "#train_batches = create_batches((train_his_inputs, train_pred_inputs), train_targets, batch_size)\n",
    "#val_batches = create_batches((val_his_inputs, val_pred_inputs), val_targets, batch_size)\n",
    "\n",
    "train_batches = list(create_batches((train_his_inputs, train_pred_inputs), train_targets, impression_ids, batch_size))\n",
    "val_batches = list(create_batches((val_his_inputs, val_pred_inputs), val_targets, impression_ids, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_batch = next(iter(train_batches))\n",
    "# inputs, targets, impression_ids = sample_batch\n",
    "\n",
    "# his_input, pred_input = inputs\n",
    "# print(f\"History input shape: {his_input.shape}\")\n",
    "# print(f\"History input values (first item):\\n{his_input[0][0][:10]}\")  # First 10 values\n",
    "\n",
    "# print(f\"\\nPred input shape: {pred_input.shape}\")\n",
    "# print(f\"Pred input values (first item):\\n{pred_input[0][0][:10]}\")\n",
    "\n",
    "# print(f\"\\nTargets shape: {targets.shape}\")\n",
    "# print(f\"Target values (first item):\\n{targets[0][:10]}\")\n",
    "\n",
    "# # Get a batch from train_dataloader_temp\n",
    "# temp_batch = next(iter(val_dataloader_temp))\n",
    "# temp_inputs, temp_targets, temp_impression_ids = temp_batch\n",
    "# temp_his, temp_pred = temp_inputs\n",
    "\n",
    "# # Get a batch from preprocessed data\n",
    "# processed_batch = next(iter(val_batches))\n",
    "# processed_inputs, processed_targets, processed_impression_ids = processed_batch\n",
    "# processed_his, processed_pred = processed_inputs\n",
    "\n",
    "# print(\"Temp dataloader shapes:\")\n",
    "# print(f\"History: {temp_his.shape}\")\n",
    "# print(f\"Pred: {temp_pred.shape}\")\n",
    "# print(f\"Targets: {temp_targets.shape}\")\n",
    "\n",
    "# print(\"\\nPreprocessed data shapes:\")\n",
    "# print(f\"History: {processed_his.shape}\")\n",
    "# print(f\"Pred: {processed_pred.shape}\")\n",
    "# print(f\"Targets: {processed_targets.shape}\")\n",
    "\n",
    "# print(\"\\nSample values comparison:\")\n",
    "# print(\"Temp history:\", temp_his[0][0][:5])\n",
    "# print(\"Processed history:\", processed_his[0][0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (his_batch, pred_batch), target_batch, impression_ids_batch in train_batches:\n",
    "#     print(f\"his_batch device: {his_batch.device}\")\n",
    "#     print(f\"pred_batch device: {pred_batch.device}\")\n",
    "#     print(f\"target_batch device: {target_batch.device}\")\n",
    "#     print(f\"impression_ids_batch device: {impression_ids_batch.device}\")\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'models_pytorch.model_config', '__annotations__': {'title_size': <class 'int'>, 'history_size': <class 'int'>, 'embedding_dim': <class 'int'>, 'word_emb_dim': <class 'int'>, 'vocab_size': <class 'int'>, 'head_num': <class 'int'>, 'head_dim': <class 'int'>, 'attention_hidden_dim': <class 'int'>, 'optimizer': <class 'str'>, 'loss': <class 'str'>, 'dropout': <class 'float'>, 'learning_rate': <class 'float'>, 'units_per_layer': list[int]}, 'title_size': 768, 'history_size': 10, 'embedding_dim': 32, 'word_emb_dim': 8, 'vocab_size': 10000, 'head_num': 4, 'head_dim': 8, 'attention_hidden_dim': 50, 'hidden_dim': 4, 'optimizer': 'adam', 'loss': 'cross_entropy_loss', 'dropout': 0.6, 'learning_rate': 0.001, 'news_output_dim': 64, 'units_per_layer': [64, 64, 64], '__dict__': <attribute '__dict__' of 'hparams_nrms' objects>, '__weakref__': <attribute '__weakref__' of 'hparams_nrms' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# see the model parameters: \n",
    "print(hparams_nrms.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024/models_pytorch/NRMSDocVecModel.py:118: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define paths\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = os.path.join(\"downloads\", \"runs\", MODEL_NAME)\n",
    "MODEL_WEIGHTS = os.path.join(\"downloads\", \"data\", \"state_dict\", MODEL_NAME, \"weights.pth\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_WEIGHTS), exist_ok=True)\n",
    "\n",
    "# Define ModelCheckpoint class\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Saves the model after every epoch if it has the best performance so far.\"\"\"\n",
    "    def __init__(self, filepath, verbose=False, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath (str): Path to save the model checkpoint.\n",
    "            verbose (bool): If True, prints a message when the model is saved.\n",
    "            save_best_only (bool): If True, saves only when the model is better than before.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_loss = None\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.filepath)\n",
    "        if self.verbose:\n",
    "            print(f\"Model saved to {self.filepath}\")\n",
    "\n",
    "# Define EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve by a given percentage over a patience period.\"\"\"\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after last time validation loss improved by min_delta.\n",
    "            min_delta (float): Minimum percentage improvement required to reset patience.\n",
    "            verbose (bool): If True, prints a message when early stopping is triggered.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta  # Minimum percentage improvement\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            # Initialize best_loss with the first validation loss\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss < self.best_loss * (1 - self.min_delta):\n",
    "            # Significant improvement found\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved by at least {self.min_delta*100:.1f}%\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No significant improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "# Initialize callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_WEIGHTS, verbose=True, save_best_only=True)\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "\n",
    "# Initialize your model\n",
    "# Ensure that NRMSModel is a PyTorch nn.Module\n",
    "\n",
    "# CUDA checks\n",
    "#print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "#print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "#print(f\"Device Name: {torch.cuda.get_device_name()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "# model = NRMSModel(\n",
    "#     hparams=hparams_nrms.__dict__,\n",
    "#     word2vec_embedding=word2vec_embedding,\n",
    "#     vocab_size=1000,\n",
    "#     word_emb_dim=8,\n",
    "#     seed=seed,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "model = NRMSDocVecModel(hparams=hparams_nrms.__dict__,\n",
    "                        device=device)\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_prediction_details(outputs, targets, k=5):\n",
    "#     \"\"\"Print detailed prediction information for the first k samples\"\"\"\n",
    "#     # Get predicted class (highest score)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "#     # Calculate accuracy for this batch\n",
    "#     correct = (predicted == targets).sum().item()\n",
    "#     total = targets.size(0)\n",
    "#     accuracy = 100 * correct / total\n",
    "    \n",
    "#     # Print details for k samples\n",
    "#     for i in range(min(k, len(targets))):\n",
    "#         print(f\"\\nSample {i}:\")\n",
    "#         print(f\"Predicted probabilities: {torch.softmax(outputs[i], dim=0)}\")\n",
    "#         print(f\"Predicted class: {predicted[i]}, True class: {targets[i]}\")\n",
    "#         print(f\"Correct: {predicted[i] == targets[i]}\")\n",
    "    \n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Print model architecture\n",
    "# print(model)\n",
    "\n",
    "# # 2. Print specific layer sizes\n",
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Layer: {name} | Size: {param.size()}\")\n",
    "\n",
    "# # 3. Get total number of parameters\n",
    "# total_params = sum(p.numel() for p in model.parameters())\n",
    "# print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "\n",
    "# # 4. Print layer by layer with shapes\n",
    "# def print_model_structure(model):\n",
    "#     print(\"\\nDetailed Model Structure:\")\n",
    "#     for name, module in model.named_children():\n",
    "#         print(f\"\\nLayer: {name}\")\n",
    "#         print(f\"Type: {type(module).__name__}\")\n",
    "#         if hasattr(module, 'weight'):\n",
    "#             print(f\"Shape: {module.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Layer: {name} | Size: {param.size()} | Parameters: {param.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_GRAD_NORM = np.sqrt(sum(p.numel() for p in model.parameters()))\n",
    "# print(f\"Max grad norm: {MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Added gradient clipping to avoid exploiding gradients. The paramter MAX_GRAD_NORM is set to 5.0 as this is a common value used in transformers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Variables to track counts\n",
    "# total_inputs = 0\n",
    "# total_targets = 0\n",
    "\n",
    "# # Iterate over the DataLoader\n",
    "# for batch_idx, (inputs, targets, impression_ids) in enumerate(train_dataloader_temp):\n",
    "#     # Move data to GPU\n",
    "#     inputs = [inp.to(device) for inp in inputs]\n",
    "#     targets = targets.to(device)\n",
    "#     impression_ids = impression_ids.to(device)\n",
    "    \n",
    "#     # Print information for the first few batches to avoid delays\n",
    "#     if batch_idx < 5:  # Adjust the number of batches to print as needed\n",
    "#         print(f\"Batch {batch_idx + 1} (on {device}):\")\n",
    "#         print(f\"  - Number of inputs: {len(inputs[0])}\")  # History input\n",
    "#         print(f\"  - Number of targets: {len(targets)}\")   # Target labels\n",
    "#         print(f\"  - Impression IDs: {len(impression_ids)}\")\n",
    "    \n",
    "#     # Update total counts\n",
    "#     total_inputs += len(inputs[0])\n",
    "#     total_targets += len(targets)\n",
    "\n",
    "# # Final counts after iteration\n",
    "# print(f\"\\nTotal number of inputs in train_dataloader_temp: {total_inputs}\")\n",
    "# print(f\"Total number of targets in train_dataloader_temp: {total_targets}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024/models_pytorch/NRMSDocVecModel.py:127: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Training Progress:   7%|▋         | 2/30 [00:33<07:48, 16.72s/it, train_loss=2.3200, val_loss=2.8442]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved by at least 5.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 3/30 [00:50<07:31, 16.71s/it, train_loss=1.8517, val_loss=2.3013]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved by at least 5.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  13%|█▎        | 4/30 [01:06<07:10, 16.57s/it, train_loss=1.6546, val_loss=2.2947]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  17%|█▋        | 5/30 [01:23<06:54, 16.59s/it, train_loss=1.6336, val_loss=2.2911]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  17%|█▋        | 5/30 [01:40<08:21, 20.05s/it, train_loss=1.6262, val_loss=2.2900]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 3/3\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-3\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = model.get_loss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Training parameters\n",
    "NUM_EPOCHS = 30\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Epoch progress bar\n",
    "epoch_pbar = tqdm(range(1, NUM_EPOCHS + 1), desc=\"Training Progress\", dynamic_ncols=True)\n",
    "for epoch in epoch_pbar:\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets, impression_ids) in enumerate(train_dataloader_temp):\n",
    "        # Prepare data\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Get positive labels\n",
    "        positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "        targets = positive_indices[:, 1].long()\n",
    "\n",
    "        # Forward and backward passes\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running statistics\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    # Compute average training loss\n",
    "    avg_train_loss = running_loss / train_batch_count if train_batch_count > 0 else float('inf')\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batch_count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, impression_ids in val_dataloader_temp:\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            targets = targets.to(device)\n",
    "            positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "            targets = positive_indices[:, 1].long()\n",
    "            outputs = model(*inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_batch_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Update tensorboard\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "\n",
    "    # Update epoch progress bar with metrics\n",
    "    epoch_pbar.set_postfix({\n",
    "        'train_loss': f'{avg_train_loss:.4f}',\n",
    "        'val_loss': f'{avg_val_loss:.4f}',\n",
    "    })\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        model_checkpoint(model, avg_val_loss)\n",
    "\n",
    "    # Check early stopping condition\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Summary:\n",
      "Initial Training Loss: 2.7681\n",
      "Final Training Loss: 1.6262\n",
      "Best Training Loss: 1.6262\n",
      "\n",
      "Initial Validation Loss: 3.6507\n",
      "Final Validation Loss: 2.2900\n",
      "Best Validation Loss: 2.2900\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print final statistics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Initial Training Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Training Loss: {min(train_losses):.4f}\")\n",
    "print(f\"\\nInitial Validation Loss: {val_losses[0]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Validation Loss: {min(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating DataLoader...\n",
      "Total samples in DataLoader: 48635\n",
      "\n",
      "First batch shapes:\n",
      "  - his_input_title: torch.Size([128, 10, 768])\n",
      "  - pred_input_title: torch.Size([128, 91, 768])\n",
      "  - targets: torch.Size([128, 91])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024/models_pytorch/NRMSDocVecModel.py:127: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed.\n",
      "Total predictions generated: 48635\n",
      "First few prediction lengths: [24, 10, 15, 10, 10, 7, 11, 7, 7, 12, 5, 19, 16, 17, 27]\n",
      "\n",
      "Validation against DataFrame:\n",
      "\n",
      "Metrics: {'auc': 0.49660534524224714, 'mrr': 0.31173190401853945, 'ndcg@5': 0.34116067095982305, 'ndcg@10': 0.4272129717302425}\n",
      "FRACTION: 0.2\n",
      ", HISTORY_SIZE: 10, LEARNING_RATE: 0.0001, WEIGHT_DECAY: 0.001\n",
      "Hyperparameters:\n",
      "title_size: 768\n",
      "history_size: 10\n",
      "embedding_dim: 32\n",
      "word_emb_dim: 8\n",
      "vocab_size: 10000\n",
      "head_num: 4\n",
      "head_dim: 8\n",
      "attention_hidden_dim: 50\n",
      "hidden_dim: 4\n",
      "optimizer: adam\n",
      "loss: cross_entropy_loss\n",
      "dropout: 0.6\n",
      "learning_rate: 0.001\n",
      "news_output_dim: 64\n",
      "units_per_layer: [64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Evaluate the model and return predictions and labels for metric calculation.\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"\\nEvaluating DataLoader...\")\n",
    "    total_samples = len(dataloader.dataset)\n",
    "    print(f\"Total samples in DataLoader: {total_samples}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, impression_ids) in enumerate(dataloader):\n",
    "            his_input_title, pred_input_title = inputs\n",
    "\n",
    "            if batch_idx == 0:  # Debug first batch shapes\n",
    "                print(\"\\nFirst batch shapes:\")\n",
    "                print(f\"  - his_input_title: {his_input_title.shape}\")\n",
    "                print(f\"  - pred_input_title: {pred_input_title.shape}\")\n",
    "                print(f\"  - targets: {targets.shape}\")\n",
    "\n",
    "            # Move data to device\n",
    "            his_input_title = his_input_title.to(device)\n",
    "            pred_input_title = pred_input_title.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model.predict(his_input_title, pred_input_title)\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            targets = targets.cpu().numpy()\n",
    "\n",
    "            # Process each sample in the batch\n",
    "            batch_size = predictions.shape[0]\n",
    "            for sample_idx in range(batch_size):\n",
    "                pred = predictions[sample_idx]\n",
    "                label = targets[sample_idx]\n",
    "\n",
    "                # Create valid_mask where label is not equal to the padding value (-1)\n",
    "                valid_mask = (label != -1)\n",
    "                sample_preds = pred[valid_mask]\n",
    "                sample_labels = label[valid_mask]\n",
    "\n",
    "                if len(sample_labels) == 0:\n",
    "                    continue  # Skip empty samples\n",
    "\n",
    "                # Ensure that there is at least one positive and one negative label\n",
    "                if len(np.unique(sample_labels)) < 2:\n",
    "                    continue  # Skip samples with only one class\n",
    "\n",
    "                all_predictions.append(sample_preds.tolist())\n",
    "                all_labels.append(sample_labels.tolist())\n",
    "\n",
    "    print(\"\\nEvaluation completed.\")\n",
    "    print(f\"Total predictions generated: {len(all_predictions)}\")\n",
    "    print(f\"First few prediction lengths: {[len(x) for x in all_predictions[:15]]}\")\n",
    "    return all_labels, all_predictions\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "labels_list, scores_list = evaluate_model(model, val_dataloader_temp, device)\n",
    "\n",
    "# Validate predictions against the DataFrame\n",
    "print(\"\\nValidation against DataFrame:\")\n",
    "if len(scores_list) != len(df_validation):\n",
    "    print(\"WARNING: Length mismatch!\")\n",
    "    print(f\"  - Number of predictions: {len(scores_list)}\")\n",
    "    print(f\"  - Number of rows in DataFrame: {len(df_validation)}\")\n",
    "\n",
    "# Compute metrics\n",
    "metrics = MetricEvaluator(\n",
    "    labels=labels_list,\n",
    "    predictions=scores_list,\n",
    "    metric_functions=[\n",
    "        AucScore(),\n",
    "        MrrScore(),\n",
    "        NdcgScore(k=5),\n",
    "        NdcgScore(k=10)\n",
    "    ],\n",
    ")\n",
    "results = metrics.evaluate()\n",
    "print(\"\\nMetrics:\", results.evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRACTION: 0.2, HISTORY_SIZE: 10, LEARNING_RATE: 0.0001, WEIGHT_DECAY: 0.001\n",
      "Hyperparameters:\n",
      "title_size: 768\n",
      "history_size: 10\n",
      "embedding_dim: 32\n",
      "word_emb_dim: 8\n",
      "vocab_size: 10000\n",
      "head_num: 4\n",
      "head_dim: 8\n",
      "attention_hidden_dim: 50\n",
      "hidden_dim: 4\n",
      "optimizer: adam\n",
      "loss: cross_entropy_loss\n",
      "dropout: 0.6\n",
      "learning_rate: 0.001\n",
      "news_output_dim: 64\n",
      "units_per_layer: [64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "print(f\"FRACTION: {FRACTION}, HISTORY_SIZE: {HISTORY_SIZE}, LEARNING_RATE: {LEARNING_RATE}, WEIGHT_DECAY: {WEIGHT_DECAY}\")\n",
    "\n",
    "# Filter out special Python attributes and print parameters\n",
    "params = {k: v for k, v in hparams_nrms.__dict__.items() if not k.startswith('__')}\n",
    "print(\"Hyperparameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_labels(df: pl.DataFrame, impression_id: int) -> int:\n",
    "    # Filter for matching impression_id\n",
    "    filtered = df.filter(pl.col('impression_id') == impression_id)\n",
    "    \n",
    "    if filtered.height == 0:\n",
    "        raise ValueError(f\"No row found for impression_id {impression_id}\")\n",
    "    \n",
    "    # Get labels from first row\n",
    "    labels = filtered.select('labels').row(0)[0]\n",
    "    \n",
    "    return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No row found for impression_id 349992000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_length_of_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_validation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m349992000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 6\u001b[0m, in \u001b[0;36mget_length_of_labels\u001b[0;34m(df, impression_id)\u001b[0m\n\u001b[1;32m      3\u001b[0m filtered \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mfilter(pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimpression_id\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m impression_id)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filtered\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo row found for impression_id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimpression_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Get labels from first row\u001b[39;00m\n\u001b[1;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m filtered\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mrow(\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: No row found for impression_id 349992000"
     ]
    }
   ],
   "source": [
    "get_length_of_labels(df_validation, 349992000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label 1: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label 2: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label 3: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label 4: [0, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 labels\n",
    "first_5_labels = df_validation.select('labels').head(5)\n",
    "\n",
    "# Print each label with index\n",
    "for i, row in enumerate(first_5_labels.iter_rows()):\n",
    "    print(f\"Label {i}: {row[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024/models_pytorch/NRMSDocVecModel.py:127: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples with only one class\n",
      "Remaining valid samples: 4864\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize lists\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "skipped_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (his_input_title, pred_input_title), targets, impression_ids in val_batches:\n",
    "        # Move to device\n",
    "        his_input_title = his_input_title.to(device)\n",
    "        pred_input_title = pred_input_title.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(his_input_title, pred_input_title)\n",
    "        \n",
    "        # Convert to probabilities if needed\n",
    "        if not torch.is_floating_point(predictions):\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Convert to lists while preserving structure\n",
    "        batch_preds = predictions.cpu().numpy().tolist()\n",
    "        batch_labels = targets.cpu().numpy().tolist()\n",
    "        impression_ids = impression_ids.cpu().numpy().tolist()\n",
    "        \n",
    "        batch_preds_without_padding = []\n",
    "        batch_labels_without_padding = []\n",
    "        \n",
    "        for pred_sample, label_sample, impression_id_sample in zip(batch_preds, batch_labels, impression_ids):\n",
    "            # Remove padding\n",
    "            actual_length = get_length_of_labels(df_validation, impression_id_sample)\n",
    "            pred_sample = pred_sample[:actual_length]\n",
    "            \n",
    "            # Check if sample has both classes before adding\n",
    "            if 1 in label_sample[:actual_length] and 0 in label_sample[:actual_length]:\n",
    "                batch_preds_without_padding.append(pred_sample)\n",
    "                batch_labels_without_padding.append(label_sample[:actual_length])\n",
    "            else:\n",
    "                skipped_samples += 1\n",
    "        \n",
    "        # Add batch predictions and labels\n",
    "        all_predictions.extend(batch_preds_without_padding)\n",
    "        all_labels.extend(batch_labels_without_padding)\n",
    "print(f\"Skipped {skipped_samples} samples with only one class\")\n",
    "print(f\"Remaining valid samples: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 0:\n",
      "Labels length:      13\n",
      "Predictions length: 13\n",
      "Num positives: 1.0\n",
      "Num negatives: 12.0\n",
      "Label distribution: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 1:\n",
      "Labels length:      10\n",
      "Predictions length: 10\n",
      "Num positives: 1.0\n",
      "Num negatives: 9.0\n",
      "Label distribution: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 2:\n",
      "Labels length:      12\n",
      "Predictions length: 12\n",
      "Num positives: 1.0\n",
      "Num negatives: 11.0\n",
      "Label distribution: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 3:\n",
      "Labels length:      11\n",
      "Predictions length: 11\n",
      "Num positives: 1.0\n",
      "Num negatives: 10.0\n",
      "Label distribution: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 4:\n",
      "Labels length:      8\n",
      "Predictions length: 8\n",
      "Num positives: 1.0\n",
      "Num negatives: 7.0\n",
      "Label distribution: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Print label distribution for first 5 samples\n",
    "for i, (preds, labels) in enumerate(zip(all_predictions[:5], all_labels[:5])):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Labels length:      {len(labels)}\")\n",
    "    print(f\"Predictions length: {len(preds)}\")\n",
    "    print(f\"Num positives: {sum(labels)}\")\n",
    "    print(f\"Num negatives: {len(labels) - sum(labels)}\")\n",
    "    print(f\"Label distribution: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "Number of predictions: 4864\n",
      "example prediction: [[0.5576398372650146, 0.5619529485702515, 0.5625104308128357, 0.5709179639816284, 0.5633894205093384, 0.5695317387580872, 0.5657944083213806, 0.5550926923751831, 0.5490545034408569, 0.5679540634155273, 0.5603517889976501, 0.5609380602836609, 0.5535123944282532], [0.5636120438575745, 0.5590565800666809, 0.5694467425346375, 0.5385706424713135, 0.5612233877182007, 0.565780758857727, 0.5651269555091858, 0.5440400838851929, 0.5636046528816223, 0.5696796178817749]]\n",
      "Number of labels: 4864\n",
      "example label: [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(type(all_predictions))\n",
    "print(type(all_labels))\n",
    "\n",
    "print(f\"Number of predictions: {len(all_predictions)}\")\n",
    "print(f\"example prediction: {all_predictions[0:2]}\")\n",
    "print(f\"Number of labels: {len(all_labels)}\")\n",
    "print(f\"example label: {all_labels[0:2]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1178\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "correct_predictions = 0\n",
    "total_samples = len(all_predictions)\n",
    "\n",
    "# Iterate over samples\n",
    "for idx, _ in enumerate(all_predictions):\n",
    "    # print(f\"Sample {idx}: Prediction: {all_predictions[idx]}\")\n",
    "    # print(f\"Sample {idx}: Label:      {all_labels[idx]}\")\n",
    "    \n",
    "    # Extract index of maximum value in predictions and labels\n",
    "    pred_max_index = np.argmax(all_predictions[idx])\n",
    "    label_max_index = np.argmax(all_labels[idx])\n",
    "    \n",
    "    # Compare indices to determine if the prediction was correct\n",
    "    if pred_max_index == label_max_index:\n",
    "        # print(f\"Sample {idx}: Prediction was correct.\")\n",
    "        correct_predictions += 1\n",
    "  #  else:\n",
    "        # print(f\"Sample {idx}: Prediction was wrong.\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.5045\n",
      "Number of valid AUC calculations: 4864\n"
     ]
    }
   ],
   "source": [
    "from evaluation import AucScore\n",
    "\n",
    "# auc_score = AucScore()\n",
    "\n",
    "# auc_score.calculate(all_predictions, all_labels)\n",
    "# print(f\"AUC: {auc_score.score}\")\n",
    "# # Calculate AUC per sample\n",
    "aucs = []\n",
    "for preds, labels in zip(all_predictions, all_labels):\n",
    "    try:\n",
    "        # Only calculate if we have both positive and negative samples\n",
    "        if sum(labels) > 0 and sum(labels) < len(labels):\n",
    "            auc = roc_auc_score(labels, preds)\n",
    "            aucs.append(auc)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Only one class present in labels. Cannot calculate AUC.\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(aucs):.4f}\")\n",
    "print(f\"Number of valid AUC calculations: {len(aucs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
