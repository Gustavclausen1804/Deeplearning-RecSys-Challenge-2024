{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.1\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Current GPU device: NVIDIA GeForce RTX 3070\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "#import optuna\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL,\n",
    "    DEFAULT_TOTAL_READ_TIME_COL,\n",
    "    DEFAULT_SENTIMENT_SCORE_COL,\n",
    ")\n",
    "\n",
    "from utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from utils._articles import convert_text2encoding_with_transformers\n",
    "from utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from utils._articles import create_article_id_to_value_mapping\n",
    "from utils._nlp import get_transformers_word_embeddings, generate_embeddings_with_transformers\n",
    "from utils._python import write_submission_file, rank_predictions_by_score\n",
    "from models_pytorch.model_config import hparams_nrms\n",
    "\n",
    "from models_pytorch.nrms import NRMSModel\n",
    "from models_pytorch.NRMSDocVecModel import NRMSDocVecModel\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from models_pytorch.dataloader import NRMSDataSet\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at behaviours and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebnerd_small\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"./ebnerd_small\")  # Base path for your data directory\n",
    "print(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>datetime[μs]</td><td>list[i8]</td></tr></thead><tbody><tr><td>884146</td><td>[9766722, 9765846, … 9769622]</td><td>[9773574, 9566633, … 9773461]</td><td>[9773461]</td><td>390458902</td><td>2023-05-20 14:21:36</td><td>[0, 0, … 1]</td></tr><tr><td>835528</td><td>[0, 0, … 9768583]</td><td>[9769581, 9738729, … 9770028]</td><td>[9769581]</td><td>316312864</td><td>2023-05-21 14:22:42</td><td>[1, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆ u32          ┆ datetime[μs] ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 884146  ┆ [9766722,    ┆ [9773574,    ┆ [9773461]    ┆ 390458902    ┆ 2023-05-20   ┆ [0, 0, … 1] │\n",
       "│         ┆ 9765846, …   ┆ 9566633, …   ┆              ┆              ┆ 14:21:36     ┆             │\n",
       "│         ┆ 9769622]     ┆ 9773461]     ┆              ┆              ┆              ┆             │\n",
       "│ 835528  ┆ [0, 0, …     ┆ [9769581,    ┆ [9769581]    ┆ 316312864    ┆ 2023-05-21   ┆ [1, 0, … 0] │\n",
       "│         ┆ 9768583]     ┆ 9738729, …   ┆              ┆              ┆ 14:22:42     ┆             │\n",
       "│         ┆              ┆ 9770028]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "]\n",
    "HISTORY_SIZE = 20 # TODO: History size. \n",
    "FRACTION = 0.1\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.with_columns([\n",
    "    (\n",
    "        (pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)\n",
    "        .dt.epoch(time_unit='s') / 3600)\n",
    "        .cast(pl.Int64)\n",
    "    ).alias(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "])\n",
    "\n",
    "df_validation = df_validation.with_columns([\n",
    "    (\n",
    "        (pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)\n",
    "        .dt.epoch(time_unit='s') / 3600)\n",
    "        .cast(pl.Int64)\n",
    "    ).alias(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>i64</td><td>list[i8]</td></tr></thead><tbody><tr><td>884146</td><td>[9766722, 9765846, … 9769622]</td><td>[9773574, 9566633, … 9773461]</td><td>[9773461]</td><td>390458902</td><td>467942</td><td>[0, 0, … 1]</td></tr><tr><td>835528</td><td>[0, 0, … 9768583]</td><td>[9769581, 9738729, … 9770028]</td><td>[9769581]</td><td>316312864</td><td>467966</td><td>[1, 0, … 0]</td></tr><tr><td>967077</td><td>[9766722, 9766627, … 9767697]</td><td>[9776337, 9776420, … 9775846]</td><td>[9776337]</td><td>150454282</td><td>468017</td><td>[1, 0, … 0]</td></tr><tr><td>1885995</td><td>[9770452, 9770178, … 9770882]</td><td>[9773014, 9772710, … 9772485]</td><td>[9773015]</td><td>507899156</td><td>467924</td><td>[0, 0, … 0]</td></tr><tr><td>2124925</td><td>[9770194, 9770207, … 9770533]</td><td>[9695098, 9310988, … 9778004]</td><td>[9778004]</td><td>508776742</td><td>468017</td><td>[0, 0, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆ u32          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 884146  ┆ [9766722,    ┆ [9773574,    ┆ [9773461]    ┆ 390458902    ┆ 467942       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9765846, …   ┆ 9566633, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9769622]     ┆ 9773461]     ┆              ┆              ┆              ┆             │\n",
       "│ 835528  ┆ [0, 0, …     ┆ [9769581,    ┆ [9769581]    ┆ 316312864    ┆ 467966       ┆ [1, 0, … 0] │\n",
       "│         ┆ 9768583]     ┆ 9738729, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆              ┆ 9770028]     ┆              ┆              ┆              ┆             │\n",
       "│ 967077  ┆ [9766722,    ┆ [9776337,    ┆ [9776337]    ┆ 150454282    ┆ 468017       ┆ [1, 0, … 0] │\n",
       "│         ┆ 9766627, …   ┆ 9776420, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9767697]     ┆ 9775846]     ┆              ┆              ┆              ┆             │\n",
       "│ 1885995 ┆ [9770452,    ┆ [9773014,    ┆ [9773015]    ┆ 507899156    ┆ 467924       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9770178, …   ┆ 9772710, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9770882]     ┆ 9772485]     ┆              ┆              ┆              ┆             │\n",
       "│ 2124925 ┆ [9770194,    ┆ [9695098,    ┆ [9778004]    ┆ 508776742    ┆ 468017       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9770207, …   ┆ 9310988, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9770533]     ┆ 9778004]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>u32</td><td>i64</td><td>list[i8]</td></tr></thead><tbody><tr><td>283866</td><td>[9776560, 9775596, … 9780039]</td><td>[7213923, 9780909, … 9521552]</td><td>[9521552]</td><td>566858780</td><td>468061</td><td>[0, 0, … 1]</td></tr><tr><td>1282363</td><td>[9777079, 9776916, … 9778875]</td><td>[9783977, 9782828, … 9551777]</td><td>[9783952]</td><td>155091152</td><td>468110</td><td>[0, 0, … 0]</td></tr><tr><td>412463</td><td>[9778500, 9778328, … 9780193]</td><td>[9784094, 9784214, … 9783754]</td><td>[9782360]</td><td>81600122</td><td>468111</td><td>[0, 0, … 0]</td></tr><tr><td>2470065</td><td>[9778731, 9778952, … 9779748]</td><td>[9749014, 9779370, … 9783655]</td><td>[9783655]</td><td>178808322</td><td>468127</td><td>[0, 0, … 1]</td></tr><tr><td>924206</td><td>[9775998, 9775983, … 9778381]</td><td>[9780986, 9787656, … 9787501]</td><td>[9780986]</td><td>317453087</td><td>468175</td><td>[1, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i32]    ┆ list[i32]    ┆ u32          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 283866  ┆ [9776560,    ┆ [7213923,    ┆ [9521552]    ┆ 566858780    ┆ 468061       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9775596, …   ┆ 9780909, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9780039]     ┆ 9521552]     ┆              ┆              ┆              ┆             │\n",
       "│ 1282363 ┆ [9777079,    ┆ [9783977,    ┆ [9783952]    ┆ 155091152    ┆ 468110       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9776916, …   ┆ 9782828, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778875]     ┆ 9551777]     ┆              ┆              ┆              ┆             │\n",
       "│ 412463  ┆ [9778500,    ┆ [9784094,    ┆ [9782360]    ┆ 81600122     ┆ 468111       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778328, …   ┆ 9784214, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9780193]     ┆ 9783754]     ┆              ┆              ┆              ┆             │\n",
       "│ 2470065 ┆ [9778731,    ┆ [9749014,    ┆ [9783655]    ┆ 178808322    ┆ 468127       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9778952, …   ┆ 9779370, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779748]     ┆ 9783655]     ┆              ┆              ┆              ┆             │\n",
       "│ 924206  ┆ [9775998,    ┆ [9780986,    ┆ [9780986]    ┆ 317453087    ┆ 468175       ┆ [1, 0, … 0] │\n",
       "│         ┆ 9775983, …   ┆ 9787656, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778381]     ┆ 9787501]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of article_ids_inview in df_train: 5.0\n",
      "Average length of article_ids_inview in df_validation: 11.973430346631785\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_length(df, column):\n",
    "    total_length = sum(len(row) for row in df[column])\n",
    "    average_length = total_length / len(df)\n",
    "    return average_length\n",
    "\n",
    "# Calculate average length for df_train\n",
    "average_length_inview_train = calculate_average_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_train: {average_length_inview_train}\")\n",
    "\n",
    "# Calculate average length for df_validation\n",
    "average_length_inview_validation = calculate_average_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_validation: {average_length_inview_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest inview article length in df_train: 5\n",
      "Longest inview article length in df_validation: 88\n",
      "Longest history length in df_train: 20\n",
      "Longest history length in df_validation: 20\n"
     ]
    }
   ],
   "source": [
    "# Function to find the maximum length of arrays in a column\n",
    "def find_max_length(df, column):\n",
    "    max_length = 0\n",
    "    for row in df[column]:\n",
    "        max_length = max(max_length, len(row))\n",
    "    return max_length\n",
    "\n",
    "# Find the longest inview article length in df_train\n",
    "max_inview_length_train = find_max_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "# Find the longest inview article length in df_validation\n",
    "max_inview_length_validation = find_max_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "print(f\"Longest inview article length in df_train: {max_inview_length_train}\")\n",
    "print(f\"Longest inview article length in df_validation: {max_inview_length_validation}\")\n",
    "\n",
    "max_history_length_train = find_max_length(df_train, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "max_history_length_validation = find_max_length(df_validation, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "\n",
    "print(f\"Longest history length in df_train: {max_history_length_train}\")\n",
    "print(f\"Longest history length in df_validation: {max_history_length_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with exactly one clicked article in df_train: 23427\n",
      "Number of rows with exactly one clicked article in df_validation: 24309\n"
     ]
    }
   ],
   "source": [
    "# Function to filter rows with exactly one clicked article\n",
    "def filter_rows_with_one_clicked_article(df, clicked_articles_col):\n",
    "    # Manually filter rows where the array has exactly one element\n",
    "    filtered_rows = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        if len(row[clicked_articles_col]) == 1:\n",
    "            filtered_rows.append(row)\n",
    "    return pl.DataFrame(filtered_rows)\n",
    "\n",
    "\n",
    "# Filter rows in df_train and df_validation\n",
    "df_train = filter_rows_with_one_clicked_article(df_train, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "df_validation = filter_rows_with_one_clicked_article(df_validation, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of rows with exactly one clicked article in df_train: {df_train.shape[0]}\")\n",
    "print(f\"Number of rows with exactly one clicked article in df_validation: {df_validation.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>283866</td><td>[9776560, 9775596, … 9780039]</td><td>[7213923, 9780909, … 9521552]</td><td>[9521552]</td><td>566858780</td><td>468061</td><td>[0, 0, … 1]</td></tr><tr><td>1282363</td><td>[9777079, 9776916, … 9778875]</td><td>[9783977, 9782828, … 9551777]</td><td>[9783952]</td><td>155091152</td><td>468110</td><td>[0, 0, … 0]</td></tr><tr><td>412463</td><td>[9778500, 9778328, … 9780193]</td><td>[9784094, 9784214, … 9783754]</td><td>[9782360]</td><td>81600122</td><td>468111</td><td>[0, 0, … 0]</td></tr><tr><td>2470065</td><td>[9778731, 9778952, … 9779748]</td><td>[9749014, 9779370, … 9783655]</td><td>[9783655]</td><td>178808322</td><td>468127</td><td>[0, 0, … 1]</td></tr><tr><td>924206</td><td>[9775998, 9775983, … 9778381]</td><td>[9780986, 9787656, … 9787501]</td><td>[9780986]</td><td>317453087</td><td>468175</td><td>[1, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ i64     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i64]   │\n",
       "│         ┆ list[i64]    ┆ list[i64]    ┆ list[i64]    ┆ i64          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 283866  ┆ [9776560,    ┆ [7213923,    ┆ [9521552]    ┆ 566858780    ┆ 468061       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9775596, …   ┆ 9780909, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9780039]     ┆ 9521552]     ┆              ┆              ┆              ┆             │\n",
       "│ 1282363 ┆ [9777079,    ┆ [9783977,    ┆ [9783952]    ┆ 155091152    ┆ 468110       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9776916, …   ┆ 9782828, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778875]     ┆ 9551777]     ┆              ┆              ┆              ┆             │\n",
       "│ 412463  ┆ [9778500,    ┆ [9784094,    ┆ [9782360]    ┆ 81600122     ┆ 468111       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778328, …   ┆ 9784214, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9780193]     ┆ 9783754]     ┆              ┆              ┆              ┆             │\n",
       "│ 2470065 ┆ [9778731,    ┆ [9749014,    ┆ [9783655]    ┆ 178808322    ┆ 468127       ┆ [0, 0, … 1] │\n",
       "│         ┆ 9778952, …   ┆ 9779370, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779748]     ┆ 9783655]     ┆              ┆              ┆              ┆             │\n",
       "│ 924206  ┆ [9775998,    ┆ [9780986,    ┆ [9780986]    ┆ 317453087    ┆ 468175       ┆ [1, 0, … 0] │\n",
       "│         ┆ 9775983, …   ┆ 9787656, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9778381]     ┆ 9787501]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in df_train: 8850\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users in df_train: {df_train['user_id'].n_unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>2007-03-27 10:22:08</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>2001-10-19 12:30:00</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>2003-01-09 06:00:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>2003-06-17 07:10:00</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>2003-07-13 19:50:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = df_articles.with_columns([\n",
    "    (\n",
    "        pl.col(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)                   # Step 3: Cast to Datetime\n",
    "        .dt.epoch(time_unit='s')            # Step 4: Convert to Epoch Seconds\n",
    "        / 3600                               # Step 5: Convert Seconds to Hours\n",
    "    ).cast(pl.Int64)                         # Step 6: Cast to Integer\n",
    "    .alias(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL)  # Step 7: Alias the Column\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>i64</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>321392</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>318952</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>318470</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>326312</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>324754</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>326386</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>278748</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>289470</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>293287</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>293923</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCVEC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document vector parquet file\n",
    "document_vector_path = Path(\"./Ekstra_Bladet_word2vec/document_vector.parquet\")\n",
    "df_document_vector = pl.read_parquet(document_vector_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "\n",
    "article_mapping = create_article_id_to_value_mapping(df=df_document_vector, value_col=\"document_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>document_vector</th></tr><tr><td>i32</td><td>list[f32]</td></tr></thead><tbody><tr><td>3000022</td><td>[0.065424, -0.047425, … 0.035706]</td></tr><tr><td>3000063</td><td>[0.028815, -0.000166, … 0.027167]</td></tr><tr><td>3000613</td><td>[0.037971, 0.033923, … 0.063961]</td></tr><tr><td>3000700</td><td>[0.046524, 0.002913, … 0.023423]</td></tr><tr><td>3000840</td><td>[0.014737, 0.024068, … 0.045991]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────┬─────────────────────────────────┐\n",
       "│ article_id ┆ document_vector                 │\n",
       "│ ---        ┆ ---                             │\n",
       "│ i32        ┆ list[f32]                       │\n",
       "╞════════════╪═════════════════════════════════╡\n",
       "│ 3000022    ┆ [0.065424, -0.047425, … 0.0357… │\n",
       "│ 3000063    ┆ [0.028815, -0.000166, … 0.0271… │\n",
       "│ 3000613    ┆ [0.037971, 0.033923, … 0.06396… │\n",
       "│ 3000700    ┆ [0.046524, 0.002913, … 0.02342… │\n",
       "│ 3000840    ┆ [0.014737, 0.024068, … 0.04599… │\n",
       "└────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_vector.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding tokenized article title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uses existing function for both categories and topics\n",
    "* Handles array of topics by joining with separator\n",
    "* Limits to first 3 topics to avoid sequence length issues\n",
    "* Maintains consistent encoding approach across feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "MAX_TITLE_LENGTH = 30\n",
    "from transformers import ConvBertTokenizer, ConvBertModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "\n",
    "transformer_tokenizer = ConvBertTokenizer.from_pretrained(\"sarnikowski/convbert-small-da-cased\")\n",
    "transformer_model = ConvBertModel.from_pretrained(\"sarnikowski/convbert-small-da-cased\")\n",
    "\n",
    "\n",
    "# For categories (keep as is - works with single strings)\n",
    "df_articles, category_encoded_col_name = convert_text2encoding_with_transformers(\n",
    "    df_articles, \n",
    "    transformer_tokenizer,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# For topics - first join the array into single string\n",
    "df_articles = df_articles.with_columns(\n",
    "    pl.col(DEFAULT_TOPICS_COL).map_elements(lambda x: \" | \".join(x[:3])).alias(f\"{DEFAULT_TOPICS_COL}_joined\")\n",
    ")\n",
    "\n",
    "# Then encode the joined topics\n",
    "df_articles, topics_encoded_col_name = convert_text2encoding_with_transformers(\n",
    "    df_articles,\n",
    "    transformer_tokenizer, \n",
    "    f\"{DEFAULT_TOPICS_COL}_joined\",\n",
    "    max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# Create mappings with encoded columns\n",
    "category_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=category_encoded_col_name\n",
    ")\n",
    "\n",
    "topic_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=topics_encoded_col_name\n",
    ")\n",
    "# Create mappings for numerical features\n",
    "pageviews_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_TOTAL_PAGEVIEWS_COL\n",
    ")\n",
    "\n",
    "read_time_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_TOTAL_READ_TIME_COL\n",
    ")\n",
    "\n",
    "sentiment_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_SENTIMENT_SCORE_COL\n",
    ")\n",
    "\n",
    "timestamp_mapping = create_article_id_to_value_mapping(\n",
    "    df_articles,\n",
    "    value_col=DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(23427, 7)\n",
      "Data preprocessing completed in 5.68 seconds.\n",
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(24309, 7)\n",
      "Data preprocessing completed in 15.17 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NRMSDataSet(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    category_mapping=category_mapping,\n",
    "    topic_mapping=topic_mapping,\n",
    "    pageviews_mapping=pageviews_mapping,\n",
    "    read_time_mapping=read_time_mapping,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    timestamp_mapping=timestamp_mapping\n",
    "\n",
    ")\n",
    "val_dataset = NRMSDataSet(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    category_mapping=category_mapping,\n",
    "    topic_mapping=topic_mapping,\n",
    "    pageviews_mapping=pageviews_mapping,\n",
    "    read_time_mapping=read_time_mapping,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    timestamp_mapping=timestamp_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 390458902\n",
      "Sample 1:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 316312864\n",
      "Sample 2:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 150454282\n",
      "Sample 3:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 507899156\n",
      "Sample 4:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 508776742\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    sample = train_dataset[idx]\n",
    "    print(f\"Sample {idx}:\")\n",
    "    print(f\"his_input_title shape: {sample[0][0].shape}\")\n",
    "    print(f\"pred_input_title shape: {sample[0][1].shape} {sample[0][1].sum()}\")\n",
    "    print(f\"pred_input_category shape: {sample[0][2].shape} {sample[0][2].sum()}\")\n",
    "    print(f\"pred_input_topic shape: {sample[0][3].shape} {sample[0][3].sum()}\")\n",
    "    print(f\"pred_input_pageviews shape: {sample[0][4].shape} {sample[0][4].sum()}\")\n",
    "    print(f\"Targets shape: {sample[1].shape} , {sample[1].dtype} {sample[1].sum()}\")\n",
    "    print(f\"impression id: {sample[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def collate_fn_with_global_padding(batch, max_len_pred, apply_padding_to_targets=True):\n",
    "    try:\n",
    "        # Unpack all features including timestamps from dataset samples\n",
    "        his_input_titles = [item[0][0] for item in batch]\n",
    "        his_category_emb = [item[0][1] for item in batch]\n",
    "        his_topic_emb = [item[0][2] for item in batch]\n",
    "        his_sentiment_scores = [item[0][3] for item in batch]\n",
    "        his_read_times = [item[0][4] for item in batch]\n",
    "        his_pageviews = [item[0][5] for item in batch]\n",
    "        his_timestamps = [item[0][6] for item in batch]\n",
    "\n",
    "        pred_input_titles = [item[0][7] for item in batch]\n",
    "        pred_category_emb = [item[0][8] for item in batch]\n",
    "        pred_topic_emb = [item[0][9] for item in batch]\n",
    "        pred_sentiment_scores = [item[0][10] for item in batch]\n",
    "        pred_read_times = [item[0][11] for item in batch]\n",
    "        pred_pageviews = [item[0][12] for item in batch]\n",
    "        pred_timestamps = [item[0][13] for item in batch]\n",
    "        impression_timestamps = [item[0][14] for item in batch]\n",
    "\n",
    "        batch_ys = [item[1] for item in batch]\n",
    "        impression_id = torch.tensor([item[2] for item in batch], dtype=torch.int64)\n",
    "\n",
    "        # Pad user history features\n",
    "        his_input_titles_padded = pad_sequence(his_input_titles, batch_first=True, padding_value=0)\n",
    "        his_category_emb_padded = pad_sequence(his_category_emb, batch_first=True, padding_value=0)\n",
    "        his_topic_emb_padded = pad_sequence(his_topic_emb, batch_first=True, padding_value=0)\n",
    "        his_sentiment_padded = pad_sequence(his_sentiment_scores, batch_first=True, padding_value=0)\n",
    "        his_read_times_padded = pad_sequence(his_read_times, batch_first=True, padding_value=0)\n",
    "        his_pageviews_padded = pad_sequence(his_pageviews, batch_first=True, padding_value=0)\n",
    "        his_timestamps_padded = pad_sequence(his_timestamps, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Pad candidate features\n",
    "        pred_input_titles_padded = pad_sequence(pred_input_titles, batch_first=True, padding_value=0)\n",
    "        pred_category_emb_padded = pad_sequence(pred_category_emb, batch_first=True, padding_value=0)\n",
    "        pred_topic_emb_padded = pad_sequence(pred_topic_emb, batch_first=True, padding_value=0)\n",
    "        pred_sentiment_padded = pad_sequence(pred_sentiment_scores, batch_first=True, padding_value=0)\n",
    "        pred_read_times_padded = pad_sequence(pred_read_times, batch_first=True, padding_value=0)\n",
    "        pred_pageviews_padded = pad_sequence(pred_pageviews, batch_first=True, padding_value=0)\n",
    "        pred_timestamps_padded = pad_sequence(pred_timestamps, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # Convert impression timestamps to tensor\n",
    "        impression_timestamps = torch.stack(impression_timestamps)\n",
    "\n",
    "        # Handle max_len_pred for candidate sequences\n",
    "        if pred_input_titles_padded.size(1) < max_len_pred:\n",
    "            pad_size = max_len_pred - pred_input_titles_padded.size(1)\n",
    "            \n",
    "            pred_input_titles_padded = torch.nn.functional.pad(pred_input_titles_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_category_emb_padded = torch.nn.functional.pad(pred_category_emb_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_topic_emb_padded = torch.nn.functional.pad(pred_topic_emb_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_sentiment_padded = torch.nn.functional.pad(pred_sentiment_padded, (0, pad_size), value=0)\n",
    "            pred_read_times_padded = torch.nn.functional.pad(pred_read_times_padded, (0, pad_size), value=0)\n",
    "            pred_pageviews_padded = torch.nn.functional.pad(pred_pageviews_padded, (0, pad_size), value=0)\n",
    "            pred_timestamps_padded = torch.nn.functional.pad(pred_timestamps_padded, (0, pad_size), value=0)\n",
    "\n",
    "        elif pred_input_titles_padded.size(1) > max_len_pred:\n",
    "            pred_input_titles_padded = pred_input_titles_padded[:, :max_len_pred, :]\n",
    "            pred_category_emb_padded = pred_category_emb_padded[:, :max_len_pred, :]\n",
    "            pred_topic_emb_padded = pred_topic_emb_padded[:, :max_len_pred, :]\n",
    "            pred_sentiment_padded = pred_sentiment_padded[:, :max_len_pred]\n",
    "            pred_read_times_padded = pred_read_times_padded[:, :max_len_pred]\n",
    "            pred_pageviews_padded = pred_pageviews_padded[:, :max_len_pred]\n",
    "            pred_timestamps_padded = pred_timestamps_padded[:, :max_len_pred]\n",
    "\n",
    "        # Handle targets padding\n",
    "        if apply_padding_to_targets:\n",
    "            batch_ys_padded = pad_sequence(batch_ys, batch_first=True, padding_value=-1)\n",
    "            if batch_ys_padded.size(1) < max_len_pred:\n",
    "                pad_size = max_len_pred - batch_ys_padded.size(1)\n",
    "                batch_ys_padded = torch.nn.functional.pad(batch_ys_padded, (0, pad_size), value=-1)\n",
    "            elif batch_ys_padded.size(1) > max_len_pred:\n",
    "                batch_ys_padded = batch_ys_padded[:, :max_len_pred]\n",
    "\n",
    "            return (\n",
    "                his_input_titles_padded,\n",
    "                his_category_emb_padded,\n",
    "                his_topic_emb_padded, \n",
    "                his_sentiment_padded,\n",
    "                his_read_times_padded,\n",
    "                his_pageviews_padded,\n",
    "                his_timestamps_padded,\n",
    "                pred_input_titles_padded,\n",
    "                pred_category_emb_padded,\n",
    "                pred_topic_emb_padded,\n",
    "                pred_sentiment_padded,\n",
    "                pred_read_times_padded,\n",
    "                pred_pageviews_padded,\n",
    "                pred_timestamps_padded,\n",
    "                impression_timestamps\n",
    "            ), batch_ys_padded, impression_id\n",
    "        else:\n",
    "            return (\n",
    "                his_input_titles_padded,\n",
    "                his_category_emb_padded,\n",
    "                his_topic_emb_padded,\n",
    "                his_sentiment_padded,\n",
    "                his_read_times_padded,\n",
    "                his_pageviews_padded,\n",
    "                his_timestamps_padded,\n",
    "                pred_input_titles_padded,\n",
    "                pred_category_emb_padded,\n",
    "                pred_topic_emb_padded,\n",
    "                pred_sentiment_padded,\n",
    "                pred_read_times_padded,\n",
    "                pred_pageviews_padded,\n",
    "                pred_timestamps_padded,\n",
    "                impression_timestamps\n",
    "            ), batch_ys, impression_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the dataset with DataLoader\n",
    "train_dataloader_temp = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,    # Set your desired batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_train)\n",
    ")\n",
    "\n",
    "val_dataloader_temp = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,    # Set your desired batch size\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History features shapes:\n",
      "his_input_titles: torch.Size([64, 20, 300])\n",
      "his_category_emb: torch.Size([64, 20, 128])\n",
      "his_topic_emb: torch.Size([64, 20, 128])\n",
      "his_sentiment: torch.Size([64, 20])\n",
      "his_read_times: torch.Size([64, 20])\n",
      "his_pageviews: torch.Size([64, 20])\n",
      "his_timestamps: torch.Size([64, 20])\n",
      "\n",
      "Candidate features shapes:\n",
      "pred_input_titles: torch.Size([64, 88, 300])\n",
      "pred_category_emb: torch.Size([64, 88, 128])\n",
      "pred_topic_emb: torch.Size([64, 88, 128])\n",
      "pred_sentiment: torch.Size([64, 88])\n",
      "pred_read_times: torch.Size([64, 88])\n",
      "pred_pageviews: torch.Size([64, 88])\n",
      "pred_timestamps: torch.Size([64, 88])\n",
      "\n",
      "Other tensors:\n",
      "impression_timestamps: torch.Size([64])\n",
      "batch_ys: torch.Size([64, 88])\n",
      "impression_id: torch.Size([64])\n",
      "\n",
      "Batch loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataloader_temp:\n",
    "    (\n",
    "        his_input_titles_padded, \n",
    "        his_category_emb_padded,\n",
    "        his_topic_emb_padded,\n",
    "        his_sentiment_padded,\n",
    "        his_read_times_padded,\n",
    "        his_pageviews_padded,\n",
    "        his_timestamps_padded,\n",
    "        pred_input_titles_padded,\n",
    "        pred_category_emb_padded,\n",
    "        pred_topic_emb_padded,\n",
    "        pred_sentiment_padded,\n",
    "        pred_read_times_padded,\n",
    "        pred_pageviews_padded,\n",
    "        pred_timestamps_padded,\n",
    "        impression_timestamps\n",
    "    ), batch_ys_padded, impression_id = batch\n",
    "\n",
    "    # Original tensor shapes\n",
    "    print(\"History features shapes:\")\n",
    "    print(f\"his_input_titles: {his_input_titles_padded.shape}\")\n",
    "    print(f\"his_category_emb: {his_category_emb_padded.shape}\")\n",
    "    print(f\"his_topic_emb: {his_topic_emb_padded.shape}\")\n",
    "    print(f\"his_sentiment: {his_sentiment_padded.shape}\")\n",
    "    print(f\"his_read_times: {his_read_times_padded.shape}\")\n",
    "    print(f\"his_pageviews: {his_pageviews_padded.shape}\")\n",
    "    print(f\"his_timestamps: {his_timestamps_padded.shape}\")\n",
    "\n",
    "    print(\"\\nCandidate features shapes:\")\n",
    "    print(f\"pred_input_titles: {pred_input_titles_padded.shape}\")\n",
    "    print(f\"pred_category_emb: {pred_category_emb_padded.shape}\")\n",
    "    print(f\"pred_topic_emb: {pred_topic_emb_padded.shape}\")\n",
    "    print(f\"pred_sentiment: {pred_sentiment_padded.shape}\")\n",
    "    print(f\"pred_read_times: {pred_read_times_padded.shape}\")\n",
    "    print(f\"pred_pageviews: {pred_pageviews_padded.shape}\")\n",
    "    print(f\"pred_timestamps: {pred_timestamps_padded.shape}\")\n",
    "    \n",
    "    print(\"\\nOther tensors:\")\n",
    "    print(f\"impression_timestamps: {impression_timestamps.shape}\")\n",
    "    print(f\"batch_ys: {batch_ys_padded.shape}\")\n",
    "    print(f\"impression_id: {impression_id.shape}\")\n",
    "\n",
    "    print(\"\\nBatch loaded successfully!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the shapes.\n",
    "\n",
    "1. `his_input_titles_padded: [128, 20, 300]`\n",
    "   - 128: batch size\n",
    "   - 20: max history length (user's reading history)\n",
    "   - 300: title embedding dimension from ConvBERT\n",
    "\n",
    "2. `pred_input_titles_padded: [128, 90, 300]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles to predict\n",
    "   - 300: title embedding dimension from ConvBERT\n",
    "\n",
    "3. `pred_category_emb_padded: [128, 90, 128]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - 128: category embedding dimension from ConvBERT\n",
    "\n",
    "4. `pred_topic_emb_padded: [128, 90, 128]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - 128: topic embedding dimension from ConvBERT\n",
    "\n",
    "5. `pred_sentiment_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single sentiment score per article\n",
    "\n",
    "6. `pred_read_times_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single read time value per article\n",
    "\n",
    "7. `pred_pageviews_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single pageview count per article\n",
    "\n",
    "8. `batch_ys_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Binary labels (1 for clicked, 0 for not clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'models_pytorch.model_config', '__annotations__': {'title_size': <class 'int'>, 'embedding_dim': <class 'int'>, 'word_emb_dim': <class 'int'>, 'vocab_size': <class 'int'>, 'head_num': <class 'int'>, 'head_dim': <class 'int'>, 'attention_hidden_dim': <class 'int'>, 'optimizer': <class 'str'>, 'loss': <class 'str'>, 'dropout': <class 'float'>, 'learning_rate': <class 'float'>, 'weight_decay': <class 'float'>, 'units_per_layer': list[int], 'use_category': <class 'bool'>, 'use_topic': <class 'bool'>, 'use_numeric': <class 'bool'>, 'use_session_discount': <class 'bool'>, 'use_publication_discount': <class 'bool'>, 'doc_out_dim': <class 'int'>, 'cat_out_dim': <class 'int'>, 'top_out_dim': <class 'int'>, 'numeric_proj_dim': <class 'int'>}, 'title_size': 300, 'embedding_dim': 32, 'word_emb_dim': 8, 'vocab_size': 10000, 'head_num': 16, 'head_dim': 128, 'attention_hidden_dim': 128, 'hidden_dim': 4, 'optimizer': 'adam', 'loss': 'cross_entropy_loss', 'dropout': 0.3, 'learning_rate': 0.0001, 'weight_decay': 0.001, 'news_output_dim': 128, 'units_per_layer': [512, 256], 'use_category': True, 'use_topic': True, 'use_numeric': True, 'use_session_discount': True, 'use_publication_discount': True, 'doc_out_dim': 128, 'cat_out_dim': 128, 'top_out_dim': 128, 'numeric_proj_dim': 16, '__dict__': <attribute '__dict__' of 'hparams_nrms' objects>, '__weakref__': <attribute '__weakref__' of 'hparams_nrms' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# see the model parameters: \n",
    "hparams_nrms.attention_hidden_dim = 128\n",
    "hparams_nrms.title_size = 300\n",
    "hparams_nrms.head_num = 16\n",
    "hparams_nrms.head_dim = 128\n",
    "hparams_nrms.units_per_layer = [512,256]\n",
    "hparams_nrms.news_output_dim = 128\n",
    "hparams_nrms.dropout = 0.3\n",
    "hparams_nrms.learning_rate = 1e-4\n",
    "hparams_nrms.use_category = True\n",
    "hparams_nrms.use_topic = True\n",
    "hparams_nrms.use_numeric = True\n",
    "hparams_nrms.use_publication_discount = True\n",
    "hparams_nrms.use_session_discount = True\n",
    "print(hparams_nrms.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "  Value:  3.8567059058842696\n",
    "  Params: \n",
    "    head_num: 16\n",
    "    shared_dim: 99\n",
    "    dropout: 0.17498541169326048\n",
    "    learning_rate: 1.0454050068420554e-05\n",
    "    weight_decay: 0.006587407554797856\n",
    "    unit_layer_1: 421\n",
    "    unit_layer_2: 386\n",
    "    use_category: False\n",
    "    use_topic: False\n",
    "    use_numeric: True\n",
    "    use_publication_discount: False\n",
    "    use_session_discount: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters with best trial results\n",
    "\n",
    "# Keep original parameters\n",
    "hparams_nrms.title_size = 300\n",
    "\n",
    "# Update with optimized parameters\n",
    "hparams_nrms.head_num = 4\n",
    "shared_dim = 140  # Rounded up 137 to nearest multiple of head_num\n",
    "hparams_nrms.head_dim = shared_dim\n",
    "hparams_nrms.attention_hidden_dim = shared_dim\n",
    "hparams_nrms.news_output_dim = shared_dim\n",
    "\n",
    "# Update layers\n",
    "hparams_nrms.units_per_layer = [257, 475]  # From optimization\n",
    "\n",
    "# Update learning parameters\n",
    "hparams_nrms.dropout = 0.208\n",
    "hparams_nrms.learning_rate = 8.486e-4\n",
    "hparams_nrms.weight_decay = 1.697e-3\n",
    "\n",
    "# Update feature flags based on optimization\n",
    "hparams_nrms.use_category = True\n",
    "hparams_nrms.use_topic = False\n",
    "hparams_nrms.use_numeric = False\n",
    "hparams_nrms.use_publication_discount = False\n",
    "hparams_nrms.use_session_discount = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters with best trial results\n",
    "\n",
    "# Keep original parameters\n",
    "hparams_nrms.title_size = 300\n",
    "\n",
    "# Update with optimized parameters\n",
    "hparams_nrms.head_num = 16\n",
    "shared_dim = 96  # Rounded up 137 to nearest multiple of head_num\n",
    "hparams_nrms.head_dim = shared_dim\n",
    "hparams_nrms.attention_hidden_dim = shared_dim\n",
    "hparams_nrms.news_output_dim = shared_dim\n",
    "\n",
    "# Update layers\n",
    "hparams_nrms.units_per_layer = [421, 386]  # From optimization\n",
    "\n",
    "# Update learning parameters\n",
    "hparams_nrms.dropout = 0.1749\n",
    "hparams_nrms.learning_rate = 1.0454050068420554e-05\n",
    "hparams_nrms.weight_decay = 0.006587407554797856\n",
    "\n",
    "# Update feature flags based on optimization\n",
    "hparams_nrms.use_category = False\n",
    "hparams_nrms.use_topic = False\n",
    "hparams_nrms.use_numeric = False\n",
    "hparams_nrms.use_publication_discount = True\n",
    "hparams_nrms.use_session_discount = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\models_pytorch\\NRMSDocVecModel.py:300: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define paths\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = os.path.join(\"downloads\", \"runs\", MODEL_NAME)\n",
    "MODEL_WEIGHTS = os.path.join(\"downloads\", \"data\", \"state_dict\", MODEL_NAME, \"weights.pth\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_WEIGHTS), exist_ok=True)\n",
    "\n",
    "# Define ModelCheckpoint class\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Saves the model after every epoch if it has the best performance so far.\"\"\"\n",
    "    def __init__(self, filepath, verbose=False, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath (str): Path to save the model checkpoint.\n",
    "            verbose (bool): If True, prints a message when the model is saved.\n",
    "            save_best_only (bool): If True, saves only when the model is better than before.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_loss = None\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.filepath)\n",
    "        if self.verbose:\n",
    "            print(f\"Model saved to {self.filepath}\")\n",
    "\n",
    "# Define EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve by a given percentage over a patience period.\"\"\"\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after last time validation loss improved by min_delta.\n",
    "            min_delta (float): Minimum percentage improvement required to reset patience.\n",
    "            verbose (bool): If True, prints a message when early stopping is triggered.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta  # Minimum percentage improvement\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            # Initialize best_loss with the first validation loss\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss < self.best_loss * (1 - self.min_delta):\n",
    "            # Significant improvement found\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved by at least {self.min_delta*100:.1f}%\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No significant improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "# Initialize callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_WEIGHTS, verbose=True, save_best_only=True)\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "\n",
    "# Initialize your model\n",
    "# Ensure that NRMSModel is a PyTorch nn.Module\n",
    "\n",
    "# CUDA checks\n",
    "#print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "#print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "#print(f\"Device Name: {torch.cuda.get_device_name()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "# model = NRMSModel(\n",
    "#     hparams=hparams_nrms.__dict__,\n",
    "#     word2vec_embedding=word2vec_embedding,\n",
    "#     vocab_size=30000,\n",
    "#     word_emb_dim=8,\n",
    "#     device=device,\n",
    "#     feed_forward_layers_after_3rd_layer=False,\n",
    "# )\n",
    "\n",
    "model = NRMSDocVecModel(hparams=hparams_nrms.__dict__,\n",
    "                        device=device)\n",
    "\n",
    "# model = NRMSModel(hparams=hparams_nrms.__dict__,\n",
    "#                   word2vec_embedding=word2vec_embedding,\n",
    "#                         device=device)\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSDocVecModel(\n",
      "  (newsencoder): NewsEncoderDocVec(\n",
      "    (doc_encoder): DocEncoder(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Dropout(p=0.1749, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (feature_fusion): FeatureFusion(\n",
      "      (linears): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "      )\n",
      "      (gates): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "      )\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (time_discount): TimeDiscount(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (userencoder): UserEncoderDocVec(\n",
      "    (titleencoder): NewsEncoderDocVec(\n",
      "      (doc_encoder): DocEncoder(\n",
      "        (layer): Sequential(\n",
      "          (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Dropout(p=0.1749, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (feature_fusion): FeatureFusion(\n",
      "        (linears): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "        )\n",
      "        (gates): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=96, bias=True)\n",
      "        )\n",
      "        (activation): Sigmoid()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      (time_discount): TimeDiscount(\n",
      "        (layer): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (multihead_attention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=96, out_features=96, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (attention_layer): AttLayer2(\n",
      "      (V_w): Linear(in_features=96, out_features=96, bias=True)\n",
      "      (q_w): Linear(in_features=96, out_features=1, bias=False)\n",
      "    )\n",
      "    (user_projection): Linear(in_features=96, out_features=96, bias=True)\n",
      "    (layer_norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    (time_discount): TimeDiscount(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer: newsencoder.doc_encoder.layer.0.weight | Size: torch.Size([128, 300])\n",
      "Layer: newsencoder.doc_encoder.layer.0.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.doc_encoder.layer.2.weight | Size: torch.Size([128])\n",
      "Layer: newsencoder.doc_encoder.layer.2.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.feature_fusion.linears.0.weight | Size: torch.Size([96, 128])\n",
      "Layer: newsencoder.feature_fusion.linears.0.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.feature_fusion.gates.0.weight | Size: torch.Size([96, 128])\n",
      "Layer: newsencoder.feature_fusion.gates.0.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.layer_norm.weight | Size: torch.Size([96])\n",
      "Layer: newsencoder.layer_norm.bias | Size: torch.Size([96])\n",
      "Layer: newsencoder.time_discount.layer.0.weight | Size: torch.Size([1, 1])\n",
      "Layer: newsencoder.time_discount.layer.0.bias | Size: torch.Size([1])\n",
      "Layer: userencoder.self_attention.multihead_attention.in_proj_weight | Size: torch.Size([288, 96])\n",
      "Layer: userencoder.self_attention.multihead_attention.in_proj_bias | Size: torch.Size([288])\n",
      "Layer: userencoder.self_attention.multihead_attention.out_proj.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.self_attention.multihead_attention.out_proj.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.attention_layer.V_w.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.attention_layer.V_w.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.attention_layer.q_w.weight | Size: torch.Size([1, 96])\n",
      "Layer: userencoder.user_projection.weight | Size: torch.Size([96, 96])\n",
      "Layer: userencoder.user_projection.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.layer_norm.weight | Size: torch.Size([96])\n",
      "Layer: userencoder.layer_norm.bias | Size: torch.Size([96])\n",
      "Layer: userencoder.time_discount.layer.0.weight | Size: torch.Size([1, 1])\n",
      "Layer: userencoder.time_discount.layer.0.bias | Size: torch.Size([1])\n",
      "\n",
      "Total parameters: 119,908\n"
     ]
    }
   ],
   "source": [
    "# 1. Print model architecture\n",
    "print(model)\n",
    "\n",
    "# 2. Print specific layer sizes\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")\n",
    "\n",
    "# 3. Get total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "\n",
    "# 4. Print layer by layer with shapes\n",
    "def print_model_structure(model):\n",
    "    print(\"\\nDetailed Model Structure:\")\n",
    "    for name, module in model.named_children():\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Type: {type(module).__name__}\")\n",
    "        if hasattr(module, 'weight'):\n",
    "            print(f\"Shape: {module.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Added gradient clipping to avoid exploiding gradients. The paramter MAX_GRAD_NORM is set to 5.0 as this is a common value used in transformers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperoptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# NUM_EPOCHS = 8\n",
    "# WEIGHT_DECAY = 1e-3\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define fixed valid head numbers\n",
    "#     possible_head_nums = [2, 4, 8, 16, 32]\n",
    "    \n",
    "#     # First suggest head_num from fixed choices\n",
    "#     head_num = trial.suggest_categorical('head_num', possible_head_nums)\n",
    "    \n",
    "#     # Suggest shared_dim that's divisible by head_num\n",
    "#     min_dim = max(64, head_num)  # Ensure minimum dimension works with head_num\n",
    "#     max_dim = 256\n",
    "#     shared_dim = trial.suggest_int('shared_dim', min_dim, max_dim)\n",
    "    \n",
    "#     # Round shared_dim to nearest multiple of head_num\n",
    "#     shared_dim = (shared_dim // head_num) * head_num\n",
    "    \n",
    "#     # Skip if dimensions don't work\n",
    "#     if shared_dim < head_num:\n",
    "#         raise optuna.TrialPruned()\n",
    "    \n",
    "#     hparams = {\n",
    "#         'title_size': 300,\n",
    "#         'head_num': head_num,\n",
    "#         'head_dim': shared_dim,\n",
    "#         'attention_hidden_dim':shared_dim,\n",
    "#         'news_output_dim': shared_dim,\n",
    "#         'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n",
    "#         'weight_decay': trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True),\n",
    "#         'units_per_layer': [\n",
    "#             trial.suggest_int('unit_layer_1', 256, 512),\n",
    "#             trial.suggest_int('unit_layer_2', 256, 512),\n",
    "#         ],\n",
    "#         'use_category': trial.suggest_categorical('use_category', [True, False]),\n",
    "#         'use_topic': trial.suggest_categorical('use_topic', [True, False]),\n",
    "#         'use_numeric': trial.suggest_categorical('use_numeric', [True, False]),\n",
    "#         'use_publication_discount': trial.suggest_categorical('use_publication_discount', [True, False]),\n",
    "#         'use_session_discount': trial.suggest_categorical('use_session_discount', [True, False])\n",
    "#     }\n",
    "\n",
    "#     # Initialize model and training components\n",
    "#     model = NRMSDocVecModel(hparams=hparams, device=device)\n",
    "#     criterion = model.get_loss().to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), \n",
    "#                           lr=hparams['learning_rate'], \n",
    "#                           weight_decay=hparams['weight_decay'])\n",
    "    \n",
    "#     # Initialize EarlyStopping\n",
    "#     early_stopping = EarlyStopping(patience=4, min_delta=0.025, verbose=True)\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         train_batch_count = 0\n",
    "\n",
    "#         for batch in train_dataloader_temp:\n",
    "#             inputs, targets, impression_id = batch\n",
    "#             inputs = [inp.to(device) for inp in inputs]\n",
    "#             targets = targets.to(device)\n",
    "#             positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#             targets = positive_indices[:, 1].long()\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(*inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             train_batch_count += 1\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         val_batch_count = 0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_dataloader_temp:\n",
    "#                 inputs, targets, impression_id = batch\n",
    "#                 inputs = [inp.to(device) for inp in inputs]\n",
    "#                 targets = targets.to(device)\n",
    "#                 positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#                 targets = positive_indices[:, 1].long()\n",
    "#                 outputs = model(*inputs)\n",
    "#                 loss = criterion(outputs, targets)\n",
    "#                 val_loss += loss.item()\n",
    "#                 val_batch_count += 1\n",
    "\n",
    "#         avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "\n",
    "#         # Update best validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "\n",
    "#         # Early stopping check\n",
    "#         early_stopping(avg_val_loss)\n",
    "#         if early_stopping.early_stop:\n",
    "#             break\n",
    "\n",
    "#         # Report to Optuna\n",
    "#         trial.report(avg_val_loss, epoch)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "\n",
    "#     return best_val_loss\n",
    "\n",
    "# # Create study and optimize\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=15)  # Increased from 3 to 50 trials\n",
    "\n",
    "# # Print results\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\.venv\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Training Progress:   0%|          | 0/15 [00:00<?, ?it/s]c:\\Users\\gusta\\Documents\\Deeplearning-RecSys-Challenge-2024\\models_pytorch\\NRMSDocVecModel.py:325: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Training Progress:  67%|██████▋   | 10/15 [03:13<01:33, 18.78s/it, train_loss=1.6353, val_loss=2.4741]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at epoch 10 with validation loss: 2.4741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  93%|█████████▎| 14/15 [04:31<00:19, 19.02s/it, train_loss=1.5160, val_loss=2.3750]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 15/15 [04:50<00:00, 19.36s/it, train_loss=1.4973, val_loss=2.3703]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure you have defined or imported the EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif current_score < self.best_score - self.min_delta:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Define model_checkpoint function if not already defined\n",
    "def model_checkpoint(model, val_loss, epoch, path='model_checkpoint.pth'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "    }, path)\n",
    "    print(f\"Model checkpoint saved at epoch {epoch} with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "# Initialize components\n",
    "NUM_EPOCHS = 15\n",
    "early_stopping = EarlyStopping(patience=4, min_delta=0.025, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Use appropriate loss function\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=hparams_nrms.learning_rate,  # Ensure hparams_nrms is defined and has learning_rate\n",
    "    weight_decay=hparams_nrms.weight_decay  # Ensure hparams_nrms has weight_decay\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Ensure your dataloaders are defined\n",
    "# train_dataloader_temp = ...\n",
    "# val_dataloader_temp = ...\n",
    "\n",
    "epoch_pbar = tqdm(range(1, NUM_EPOCHS + 1), desc=\"Training Progress\", dynamic_ncols=True)\n",
    "for epoch in epoch_pbar:\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch in train_dataloader_temp:\n",
    "        inputs, targets, _ = batch  # Assuming the third element is not used\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Extract positive indices\n",
    "        positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "        if positive_indices.numel() == 0:\n",
    "            raise ValueError(\"No positive samples in the batch\")\n",
    "            continue  # Skip if no positive samples in the batch\n",
    "        targets = positive_indices[:, 1].long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs)  # Shape: (N, C)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    avg_train_loss = running_loss / train_batch_count if train_batch_count > 0 else float('inf')\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader_temp:\n",
    "            inputs, targets, _ = batch\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "            if positive_indices.numel() == 0:\n",
    "                continue\n",
    "            targets = positive_indices[:, 1].long()\n",
    "\n",
    "            outputs = model(*inputs)  # Shape: (N, C)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_batch_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Logging\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "\n",
    "    # Update Progress Bar\n",
    "    epoch_pbar.set_postfix({\n",
    "        'train_loss': f'{avg_train_loss:.4f}',\n",
    "        'val_loss': f'{avg_val_loss:.4f}',\n",
    "    })\n",
    "\n",
    "    # Save Checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        model_checkpoint(model, avg_val_loss, epoch)\n",
    "\n",
    "    # Scheduler Step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Summary:\n",
      "Initial Training Loss: 7.0979\n",
      "Final Training Loss: 1.4973\n",
      "Best Training Loss: 1.4973\n",
      "\n",
      "Initial Validation Loss: 8.8001\n",
      "Final Validation Loss: 2.3703\n",
      "Best Validation Loss: 2.3703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"nrms_training_loss.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print final statistics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Initial Training Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Training Loss: {min(train_losses):.4f}\")\n",
    "print(f\"\\nInitial Validation Loss: {val_losses[0]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Validation Loss: {min(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def evaluate_model(model, dataloader, device):\n",
    "#     \"\"\"Evaluate the model and return predictions and labels for metric calculation.\"\"\"\n",
    "#     model.eval()\n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     print(\"\\nEvaluating DataLoader...\")\n",
    "#     total_samples = len(dataloader.dataset)\n",
    "#     print(f\"Total samples in DataLoader: {total_samples}\")\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets, impression_ids) in enumerate(dataloader):\n",
    "#             his_input_title, pred_input_title = inputs\n",
    "\n",
    "#             if batch_idx == 0:  # Debug first batch shapes\n",
    "#                 print(\"\\nFirst batch shapes:\")\n",
    "#                 print(f\"  - his_input_title: {his_input_title.shape}\")\n",
    "#                 print(f\"  - pred_input_title: {pred_input_title.shape}\")\n",
    "#                 print(f\"  - targets: {targets.shape}\")\n",
    "\n",
    "#             # Move data to device\n",
    "#             his_input_title = his_input_title.to(device)\n",
    "#             pred_input_title = pred_input_title.to(device)\n",
    "#             targets = targets.to(device)\n",
    "\n",
    "#             # Get predictions\n",
    "#             predictions = model.predict(his_input_title, pred_input_title)\n",
    "#             predictions = predictions.cpu().numpy()\n",
    "#             targets = targets.cpu().numpy()\n",
    "\n",
    "#             # Process each sample in the batch\n",
    "#             batch_size = predictions.shape[0]\n",
    "#             for sample_idx in range(batch_size):\n",
    "#                 pred = predictions[sample_idx]\n",
    "#                 label = targets[sample_idx]\n",
    "\n",
    "#                 # Create valid_mask where label is not equal to the padding value (-1)\n",
    "#                 valid_mask = (label != -1)\n",
    "#                 sample_preds = pred[valid_mask]\n",
    "#                 sample_labels = label[valid_mask]\n",
    "\n",
    "#                 if len(sample_labels) == 0:\n",
    "#                     continue  # Skip empty samples\n",
    "\n",
    "#                 # Ensure that there is at least one positive and one negative label\n",
    "#                 if len(np.unique(sample_labels)) < 2:\n",
    "#                     continue  # Skip samples with only one class\n",
    "\n",
    "#                 all_predictions.append(sample_preds.tolist())\n",
    "#                 all_labels.append(sample_labels.tolist())\n",
    "\n",
    "#     print(\"\\nEvaluation completed.\")\n",
    "#     print(f\"Total predictions generated: {len(all_predictions)}\")\n",
    "#     print(f\"First few prediction lengths: {[len(x) for x in all_predictions[:15]]}\")\n",
    "#     return all_labels, all_predictions\n",
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# labels_list, scores_list = evaluate_model(model, val_dataloader_temp, device)\n",
    "\n",
    "# # Validate predictions against the DataFrame\n",
    "# print(\"\\nValidation against DataFrame:\")\n",
    "# if len(scores_list) != len(df_validation):\n",
    "#     print(\"WARNING: Length mismatch!\")\n",
    "#     print(f\"  - Number of predictions: {len(scores_list)}\")\n",
    "#     print(f\"  - Number of rows in DataFrame: {len(df_validation)}\")\n",
    "\n",
    "# # Compute metrics\n",
    "# metrics = MetricEvaluator(\n",
    "#     labels=labels_list,\n",
    "#     predictions=scores_list,\n",
    "#     metric_functions=[\n",
    "#         AucScore(),\n",
    "#         MrrScore(),\n",
    "#         NdcgScore(k=5),\n",
    "#         NdcgScore(k=10)\n",
    "#     ],\n",
    "# )\n",
    "# results = metrics.evaluate()\n",
    "# print(\"\\nMetrics:\", results.evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRACTION: 0.1, HISTORY_SIZE: 20\n",
      "Hyperparameters:\n",
      "title_size: 300\n",
      "embedding_dim: 32\n",
      "word_emb_dim: 8\n",
      "vocab_size: 10000\n",
      "head_num: 16\n",
      "head_dim: 96\n",
      "attention_hidden_dim: 96\n",
      "hidden_dim: 4\n",
      "optimizer: adam\n",
      "loss: cross_entropy_loss\n",
      "dropout: 0.1749\n",
      "learning_rate: 1.0454050068420554e-05\n",
      "weight_decay: 0.006587407554797856\n",
      "news_output_dim: 96\n",
      "units_per_layer: [421, 386]\n",
      "use_category: False\n",
      "use_topic: False\n",
      "use_numeric: False\n",
      "use_session_discount: True\n",
      "use_publication_discount: True\n",
      "doc_out_dim: 128\n",
      "cat_out_dim: 128\n",
      "top_out_dim: 128\n",
      "numeric_proj_dim: 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"FRACTION: {FRACTION}, HISTORY_SIZE: {HISTORY_SIZE}\")\n",
    "\n",
    "# Filter out special Python attributes and print parameters\n",
    "params = {k: v for k, v in hparams_nrms.__dict__.items() if not k.startswith('__')}\n",
    "print(\"Hyperparameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_labels(df: pl.DataFrame, impression_id: int) -> int:\n",
    "    # Filter for matching impression_id\n",
    "    filtered = df.filter(pl.col('impression_id') == impression_id)\n",
    "    \n",
    "    if filtered.height == 0:\n",
    "        raise ValueError(f\"No row found for impression_id {impression_id}\")\n",
    "    \n",
    "    # Get labels from first row\n",
    "    labels = filtered.select('labels').row(0)[0]\n",
    "    \n",
    "    return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_length_of_labels(df_validation, 349992000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Label 1: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "Label 2: [0, 0, 1, 0, 0]\n",
      "Label 3: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Label 4: [1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 labels\n",
    "first_5_labels = df_validation.select('labels').head(5)\n",
    "\n",
    "# Print each label with index\n",
    "for i, row in enumerate(first_5_labels.iter_rows()):\n",
    "    print(f\"Label {i}: {row[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples with only one class\n",
      "Remaining valid samples: 24309\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize lists\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "skipped_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader_temp:\n",
    "        inputs, targets, impression_ids = batch\n",
    "        \n",
    "        # Move to device\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(*inputs)\n",
    "        \n",
    "        # Convert to probabilities if needed\n",
    "        if not torch.is_floating_point(predictions):\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Convert to lists while preserving structure\n",
    "        batch_preds = predictions.cpu().numpy().tolist()\n",
    "        batch_labels = targets.cpu().numpy().tolist()\n",
    "        impression_ids = impression_ids.cpu().numpy().tolist()\n",
    "        \n",
    "        batch_preds_without_padding = []\n",
    "        batch_labels_without_padding = []\n",
    "        \n",
    "        for pred_sample, label_sample, impression_id_sample in zip(batch_preds, batch_labels, impression_ids):\n",
    "            # Remove padding\n",
    "            actual_length = get_length_of_labels(df_validation, impression_id_sample)\n",
    "            pred_sample = pred_sample[:actual_length]\n",
    "            \n",
    "            # Check if sample has both classes before adding\n",
    "            if 1 in label_sample[:actual_length] and 0 in label_sample[:actual_length]:\n",
    "                batch_preds_without_padding.append(pred_sample)\n",
    "                batch_labels_without_padding.append(label_sample[:actual_length])\n",
    "            else:\n",
    "                skipped_samples += 1\n",
    "        \n",
    "        # Add batch predictions and labels\n",
    "        all_predictions.extend(batch_preds_without_padding)\n",
    "        all_labels.extend(batch_labels_without_padding)\n",
    "\n",
    "print(f\"Skipped {skipped_samples} samples with only one class\")\n",
    "print(f\"Remaining valid samples: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug: Print label distribution for first 5 samples\n",
    "# for i, (preds, labels) in enumerate(zip(all_predictions[:5], all_labels[:5])):\n",
    "#     print(f\"\\nSample {i}:\")\n",
    "#     print(f\"Labels length:      {len(labels)}\")\n",
    "#     print(f\"Predictions length: {len(preds)}\")\n",
    "#     print(f\"Num positives: {sum(labels)}\")\n",
    "#     print(f\"Num negatives: {len(labels) - sum(labels)}\")\n",
    "#     print(f\"Label distribution: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(all_predictions))\n",
    "# print(type(all_labels))\n",
    "\n",
    "# print(f\"Number of predictions: {len(all_predictions)}\")\n",
    "# print(f\"example prediction: {all_predictions[0:2]}\")\n",
    "# print(f\"Number of labels: {len(all_labels)}\")\n",
    "# print(f\"example label: {all_labels[0:2]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1725\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "correct_predictions = 0\n",
    "total_samples = len(all_predictions)\n",
    "\n",
    "# Iterate over samples\n",
    "for idx, _ in enumerate(all_predictions):\n",
    "    # print(f\"Sample {idx}: Prediction: {all_predictions[idx]}\")\n",
    "    # print(f\"Sample {idx}: Label:      {all_labels[idx]}\")\n",
    "    \n",
    "    # Extract index of maximum value in predictions and labels\n",
    "    pred_max_index = np.argmax(all_predictions[idx])\n",
    "    label_max_index = np.argmax(all_labels[idx])\n",
    "    \n",
    "    # Compare indices to determine if the prediction was correct\n",
    "    if pred_max_index == label_max_index:\n",
    "        # print(f\"Sample {idx}: Prediction was correct.\")\n",
    "        correct_predictions += 1\n",
    "  #  else:\n",
    "        # print(f\"Sample {idx}: Prediction was wrong.\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.5965\n",
      "Number of valid AUC calculations: 24309\n"
     ]
    }
   ],
   "source": [
    "from evaluation import AucScore\n",
    "\n",
    "# auc_score = AucScore()\n",
    "\n",
    "# auc_score.calculate(all_predictions, all_labels)\n",
    "# print(f\"AUC: {auc_score.score}\")\n",
    "# # Calculate AUC per sample\n",
    "aucs = []\n",
    "for preds, labels in zip(all_predictions, all_labels):\n",
    "    try:\n",
    "        # Only calculate if we have both positive and negative samples\n",
    "        if sum(labels) > 0 and sum(labels) < len(labels):\n",
    "            auc = roc_auc_score(labels, preds)\n",
    "            aucs.append(auc)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Only one class present in labels. Cannot calculate AUC.\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(aucs):.4f}\")\n",
    "print(f\"Number of valid AUC calculations: {len(aucs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
