{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.12\n",
      "PyTorch version: 2.4.1+cu124\n",
      "CUDA available: True\n",
      "Current GPU device: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL\n",
    ")\n",
    "\n",
    "from utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from utils._articles import convert_text2encoding_with_transformers\n",
    "from utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from utils._articles import create_article_id_to_value_mapping\n",
    "from utils._nlp import get_transformers_word_embeddings, generate_embeddings_with_transformers\n",
    "from utils._python import write_submission_file, rank_predictions_by_score\n",
    "from models_pytorch.model_config import hparams_nrms\n",
    "\n",
    "from models_pytorch.nrms import NRMSModel\n",
    "from models_pytorch.NRMSDocVecModel import NRMSDocVecModel\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from models_pytorch.dataloader import NRMSDataSet\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 64\n",
    "\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at behaviours and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebnerd_small\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"./ebnerd_small\")  # Base path for your data directory\n",
    "print(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>467624</td><td>[9770023, 9770594, … 9769457]</td><td>[9698639, 8422665, … 9771325]</td><td>[9771325]</td><td>42541964</td><td>[0, 0, … 1]</td></tr><tr><td>1037391</td><td>[9768129, 9768377, … 9770425]</td><td>[7306652, 9771051, … 9482380]</td><td>[9771051]</td><td>281047518</td><td>[0, 1, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 467624  ┆ [9770023,         ┆ [9698639,         ┆ [9771325]        ┆ 42541964      ┆ [0, 0, … 1] │\n",
       "│         ┆ 9770594, …        ┆ 8422665, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9769457]          ┆ 9771325]          ┆                  ┆               ┆             │\n",
       "│ 1037391 ┆ [9768129,         ┆ [7306652,         ┆ [9771051]        ┆ 281047518     ┆ [0, 1, … 0] │\n",
       "│         ┆ 9768377, …        ┆ 9771051, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9770425]          ┆ 9482380]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 20 # TODO: History size. \n",
    "FRACTION = 0.1\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of article_ids_inview in df_train: 5.0\n",
      "Average length of article_ids_inview in df_validation: 12.021787115761937\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_length(df, column):\n",
    "    total_length = sum(len(row) for row in df[column])\n",
    "    average_length = total_length / len(df)\n",
    "    return average_length\n",
    "\n",
    "# Calculate average length for df_train\n",
    "average_length_inview_train = calculate_average_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_train: {average_length_inview_train}\")\n",
    "\n",
    "# Calculate average length for df_validation\n",
    "average_length_inview_validation = calculate_average_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_validation: {average_length_inview_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest inview article length in df_train: 5\n",
      "Longest inview article length in df_validation: 87\n",
      "Longest history length in df_train: 20\n",
      "Longest history length in df_validation: 20\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Function to find the maximum length of arrays in a column\n",
    "def find_max_length(df, column):\n",
    "    max_length = 0\n",
    "    for row in df[column]:\n",
    "        max_length = max(max_length, len(row))\n",
    "    return max_length\n",
    "\n",
    "# Find the longest inview article length in df_train\n",
    "max_inview_length_train = find_max_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "# Find the longest inview article length in df_validation\n",
    "max_inview_length_validation = find_max_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "print(f\"Longest inview article length in df_train: {max_inview_length_train}\")\n",
    "print(f\"Longest inview article length in df_validation: {max_inview_length_validation}\")\n",
    "\n",
    "max_history_length_train = find_max_length(df_train, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "max_history_length_validation = find_max_length(df_validation, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "\n",
    "print(f\"Longest history length in df_train: {max_history_length_train}\")\n",
    "print(f\"Longest history length in df_validation: {max_history_length_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with exactly one clicked article in df_train: 23427\n",
      "Number of rows with exactly one clicked article in df_validation: 24322\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# Function to filter rows with exactly one clicked article\n",
    "def filter_rows_with_one_clicked_article(df, clicked_articles_col):\n",
    "    # Manually filter rows where the array has exactly one element\n",
    "    filtered_rows = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        if len(row[clicked_articles_col]) == 1:\n",
    "            filtered_rows.append(row)\n",
    "    return pl.DataFrame(filtered_rows)\n",
    "\n",
    "\n",
    "# Filter rows in df_train and df_validation\n",
    "df_train = filter_rows_with_one_clicked_article(df_train, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "df_validation = filter_rows_with_one_clicked_article(df_validation, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of rows with exactly one clicked article in df_train: {df_train.shape[0]}\")\n",
    "print(f\"Number of rows with exactly one clicked article in df_validation: {df_validation.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>1985027</td><td>[9768566, 9759681, … 9780271]</td><td>[9789386, 9789018, … 9787722]</td><td>[9787722]</td><td>265030513</td><td>[0, 0, … 1]</td></tr><tr><td>1556742</td><td>[9777769, 9779737, … 9779427]</td><td>[9779365, 9782059, … 9772508]</td><td>[9782059]</td><td>100766197</td><td>[0, 1, … 0]</td></tr><tr><td>2558190</td><td>[0, 0, … 9778657]</td><td>[9785471, 8952833, … 9486080]</td><td>[9538004]</td><td>39197204</td><td>[0, 0, … 0]</td></tr><tr><td>2350873</td><td>[9774944, 9776985, … 9777636]</td><td>[9783729, 9783213, … 9783965]</td><td>[9783213]</td><td>501256032</td><td>[0, 1, … 0]</td></tr><tr><td>36789</td><td>[9778971, 9776967, … 9778915]</td><td>[9080070, 9785260, … 9428643]</td><td>[9785260]</td><td>451925895</td><td>[0, 1, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ i64     ┆ list[i64]         ┆ ---               ┆ ---              ┆ i64           ┆ list[i64]   │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 1985027 ┆ [9768566,         ┆ [9789386,         ┆ [9787722]        ┆ 265030513     ┆ [0, 0, … 1] │\n",
       "│         ┆ 9759681, …        ┆ 9789018, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9780271]          ┆ 9787722]          ┆                  ┆               ┆             │\n",
       "│ 1556742 ┆ [9777769,         ┆ [9779365,         ┆ [9782059]        ┆ 100766197     ┆ [0, 1, … 0] │\n",
       "│         ┆ 9779737, …        ┆ 9782059, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9779427]          ┆ 9772508]          ┆                  ┆               ┆             │\n",
       "│ 2558190 ┆ [0, 0, … 9778657] ┆ [9785471,         ┆ [9538004]        ┆ 39197204      ┆ [0, 0, … 0] │\n",
       "│         ┆                   ┆ 8952833, …        ┆                  ┆               ┆             │\n",
       "│         ┆                   ┆ 9486080]          ┆                  ┆               ┆             │\n",
       "│ 2350873 ┆ [9774944,         ┆ [9783729,         ┆ [9783213]        ┆ 501256032     ┆ [0, 1, … 0] │\n",
       "│         ┆ 9776985, …        ┆ 9783213, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9777636]          ┆ 9783965]          ┆                  ┆               ┆             │\n",
       "│ 36789   ┆ [9778971,         ┆ [9080070,         ┆ [9785260]        ┆ 451925895     ┆ [0, 1, … 0] │\n",
       "│         ┆ 9776967, …        ┆ 9785260, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9778915]          ┆ 9428643]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in df_train: 8898\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users in df_train: {df_train['user_id'].n_unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>2007-03-27 10:22:08</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>2001-10-19 12:30:00</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>2003-01-09 06:00:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>2003-06-17 07:10:00</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>2003-07-13 19:50:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "DataFrame after tokenization:\n",
      "shape: (20_738, 21)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
      "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
      "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
      "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
      "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
      "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
      "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
      "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
      "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ 9803492   ┆ Vilde     ┆ Der er    ┆ 2023-06-2 ┆ … ┆ 100120    ┆ 4.112624e ┆ 0.6095    ┆ Neutral  │\n",
      "│           ┆ billeder: ┆ gang i    ┆ 9         ┆   ┆           ┆ 6         ┆           ┆          │\n",
      "│           ┆ Vulkan i  ┆ vulkanen  ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ udbru…    ┆ på Hawa…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803505   ┆ Flyvende  ┆ Verdens   ┆ 2023-06-2 ┆ … ┆ 959       ┆ 55691.0   ┆ 0.8884    ┆ Positive │\n",
      "│           ┆ Antonsen  ┆ nummer    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ knuser    ┆ syv, Chou ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ topsp…    ┆ Tien-…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803525   ┆ Dansk sku ┆ Julie R.  ┆ 2023-06-2 ┆ … ┆ 50361     ┆ 2.550671e ┆ 0.7737    ┆ Negative │\n",
      "│           ┆ espiller: ┆ Ølgaard   ┆ 9         ┆   ┆           ┆ 6         ┆           ┆          │\n",
      "│           ┆ - Jeg     ┆ fik akut  ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ nægte…    ┆ kejs…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803560   ┆ Så slemt  ┆ Tusindvis ┆ 2023-06-2 ┆ … ┆ 1237      ┆ 67514.0   ┆ 0.9927    ┆ Negative │\n",
      "│           ┆ er det:   ┆ af huse   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ 14.000    ┆ står      ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ huse e…   ┆ under v…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803607   ┆ Aktion    ┆ Flere     ┆ 2023-06-2 ┆ … ┆ 79590     ┆ 3.69476e6 ┆ 0.9948    ┆ Negative │\n",
      "│           ┆ mod svind ┆ kvinder   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ lere:     ┆ er ifølge ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Seks per… ┆ politi…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# LOAD HUGGINGFACE and move to device immediately:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME).to(device)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# # We'll init the word embeddings using the\n",
    "# word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "\n",
    "# # Concatenate text columns\n",
    "# df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "\n",
    "# # Get tokenized version\n",
    "# df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "#     df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    "# )\n",
    "\n",
    "print(\"DataFrame after tokenization:\")\n",
    "print(df_articles)\n",
    "\n",
    "# print(df_articles[token_col_title][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding tokenized article title + subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 649/649 [01:00<00:00, 10.71text/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from utils._python import batch_items_generator\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "n_batches = int(np.ceil(df_articles.height / BATCH_SIZE))\n",
    "\n",
    "chunked_text_list = batch_items_generator(df_articles[DEFAULT_TITLE_COL].to_list(), BATCH_SIZE)\n",
    "embeddings = (\n",
    "    generate_embeddings_with_transformers(\n",
    "        model=transformer_model,\n",
    "        tokenizer=transformer_tokenizer,\n",
    "        text_list=text_list,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "    for text_list in tqdm(\n",
    "        chunked_text_list, desc=\"Encoding\", total=n_batches, unit=\"text\"\n",
    "    )\n",
    ")\n",
    "embeddings = torch.vstack(list(embeddings))\n",
    "\n",
    "embedded_title = f\"{DEFAULT_TITLE_COL}_embedded\"\n",
    "\n",
    "df_articles = df_articles.with_columns(pl.Series(embedded_title, embeddings.to(\"cpu\").numpy()))\n",
    "\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=embedded_title\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 20738\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of articles: {len(article_mapping)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "Data preprocessing completed in 4.45 seconds.\n",
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "Data preprocessing completed in 5.45 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NRMSDataSet(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    ")\n",
    "val_dataset = NRMSDataSet(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(5):\n",
    "#     sample = train_dataset[idx]\n",
    "#     print(f\"Sample {idx}:\")\n",
    "#     print(f\"his_input_title shape: {sample[0][0].shape}\")\n",
    "#     print(f\"pred_input_title shape: {sample[0][1].shape} {sample[0][1].sum()}\")\n",
    "#     print(f\"Targets shape: {sample[1].shape} , {sample[1].dtype} {sample[1].sum()}\")\n",
    "#     print(f\"impression id: {sample[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_fn_with_global_padding(batch, max_len_pred, apply_padding_to_targets : bool = True):\n",
    "    try:\n",
    "        his_input_titles = [item[0][0] for item in batch]  # History inputs\n",
    "        pred_input_titles = [item[0][1] for item in batch]  # Prediction inputs\n",
    "        batch_ys = [item[1] for item in batch]  # Targets\n",
    "        impression_id = torch.tensor([item[2] for item in batch], dtype=torch.int64)  # Impression ID\n",
    "        \n",
    "\n",
    "        # Pad sequences to the global maximum length\n",
    "        his_input_titles_padded = pad_sequence(his_input_titles, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Pad prediction inputs and adjust to the global maximum length\n",
    "        pred_input_titles_padded = pad_sequence(pred_input_titles, batch_first=True, padding_value=0)\n",
    "        if pred_input_titles_padded.size(1) < max_len_pred:\n",
    "            # Add padding if sequence length is shorter than max_len_pred\n",
    "            pad_size = max_len_pred - pred_input_titles_padded.size(1)\n",
    "            pred_input_titles_padded = torch.nn.functional.pad(\n",
    "                pred_input_titles_padded, (0, 0, 0, pad_size), value=0\n",
    "            )\n",
    "        elif pred_input_titles_padded.size(1) > max_len_pred:\n",
    "            # Trim if sequence length exceeds max_len_pred\n",
    "            pred_input_titles_padded = pred_input_titles_padded[:, :max_len_pred, :]\n",
    "\n",
    "        # Pad targets to the global maximum length\n",
    "        if apply_padding_to_targets:\n",
    "            batch_ys_padded = pad_sequence(batch_ys, batch_first=True, padding_value=-1)\n",
    "            if batch_ys_padded.size(1) < max_len_pred:\n",
    "                pad_size = max_len_pred - batch_ys_padded.size(1)\n",
    "                batch_ys_padded = torch.nn.functional.pad(batch_ys_padded, (0, pad_size), value=-1)\n",
    "            elif batch_ys_padded.size(1) > max_len_pred:\n",
    "                batch_ys_padded = batch_ys_padded[:, :max_len_pred]\n",
    "\n",
    "            return (his_input_titles_padded, pred_input_titles_padded), batch_ys_padded, impression_id\n",
    "        else:\n",
    "            return (his_input_titles_padded, pred_input_titles_padded), batch_ys, impression_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the dataset with DataLoader\n",
    "train_dataloader_temp = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,    # Set your desired batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")\n",
    "\n",
    "val_dataloader_temp = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,    # Set your desired batch size\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 94, 768])\n",
      "torch.Size([128, 94])\n",
      "tensor([359896188, 224747314,  25654902, 168055102, 198894701,  85580260,\n",
      "        399726989,  57246595, 379481458, 299659476, 244160998,  36785079,\n",
      "         42738260,  96940346, 379099009, 323175617, 288643184, 352999832,\n",
      "        274016255, 394667691, 443404546, 240665876, 237973484, 576612450,\n",
      "        460383402, 433095123, 232429352, 165100499, 279048130, 213332686,\n",
      "        521855911, 405911081, 337728748, 401605727, 509556879, 472910835,\n",
      "        131617588, 432445684, 109590192, 456762930,  42728594, 505100912,\n",
      "        461404225, 138285983, 546749147, 579213201, 236944911, 399171513,\n",
      "         79235232, 397174606, 441339833, 571176799, 222843818,  96320097,\n",
      "        187264861, 296970654, 432406916, 103985300, 186160821,  43634806,\n",
      "        387918433,   6338330, 470402174, 233249381, 507024792, 424428151,\n",
      "        223421622, 306908080,  70217594, 270236778, 288117883, 100472738,\n",
      "         43206321, 316118005, 193597407, 413710657, 100894233, 299581800,\n",
      "        417169705,  41094682, 453344938, 348522634, 454191379, 260849225,\n",
      "        273160499, 568816865, 445386518, 473378535, 456505878, 258780000,\n",
      "        411735053, 523594017,  86222215, 399751647, 180492267, 180982662,\n",
      "        379423706, 244596100, 531694194, 313457722, 300897140,  76892572,\n",
      "        100344314, 476404801,  18683659, 470615054, 403128406, 147841973,\n",
      "        433843559, 432072454, 177631644, 221470971, 552851176, 548071046,\n",
      "         85256472,  95066916, 505331368, 460136771, 212863060, 397044059,\n",
      "        571024853, 149293276, 331238829,  63713775, 188274667, 340483410,\n",
      "        438193577, 433998122])\n",
      "Batch loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataloader_temp:\n",
    "    (his_input_titles_padded, pred_input_titles_padded), batch_ys_padded, impression_id = batch\n",
    "    print(pred_input_titles_padded.shape)  # Look at one padded sequence\n",
    "    print(batch_ys_padded.shape)  # Look at one padded sequence\n",
    "    print(impression_id)\n",
    "\n",
    "    print(\"Batch loaded successfully!\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THIS CODE SHOULD ONLY RUN WHEN GENERATING THE DATA FOR THE FIRST TIME\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Function to preprocess and save data\n",
    "# def preprocess_and_save(dataloader, filepath, device=\"cuda\"):\n",
    "#     all_inputs_his = []\n",
    "#     all_inputs_pred = []\n",
    "#     all_targets = []\n",
    "#     all_impression_ids = []\n",
    "\n",
    "#     # Iterate over DataLoader and collect data\n",
    "#     for (his_inputs, pred_inputs), targets, impressionID in tqdm(dataloader, desc=\"Processing Data\"):\n",
    "#         all_inputs_his.append(his_inputs)\n",
    "#         all_inputs_pred.append(pred_inputs)\n",
    "#         all_targets.append(targets)\n",
    "#         all_impression_ids.append(impressionID)\n",
    "\n",
    "#     # Concatenate all batches into a single tensor\n",
    "#     all_inputs_his = torch.cat(all_inputs_his).to(device)\n",
    "#     all_inputs_pred = torch.cat(all_inputs_pred).to(device)\n",
    "#     all_targets = torch.cat(all_targets).to(device)\n",
    "#     all_impression_ids = torch.cat(all_impression_ids).to(device)\n",
    "\n",
    "#     # Save the preprocessed data as a tuple\n",
    "#     torch.save((all_inputs_his, all_inputs_pred, all_targets, all_impression_ids), filepath)\n",
    "#     print(f\"Data saved to {filepath}\")\n",
    "\n",
    "# # Save train and validation data\n",
    "# preprocess_and_save(val_dataloader_temp, \"val_data_small_dataset_with_impression_ids.pt\", device=\"cuda\")\n",
    "\n",
    "# preprocess_and_save(train_dataloader_temp, \"train_data_small_dataset_with_impression_ids.pt\", device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_preprocessed_data(filepath, device=\"cuda\"):\n",
    "#     # Load the data from the .pt file\n",
    "#     data = torch.load(filepath)\n",
    "\n",
    "#     # Unpack the data\n",
    "#     his_inputs, pred_inputs, targets, impression_ids = data\n",
    "\n",
    "#     # Move the data to the specified device\n",
    "#     his_inputs = his_inputs.to(device, non_blocking=True)\n",
    "#     pred_inputs = pred_inputs.to(device, non_blocking=True)\n",
    "#     targets = targets.to(device, non_blocking=True)\n",
    "#     impression_ids = impression_ids.to(device, non_blocking=True)\n",
    "\n",
    "#     return his_inputs, pred_inputs, targets, impression_ids\n",
    "\n",
    "# # Example: Load train and validation data\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# train_his_inputs, train_pred_inputs, train_targets, impression_ids = load_preprocessed_data(\"train_data_small_dataset_with_impression_ids.pt\", device)\n",
    "# val_his_inputs, val_pred_inputs, val_targets, impression_ids = load_preprocessed_data(\"val_data_small_dataset_with_impression_ids.pt\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_batches(inputs, targets, impression_ids, batch_size):\n",
    "#     his_inputs, pred_inputs = inputs\n",
    "#     for i in range(0, his_inputs.size(0), batch_size):\n",
    "#         his_batch = his_inputs[i:i+batch_size]\n",
    "#         pred_batch = pred_inputs[i:i+batch_size]\n",
    "#         target_batch = targets[i:i+batch_size]\n",
    "#         impression_id_batch = impression_ids[i:i+batch_size]\n",
    "#         yield (his_batch, pred_batch), target_batch, impression_id_batch\n",
    "\n",
    "# # Set the batch size\n",
    "# batch_size = 64\n",
    "\n",
    "# # Example: Create batches for train and validation data\n",
    "# #train_batches = create_batches((train_his_inputs, train_pred_inputs), train_targets, batch_size)\n",
    "# #val_batches = create_batches((val_his_inputs, val_pred_inputs), val_targets, batch_size)\n",
    "\n",
    "# train_batches = list(create_batches((train_his_inputs, train_pred_inputs), train_targets, impression_ids, batch_size))\n",
    "# val_batches = list(create_batches((val_his_inputs, val_pred_inputs), val_targets, impression_ids, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (his_batch, pred_batch), target_batch, impression_ids_batch in train_batches:\n",
    "#     print(f\"his_batch device: {his_batch.device}\")\n",
    "#     print(f\"pred_batch device: {pred_batch.device}\")\n",
    "#     print(f\"target_batch device: {target_batch.device}\")\n",
    "#     print(f\"impression_ids_batch device: {impression_ids_batch.device}\")\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'models_pytorch.model_config', '__annotations__': {'title_size': <class 'int'>, 'embedding_dim': <class 'int'>, 'word_emb_dim': <class 'int'>, 'vocab_size': <class 'int'>, 'head_num': <class 'int'>, 'head_dim': <class 'int'>, 'attention_hidden_dim': <class 'int'>, 'optimizer': <class 'str'>, 'loss': <class 'str'>, 'dropout': <class 'float'>, 'learning_rate': <class 'float'>, 'units_per_layer': list[int]}, 'title_size': 768, 'embedding_dim': 32, 'word_emb_dim': 8, 'vocab_size': 10000, 'head_num': 4, 'head_dim': 8, 'attention_hidden_dim': 50, 'hidden_dim': 4, 'optimizer': 'adam', 'loss': 'cross_entropy_loss', 'dropout': 0.2, 'learning_rate': 0.001, 'news_output_dim': 64, 'units_per_layer': [64, 64, 64], '__dict__': <attribute '__dict__' of 'hparams_nrms' objects>, '__weakref__': <attribute '__weakref__' of 'hparams_nrms' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# see the model parameters: \n",
    "print(hparams_nrms.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 14:31:33.255620: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732887093.277235   25570 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732887093.282341   25570 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-29 14:31:33.296939: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024/models_pytorch/NRMSDocVecModel.py:118: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define paths\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = os.path.join(\"downloads\", \"runs\", MODEL_NAME)\n",
    "MODEL_WEIGHTS = os.path.join(\"downloads\", \"data\", \"state_dict\", MODEL_NAME, \"weights.pth\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_WEIGHTS), exist_ok=True)\n",
    "\n",
    "# Define ModelCheckpoint class\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Saves the model after every epoch if it has the best performance so far.\"\"\"\n",
    "    def __init__(self, filepath, verbose=False, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath (str): Path to save the model checkpoint.\n",
    "            verbose (bool): If True, prints a message when the model is saved.\n",
    "            save_best_only (bool): If True, saves only when the model is better than before.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_loss = None\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.filepath)\n",
    "        if self.verbose:\n",
    "            print(f\"Model saved to {self.filepath}\")\n",
    "\n",
    "# Define EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve by a given percentage over a patience period.\"\"\"\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after last time validation loss improved by min_delta.\n",
    "            min_delta (float): Minimum percentage improvement required to reset patience.\n",
    "            verbose (bool): If True, prints a message when early stopping is triggered.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta  # Minimum percentage improvement\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            # Initialize best_loss with the first validation loss\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss < self.best_loss * (1 - self.min_delta):\n",
    "            # Significant improvement found\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved by at least {self.min_delta*100:.1f}%\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No significant improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "# Initialize callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_WEIGHTS, verbose=True, save_best_only=True)\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "\n",
    "# Initialize your model\n",
    "# Ensure that NRMSModel is a PyTorch nn.Module\n",
    "\n",
    "# CUDA checks\n",
    "#print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "#print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "#print(f\"Device Name: {torch.cuda.get_device_name()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "# model = NRMSModel(\n",
    "#     hparams=hparams_nrms.__dict__,\n",
    "#     word2vec_embedding=word2vec_embedding,\n",
    "#     vocab_size=1000,\n",
    "#     word_emb_dim=8,\n",
    "#     seed=seed,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "model = NRMSDocVecModel(hparams=hparams_nrms.__dict__,\n",
    "                        device=device)\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_prediction_details(outputs, targets, k=5):\n",
    "#     \"\"\"Print detailed prediction information for the first k samples\"\"\"\n",
    "#     # Get predicted class (highest score)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "#     # Calculate accuracy for this batch\n",
    "#     correct = (predicted == targets).sum().item()\n",
    "#     total = targets.size(0)\n",
    "#     accuracy = 100 * correct / total\n",
    "    \n",
    "#     # Print details for k samples\n",
    "#     for i in range(min(k, len(targets))):\n",
    "#         print(f\"\\nSample {i}:\")\n",
    "#         print(f\"Predicted probabilities: {torch.softmax(outputs[i], dim=0)}\")\n",
    "#         print(f\"Predicted class: {predicted[i]}, True class: {targets[i]}\")\n",
    "#         print(f\"Correct: {predicted[i] == targets[i]}\")\n",
    "    \n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSDocVecModel(\n",
      "  (newsencoder): NewsEncoderDocVec(\n",
      "    (model): Sequential(\n",
      "      (0): Linear(in_features=768, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.2, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Dropout(p=0.2, inplace=False)\n",
      "      (8): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (9): ReLU()\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Dropout(p=0.2, inplace=False)\n",
      "      (12): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (13): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (userencoder): UserEncoderDocVec(\n",
      "    (titleencoder): NewsEncoderDocVec(\n",
      "      (model): Sequential(\n",
      "        (0): Linear(in_features=768, out_features=64, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Dropout(p=0.2, inplace=False)\n",
      "        (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (5): ReLU()\n",
      "        (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): Dropout(p=0.2, inplace=False)\n",
      "        (8): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (9): ReLU()\n",
      "        (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (11): Dropout(p=0.2, inplace=False)\n",
      "        (12): Linear(in_features=64, out_features=64, bias=True)\n",
      "        (13): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (self_attention): SelfAttention()\n",
      "    (attention_layer): AttLayer2(\n",
      "      (q): Linear(in_features=50, out_features=1, bias=False)\n",
      "    )\n",
      "    (user_projection): Linear(in_features=50, out_features=64, bias=True)\n",
      "  )\n",
      ")\n",
      "Layer: newsencoder.model.0.weight | Size: torch.Size([64, 768])\n",
      "Layer: newsencoder.model.0.bias | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.2.weight | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.2.bias | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.4.weight | Size: torch.Size([64, 64])\n",
      "Layer: newsencoder.model.4.bias | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.6.weight | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.6.bias | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.8.weight | Size: torch.Size([64, 64])\n",
      "Layer: newsencoder.model.8.bias | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.10.weight | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.10.bias | Size: torch.Size([64])\n",
      "Layer: newsencoder.model.12.weight | Size: torch.Size([64, 64])\n",
      "Layer: newsencoder.model.12.bias | Size: torch.Size([64])\n",
      "Layer: userencoder.attention_layer.b | Size: torch.Size([50])\n",
      "Layer: userencoder.attention_layer.q.weight | Size: torch.Size([1, 50])\n",
      "Layer: userencoder.user_projection.weight | Size: torch.Size([64, 50])\n",
      "Layer: userencoder.user_projection.bias | Size: torch.Size([64])\n",
      "\n",
      "Total parameters: 65,444\n"
     ]
    }
   ],
   "source": [
    "# 1. Print model architecture\n",
    "print(model)\n",
    "\n",
    "# 2. Print specific layer sizes\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")\n",
    "\n",
    "# 3. Get total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "\n",
    "# 4. Print layer by layer with shapes\n",
    "def print_model_structure(model):\n",
    "    print(\"\\nDetailed Model Structure:\")\n",
    "    for name, module in model.named_children():\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Type: {type(module).__name__}\")\n",
    "        if hasattr(module, 'weight'):\n",
    "            print(f\"Shape: {module.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Layer: {name} | Size: {param.size()} | Parameters: {param.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_GRAD_NORM = np.sqrt(sum(p.numel() for p in model.parameters()))\n",
    "# print(f\"Max grad norm: {MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Added gradient clipping to avoid exploiding gradients. The paramter MAX_GRAD_NORM is set to 5.0 as this is a common value used in transformers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Variables to track counts\n",
    "# total_inputs = 0\n",
    "# total_targets = 0\n",
    "\n",
    "# # Iterate over the DataLoader\n",
    "# for batch_idx, (inputs, targets, impression_ids) in enumerate(train_dataloader_temp):\n",
    "#     # Move data to GPU\n",
    "#     inputs = [inp.to(device) for inp in inputs]\n",
    "#     targets = targets.to(device)\n",
    "#     impression_ids = impression_ids.to(device)\n",
    "    \n",
    "#     # Print information for the first few batches to avoid delays\n",
    "#     if batch_idx < 5:  # Adjust the number of batches to print as needed\n",
    "#         print(f\"Batch {batch_idx + 1} (on {device}):\")\n",
    "#         print(f\"  - Number of inputs: {len(inputs[0])}\")  # History input\n",
    "#         print(f\"  - Number of targets: {len(targets)}\")   # Target labels\n",
    "#         print(f\"  - Impression IDs: {len(impression_ids)}\")\n",
    "    \n",
    "#     # Update total counts\n",
    "#     total_inputs += len(inputs[0])\n",
    "#     total_targets += len(targets)\n",
    "\n",
    "# # Final counts after iteration\n",
    "# print(f\"\\nTotal number of inputs in train_dataloader_temp: {total_inputs}\")\n",
    "# print(f\"Total number of targets in train_dataloader_temp: {total_targets}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperoptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-29 14:31:34,630] A new study created in memory with name: no-name-ed0dadb2-3819-4441-b54d-e405d0a03dab\n",
      "/home/miki/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024/models_pytorch/NRMSDocVecModel.py:127: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved by at least 5.0%\n",
      "No significant improvement in validation loss. Counter: 1/3\n",
      "No significant improvement in validation loss. Counter: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-11-29 14:32:28,078] Trial 0 failed with parameters: {'history_size': 10, 'head_num': 5, 'head_dim': 14, 'attention_hidden_dim': 102, 'dropout': 0.484601633922385, 'learning_rate': 1.9553534425958017e-05, 'news_output_dim': 59, 'unit_layer_0': 81, 'unit_layer_1': 90, 'unit_layer_2': 71} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/miki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_25570/2148538864.py\", line 38, in objective\n",
      "    train_loss = train_one_epoch(model, train_dataloader_temp, optimizer, criterion)\n",
      "  File \"/tmp/ipykernel_25570/2148538864.py\", line 73, in train_one_epoch\n",
      "    loss.backward()\n",
      "  File \"/home/miki/.local/lib/python3.10/site-packages/torch/_tensor.py\", line 521, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/miki/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 289, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/miki/.local/lib/python3.10/site-packages/torch/autograd/graph.py\", line 769, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-11-29 14:32:28,082] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 101\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Create study and optimize\u001b[39;00m\n\u001b[1;32m    100\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 101\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Run 50 trials\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[22], line 38\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Training phase\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 38\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader_temp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Validation phase\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m validate(model, val_dataloader_temp, criterion)\n",
      "Cell \u001b[0;32mIn[22], line 73\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     71\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m     72\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     76\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import optuna\n",
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "\n",
    "# LEARNING_RATE = 1e-4\n",
    "# WEIGHT_DECAY = 1e-3\n",
    "# NUM_EPOCHS = 30\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define hyperparameter search space\n",
    "#     hparams = {\n",
    "#         'title_size': 768,\n",
    "#         'history_size': trial.suggest_int('history_size', 5, 20),\n",
    "#         'head_num': trial.suggest_int('head_num', 2, 8),\n",
    "#         'head_dim': trial.suggest_int('head_dim', 4, 16),\n",
    "#         'attention_hidden_dim': trial.suggest_int('attention_hidden_dim', 32, 128),\n",
    "#         'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n",
    "#         'news_output_dim': trial.suggest_int('news_output_dim', 32, 128),\n",
    "#         'units_per_layer': [trial.suggest_int(f'unit_layer_{i}', 32, 128) for i in range(3)]\n",
    "#     }\n",
    "\n",
    "#     # Initialize model and training components\n",
    "#     model = NRMSDocVecModel(hparams=hparams, device=device)\n",
    "#     criterion = model.get_loss().to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), \n",
    "#                           lr=hparams['learning_rate'], \n",
    "#                           weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "#     # Initialize EarlyStopping\n",
    "#     early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         train_loss = train_one_epoch(model, train_dataloader_temp, optimizer, criterion)\n",
    "        \n",
    "#         # Validation phase\n",
    "#         val_loss = validate(model, val_dataloader_temp, criterion)\n",
    "        \n",
    "#         # Update best validation loss\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "\n",
    "#         # Early stopping check\n",
    "#         early_stopping(val_loss)\n",
    "#         if early_stopping.early_stop:\n",
    "#             print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "#             break\n",
    "\n",
    "#         # Report to Optuna\n",
    "#         trial.report(val_loss, epoch)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "\n",
    "#     return best_val_loss\n",
    "\n",
    "# def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "#     running_loss = 0.0\n",
    "#     batch_count = 0\n",
    "    \n",
    "#     for inputs, targets, impression_ids in dataloader:\n",
    "#         inputs = [inp.to(device) for inp in inputs]\n",
    "#         targets = targets.to(device)\n",
    "#         positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#         targets = positive_indices[:, 1].long()\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(*inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#         batch_count += 1\n",
    "    \n",
    "#     return running_loss / batch_count\n",
    "\n",
    "# def validate(model, dataloader, criterion):\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     batch_count = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for inputs, targets, impression_ids in dataloader:\n",
    "#             inputs = [inp.to(device) for inp in inputs]\n",
    "#             targets = targets.to(device)\n",
    "#             positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#             targets = positive_indices[:, 1].long()\n",
    "#             outputs = model(*inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             val_loss += loss.item()\n",
    "#             batch_count += 1\n",
    "    \n",
    "#     return val_loss / batch_count\n",
    "\n",
    "# # Create study and optimize\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=3)  # Run 50 trials\n",
    "\n",
    "# # Print results\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 2/30 [00:25<05:50, 12.53s/it, train_loss=1.8309, val_loss=2.5485]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 3/30 [00:37<05:31, 12.29s/it, train_loss=1.7556, val_loss=2.4656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved by at least 5.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  13%|█▎        | 4/30 [00:48<05:13, 12.04s/it, train_loss=1.7151, val_loss=2.3677]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  17%|█▋        | 5/30 [01:00<05:00, 12.03s/it, train_loss=1.6731, val_loss=2.3188]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved by at least 5.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  20%|██        | 6/30 [01:13<04:49, 12.07s/it, train_loss=1.6409, val_loss=2.2927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  23%|██▎       | 7/30 [01:24<04:35, 11.96s/it, train_loss=1.6144, val_loss=2.2906]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  23%|██▎       | 7/30 [01:36<05:17, 13.81s/it, train_loss=1.6026, val_loss=2.2870]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 3/3\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = model.get_loss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Training parameters\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Epoch progress bar\n",
    "epoch_pbar = tqdm(range(1, NUM_EPOCHS + 1), desc=\"Training Progress\", dynamic_ncols=True)\n",
    "for epoch in epoch_pbar:\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets, impression_ids) in enumerate(train_dataloader_temp):\n",
    "        # Prepare data\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Get positive labels\n",
    "        positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "        targets = positive_indices[:, 1].long()\n",
    "\n",
    "        # Forward and backward passes\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running statistics\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    # Compute average training loss\n",
    "    avg_train_loss = running_loss / train_batch_count if train_batch_count > 0 else float('inf')\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batch_count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, impression_ids in val_dataloader_temp:\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            targets = targets.to(device)\n",
    "            positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "            targets = positive_indices[:, 1].long()\n",
    "            outputs = model(*inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_batch_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Update tensorboard\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "\n",
    "    # Update epoch progress bar with metrics\n",
    "    epoch_pbar.set_postfix({\n",
    "        'train_loss': f'{avg_train_loss:.4f}',\n",
    "        'val_loss': f'{avg_val_loss:.4f}',\n",
    "    })\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        model_checkpoint(model, avg_val_loss)\n",
    "\n",
    "    # Check early stopping condition\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Summary:\n",
      "Initial Training Loss: 2.1585\n",
      "Final Training Loss: 1.6026\n",
      "Best Training Loss: 1.6026\n",
      "\n",
      "Initial Validation Loss: 2.6331\n",
      "Final Validation Loss: 2.2870\n",
      "Best Validation Loss: 2.2870\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print final statistics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Initial Training Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Training Loss: {min(train_losses):.4f}\")\n",
    "print(f\"\\nInitial Validation Loss: {val_losses[0]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Validation Loss: {min(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating DataLoader...\n",
      "Total samples in DataLoader: 24322\n",
      "\n",
      "First batch shapes:\n",
      "  - his_input_title: torch.Size([128, 20, 768])\n",
      "  - pred_input_title: torch.Size([128, 87, 768])\n",
      "  - targets: torch.Size([128, 87])\n",
      "\n",
      "Evaluation completed.\n",
      "Total predictions generated: 24322\n",
      "First few prediction lengths: [5, 6, 9, 5, 5, 12, 5, 7, 5, 25, 9, 5, 5, 6, 36]\n",
      "\n",
      "Validation against DataFrame:\n",
      "\n",
      "Metrics: {'auc': 0.5473619202244294, 'mrr': 0.3427701420987983, 'ndcg@5': 0.380479807514404, 'ndcg@10': 0.45891013813394177}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Evaluate the model and return predictions and labels for metric calculation.\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"\\nEvaluating DataLoader...\")\n",
    "    total_samples = len(dataloader.dataset)\n",
    "    print(f\"Total samples in DataLoader: {total_samples}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, impression_ids) in enumerate(dataloader):\n",
    "            his_input_title, pred_input_title = inputs\n",
    "\n",
    "            if batch_idx == 0:  # Debug first batch shapes\n",
    "                print(\"\\nFirst batch shapes:\")\n",
    "                print(f\"  - his_input_title: {his_input_title.shape}\")\n",
    "                print(f\"  - pred_input_title: {pred_input_title.shape}\")\n",
    "                print(f\"  - targets: {targets.shape}\")\n",
    "\n",
    "            # Move data to device\n",
    "            his_input_title = his_input_title.to(device)\n",
    "            pred_input_title = pred_input_title.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model.predict(his_input_title, pred_input_title)\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            targets = targets.cpu().numpy()\n",
    "\n",
    "            # Process each sample in the batch\n",
    "            batch_size = predictions.shape[0]\n",
    "            for sample_idx in range(batch_size):\n",
    "                pred = predictions[sample_idx]\n",
    "                label = targets[sample_idx]\n",
    "\n",
    "                # Create valid_mask where label is not equal to the padding value (-1)\n",
    "                valid_mask = (label != -1)\n",
    "                sample_preds = pred[valid_mask]\n",
    "                sample_labels = label[valid_mask]\n",
    "\n",
    "                if len(sample_labels) == 0:\n",
    "                    continue  # Skip empty samples\n",
    "\n",
    "                # Ensure that there is at least one positive and one negative label\n",
    "                if len(np.unique(sample_labels)) < 2:\n",
    "                    continue  # Skip samples with only one class\n",
    "\n",
    "                all_predictions.append(sample_preds.tolist())\n",
    "                all_labels.append(sample_labels.tolist())\n",
    "\n",
    "    print(\"\\nEvaluation completed.\")\n",
    "    print(f\"Total predictions generated: {len(all_predictions)}\")\n",
    "    print(f\"First few prediction lengths: {[len(x) for x in all_predictions[:15]]}\")\n",
    "    return all_labels, all_predictions\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "labels_list, scores_list = evaluate_model(model, val_dataloader_temp, device)\n",
    "\n",
    "# Validate predictions against the DataFrame\n",
    "print(\"\\nValidation against DataFrame:\")\n",
    "if len(scores_list) != len(df_validation):\n",
    "    print(\"WARNING: Length mismatch!\")\n",
    "    print(f\"  - Number of predictions: {len(scores_list)}\")\n",
    "    print(f\"  - Number of rows in DataFrame: {len(df_validation)}\")\n",
    "\n",
    "# Compute metrics\n",
    "metrics = MetricEvaluator(\n",
    "    labels=labels_list,\n",
    "    predictions=scores_list,\n",
    "    metric_functions=[\n",
    "        AucScore(),\n",
    "        MrrScore(),\n",
    "        NdcgScore(k=5),\n",
    "        NdcgScore(k=10)\n",
    "    ],\n",
    ")\n",
    "results = metrics.evaluate()\n",
    "print(\"\\nMetrics:\", results.evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRACTION: 0.2, HISTORY_SIZE: 10, LEARNING_RATE: 0.0001, WEIGHT_DECAY: 0.001\n",
      "Hyperparameters:\n",
      "title_size: 768\n",
      "history_size: 10\n",
      "embedding_dim: 32\n",
      "word_emb_dim: 8\n",
      "vocab_size: 10000\n",
      "head_num: 4\n",
      "head_dim: 8\n",
      "attention_hidden_dim: 50\n",
      "hidden_dim: 4\n",
      "optimizer: adam\n",
      "loss: cross_entropy_loss\n",
      "dropout: 0.6\n",
      "learning_rate: 0.001\n",
      "news_output_dim: 64\n",
      "units_per_layer: [64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "print(f\"FRACTION: {FRACTION}, HISTORY_SIZE: {HISTORY_SIZE}, LEARNING_RATE: {LEARNING_RATE}, WEIGHT_DECAY: {WEIGHT_DECAY}\")\n",
    "\n",
    "# Filter out special Python attributes and print parameters\n",
    "params = {k: v for k, v in hparams_nrms.__dict__.items() if not k.startswith('__')}\n",
    "print(\"Hyperparameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_labels(df: pl.DataFrame, impression_id: int) -> int:\n",
    "    # Filter for matching impression_id\n",
    "    filtered = df.filter(pl.col('impression_id') == impression_id)\n",
    "    \n",
    "    if filtered.height == 0:\n",
    "        raise ValueError(f\"No row found for impression_id {impression_id}\")\n",
    "    \n",
    "    # Get labels from first row\n",
    "    labels = filtered.select('labels').row(0)[0]\n",
    "    \n",
    "    return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_length_of_labels(df_validation, 349992000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [0, 0, 0, 0, 1]\n",
      "Label 1: [0, 1, 0, 0, 0, 0]\n",
      "Label 2: [0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "Label 3: [0, 1, 0, 0, 0]\n",
      "Label 4: [0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 labels\n",
    "first_5_labels = df_validation.select('labels').head(5)\n",
    "\n",
    "# Print each label with index\n",
    "for i, row in enumerate(first_5_labels.iter_rows()):\n",
    "    print(f\"Label {i}: {row[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples with only one class\n",
      "Remaining valid samples: 24322\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize lists\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "skipped_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (his_input_title, pred_input_title), targets, impression_ids in val_dataloader_temp:\n",
    "        # Move to device\n",
    "        his_input_title = his_input_title.to(device)\n",
    "        pred_input_title = pred_input_title.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(his_input_title, pred_input_title)\n",
    "        \n",
    "        # Convert to probabilities if needed\n",
    "        if not torch.is_floating_point(predictions):\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Convert to lists while preserving structure\n",
    "        batch_preds = predictions.cpu().numpy().tolist()\n",
    "        batch_labels = targets.cpu().numpy().tolist()\n",
    "        impression_ids = impression_ids.cpu().numpy().tolist()\n",
    "        \n",
    "        batch_preds_without_padding = []\n",
    "        batch_labels_without_padding = []\n",
    "        \n",
    "        for pred_sample, label_sample, impression_id_sample in zip(batch_preds, batch_labels, impression_ids):\n",
    "            # Remove padding\n",
    "            actual_length = get_length_of_labels(df_validation, impression_id_sample)\n",
    "            pred_sample = pred_sample[:actual_length]\n",
    "            \n",
    "            # Check if sample has both classes before adding\n",
    "            if 1 in label_sample[:actual_length] and 0 in label_sample[:actual_length]:\n",
    "                batch_preds_without_padding.append(pred_sample)\n",
    "                batch_labels_without_padding.append(label_sample[:actual_length])\n",
    "            else:\n",
    "                skipped_samples += 1\n",
    "        \n",
    "        # Add batch predictions and labels\n",
    "        all_predictions.extend(batch_preds_without_padding)\n",
    "        all_labels.extend(batch_labels_without_padding)\n",
    "print(f\"Skipped {skipped_samples} samples with only one class\")\n",
    "print(f\"Remaining valid samples: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 0:\n",
      "Labels length:      5\n",
      "Predictions length: 5\n",
      "Num positives: 1.0\n",
      "Num negatives: 4.0\n",
      "Label distribution: [0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "\n",
      "Sample 1:\n",
      "Labels length:      6\n",
      "Predictions length: 6\n",
      "Num positives: 1.0\n",
      "Num negatives: 5.0\n",
      "Label distribution: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 2:\n",
      "Labels length:      9\n",
      "Predictions length: 9\n",
      "Num positives: 1.0\n",
      "Num negatives: 8.0\n",
      "Label distribution: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "Sample 3:\n",
      "Labels length:      5\n",
      "Predictions length: 5\n",
      "Num positives: 1.0\n",
      "Num negatives: 4.0\n",
      "Label distribution: [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 4:\n",
      "Labels length:      5\n",
      "Predictions length: 5\n",
      "Num positives: 1.0\n",
      "Num negatives: 4.0\n",
      "Label distribution: [0.0, 1.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Print label distribution for first 5 samples\n",
    "for i, (preds, labels) in enumerate(zip(all_predictions[:5], all_labels[:5])):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Labels length:      {len(labels)}\")\n",
    "    print(f\"Predictions length: {len(preds)}\")\n",
    "    print(f\"Num positives: {sum(labels)}\")\n",
    "    print(f\"Num negatives: {len(labels) - sum(labels)}\")\n",
    "    print(f\"Label distribution: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "Number of predictions: 24322\n",
      "example prediction: [[0.7804455161094666, 0.7601590752601624, 0.7508010864257812, 0.776279628276825, 0.7662674784660339], [0.7439578771591187, 0.7921673059463501, 0.7626770734786987, 0.783227801322937, 0.7442592978477478, 0.7755287289619446]]\n",
      "Number of labels: 24322\n",
      "example label: [[0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(type(all_predictions))\n",
    "print(type(all_labels))\n",
    "\n",
    "print(f\"Number of predictions: {len(all_predictions)}\")\n",
    "print(f\"example prediction: {all_predictions[0:2]}\")\n",
    "print(f\"Number of labels: {len(all_labels)}\")\n",
    "print(f\"example label: {all_labels[0:2]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1438\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "correct_predictions = 0\n",
    "total_samples = len(all_predictions)\n",
    "\n",
    "# Iterate over samples\n",
    "for idx, _ in enumerate(all_predictions):\n",
    "    # print(f\"Sample {idx}: Prediction: {all_predictions[idx]}\")\n",
    "    # print(f\"Sample {idx}: Label:      {all_labels[idx]}\")\n",
    "    \n",
    "    # Extract index of maximum value in predictions and labels\n",
    "    pred_max_index = np.argmax(all_predictions[idx])\n",
    "    label_max_index = np.argmax(all_labels[idx])\n",
    "    \n",
    "    # Compare indices to determine if the prediction was correct\n",
    "    if pred_max_index == label_max_index:\n",
    "        # print(f\"Sample {idx}: Prediction was correct.\")\n",
    "        correct_predictions += 1\n",
    "  #  else:\n",
    "        # print(f\"Sample {idx}: Prediction was wrong.\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.5474\n",
      "Number of valid AUC calculations: 24322\n"
     ]
    }
   ],
   "source": [
    "from evaluation import AucScore\n",
    "\n",
    "# auc_score = AucScore()\n",
    "\n",
    "# auc_score.calculate(all_predictions, all_labels)\n",
    "# print(f\"AUC: {auc_score.score}\")\n",
    "# # Calculate AUC per sample\n",
    "aucs = []\n",
    "for preds, labels in zip(all_predictions, all_labels):\n",
    "    try:\n",
    "        # Only calculate if we have both positive and negative samples\n",
    "        if sum(labels) > 0 and sum(labels) < len(labels):\n",
    "            auc = roc_auc_score(labels, preds)\n",
    "            aucs.append(auc)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Only one class present in labels. Cannot calculate AUC.\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(aucs):.4f}\")\n",
    "print(f\"Number of valid AUC calculations: {len(aucs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
