{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Python version: 3.12.1\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "Current GPU device: NVIDIA GeForce RTX 3070\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "#import optuna\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL,\n",
    "    DEFAULT_TOTAL_READ_TIME_COL,\n",
    "    DEFAULT_SENTIMENT_SCORE_COL,\n",
    ")\n",
    "\n",
    "from utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from utils._articles import convert_text2encoding_with_transformers\n",
    "from utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from utils._articles import create_article_id_to_value_mapping\n",
    "from utils._nlp import get_transformers_word_embeddings, generate_embeddings_with_transformers\n",
    "from utils._python import write_submission_file, rank_predictions_by_score\n",
    "from models_pytorch.model_config import hparams_nrms\n",
    "\n",
    "from models_pytorch.nrms import NRMSModel\n",
    "from models_pytorch.NRMSDocVecModel import NRMSDocVecModel\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from models_pytorch.dataloader import NRMSDataSet\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at behaviours and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebnerd_small\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"./ebnerd_small\")  # Base path for your data directory\n",
    "print(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>datetime[μs]</td><td>list[i8]</td></tr></thead><tbody><tr><td>2049682</td><td>[9767604, 9768997, … 9770532]</td><td>[9773378, 7213923, … 7213923]</td><td>[9773378]</td><td>143742031</td><td>2023-05-20 14:04:32</td><td>[1, 0, … 0]</td></tr><tr><td>1680897</td><td>[9763634, 9763579, … 9768820]</td><td>[9527795, 9776041, … 9776041]</td><td>[9775983]</td><td>406393631</td><td>2023-05-22 22:09:00</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆ u32          ┆ datetime[μs] ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 2049682 ┆ [9767604,    ┆ [9773378,    ┆ [9773378]    ┆ 143742031    ┆ 2023-05-20   ┆ [1, 0, … 0] │\n",
       "│         ┆ 9768997, …   ┆ 7213923, …   ┆              ┆              ┆ 14:04:32     ┆             │\n",
       "│         ┆ 9770532]     ┆ 7213923]     ┆              ┆              ┆              ┆             │\n",
       "│ 1680897 ┆ [9763634,    ┆ [9527795,    ┆ [9775983]    ┆ 406393631    ┆ 2023-05-22   ┆ [0, 0, … 0] │\n",
       "│         ┆ 9763579, …   ┆ 9776041, …   ┆              ┆              ┆ 22:09:00     ┆             │\n",
       "│         ┆ 9768820]     ┆ 9776041]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "]\n",
    "HISTORY_SIZE = 20 # TODO: History size. \n",
    "FRACTION = 0.1\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.with_columns([\n",
    "    (\n",
    "        (pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)\n",
    "        .dt.epoch(time_unit='s') / 3600)\n",
    "        .cast(pl.Int64)\n",
    "    ).alias(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "])\n",
    "\n",
    "df_validation = df_validation.with_columns([\n",
    "    (\n",
    "        (pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)\n",
    "        .dt.epoch(time_unit='s') / 3600)\n",
    "        .cast(pl.Int64)\n",
    "    ).alias(DEFAULT_IMPRESSION_TIMESTAMP_COL)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>i64</td><td>list[i8]</td></tr></thead><tbody><tr><td>2049682</td><td>[9767604, 9768997, … 9770532]</td><td>[9773378, 7213923, … 7213923]</td><td>[9773378]</td><td>143742031</td><td>467942</td><td>[1, 0, … 0]</td></tr><tr><td>1680897</td><td>[9763634, 9763579, … 9768820]</td><td>[9527795, 9776041, … 9776041]</td><td>[9775983]</td><td>406393631</td><td>467998</td><td>[0, 0, … 0]</td></tr><tr><td>2494285</td><td>[9770207, 9770037, … 9769650]</td><td>[9664250, 9647704, … 9772858]</td><td>[9701446]</td><td>333126948</td><td>467919</td><td>[0, 0, … 0]</td></tr><tr><td>278696</td><td>[9763153, 9762407, … 9759345]</td><td>[9508202, 9774352, … 9527795]</td><td>[9772453]</td><td>294334127</td><td>467958</td><td>[0, 0, … 0]</td></tr><tr><td>716222</td><td>[9760741, 9757533, … 9767697]</td><td>[9774358, 9769557, … 9774899]</td><td>[9769557]</td><td>258248879</td><td>467967</td><td>[0, 1, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i64]    ┆ list[i64]    ┆ u32          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 2049682 ┆ [9767604,    ┆ [9773378,    ┆ [9773378]    ┆ 143742031    ┆ 467942       ┆ [1, 0, … 0] │\n",
       "│         ┆ 9768997, …   ┆ 7213923, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9770532]     ┆ 7213923]     ┆              ┆              ┆              ┆             │\n",
       "│ 1680897 ┆ [9763634,    ┆ [9527795,    ┆ [9775983]    ┆ 406393631    ┆ 467998       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9763579, …   ┆ 9776041, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9768820]     ┆ 9776041]     ┆              ┆              ┆              ┆             │\n",
       "│ 2494285 ┆ [9770207,    ┆ [9664250,    ┆ [9701446]    ┆ 333126948    ┆ 467919       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9770037, …   ┆ 9647704, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9769650]     ┆ 9772858]     ┆              ┆              ┆              ┆             │\n",
       "│ 278696  ┆ [9763153,    ┆ [9508202,    ┆ [9772453]    ┆ 294334127    ┆ 467958       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9762407, …   ┆ 9774352, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9759345]     ┆ 9527795]     ┆              ┆              ┆              ┆             │\n",
       "│ 716222  ┆ [9760741,    ┆ [9774358,    ┆ [9769557]    ┆ 258248879    ┆ 467967       ┆ [0, 1, … 0] │\n",
       "│         ┆ 9757533, …   ┆ 9769557, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9767697]     ┆ 9774899]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i32]</td><td>list[i32]</td><td>u32</td><td>i64</td><td>list[i8]</td></tr></thead><tbody><tr><td>2245261</td><td>[0, 0, … 9778902]</td><td>[9778796, 9782487, … 9774733]</td><td>[9782315]</td><td>185858493</td><td>468084</td><td>[0, 0, … 0]</td></tr><tr><td>2009884</td><td>[9779748, 9778902, … 9779150]</td><td>[9268227, 9782421, … 9782361]</td><td>[9782133]</td><td>89040376</td><td>468083</td><td>[0, 0, … 0]</td></tr><tr><td>2400369</td><td>[9778220, 9775596, … 9779430]</td><td>[9781855, 9781785, … 9781558]</td><td>[9781859]</td><td>521900210</td><td>468080</td><td>[0, 0, … 0]</td></tr><tr><td>2209151</td><td>[9779642, 9779141, … 9779045]</td><td>[9780849, 9783379, … 9780476]</td><td>[9781998]</td><td>449052651</td><td>468103</td><td>[0, 0, … 0]</td></tr><tr><td>188693</td><td>[9774430, 9774527, … 9780096]</td><td>[9787499, 9462356, … 9788362]</td><td>[9780702]</td><td>327759373</td><td>468182</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ u32     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i8]    │\n",
       "│         ┆ list[i32]    ┆ list[i32]    ┆ list[i32]    ┆ u32          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 2245261 ┆ [0, 0, …     ┆ [9778796,    ┆ [9782315]    ┆ 185858493    ┆ 468084       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778902]     ┆ 9782487, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆              ┆ 9774733]     ┆              ┆              ┆              ┆             │\n",
       "│ 2009884 ┆ [9779748,    ┆ [9268227,    ┆ [9782133]    ┆ 89040376     ┆ 468083       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778902, …   ┆ 9782421, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779150]     ┆ 9782361]     ┆              ┆              ┆              ┆             │\n",
       "│ 2400369 ┆ [9778220,    ┆ [9781855,    ┆ [9781859]    ┆ 521900210    ┆ 468080       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9775596, …   ┆ 9781785, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779430]     ┆ 9781558]     ┆              ┆              ┆              ┆             │\n",
       "│ 2209151 ┆ [9779642,    ┆ [9780849,    ┆ [9781998]    ┆ 449052651    ┆ 468103       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9779141, …   ┆ 9783379, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779045]     ┆ 9780476]     ┆              ┆              ┆              ┆             │\n",
       "│ 188693  ┆ [9774430,    ┆ [9787499,    ┆ [9780702]    ┆ 327759373    ┆ 468182       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9774527, …   ┆ 9462356, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9780096]     ┆ 9788362]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of article_ids_inview in df_train: 5.0\n",
      "Average length of article_ids_inview in df_validation: 11.907987246566384\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_length(df, column):\n",
    "    total_length = sum(len(row) for row in df[column])\n",
    "    average_length = total_length / len(df)\n",
    "    return average_length\n",
    "\n",
    "# Calculate average length for df_train\n",
    "average_length_inview_train = calculate_average_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_train: {average_length_inview_train}\")\n",
    "\n",
    "# Calculate average length for df_validation\n",
    "average_length_inview_validation = calculate_average_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_validation: {average_length_inview_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest inview article length in df_train: 5\n",
      "Longest inview article length in df_validation: 89\n",
      "Longest history length in df_train: 20\n",
      "Longest history length in df_validation: 20\n"
     ]
    }
   ],
   "source": [
    "# Function to find the maximum length of arrays in a column\n",
    "def find_max_length(df, column):\n",
    "    max_length = 0\n",
    "    for row in df[column]:\n",
    "        max_length = max(max_length, len(row))\n",
    "    return max_length\n",
    "\n",
    "# Find the longest inview article length in df_train\n",
    "max_inview_length_train = find_max_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "# Find the longest inview article length in df_validation\n",
    "max_inview_length_validation = find_max_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "print(f\"Longest inview article length in df_train: {max_inview_length_train}\")\n",
    "print(f\"Longest inview article length in df_validation: {max_inview_length_validation}\")\n",
    "\n",
    "max_history_length_train = find_max_length(df_train, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "max_history_length_validation = find_max_length(df_validation, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "\n",
    "print(f\"Longest history length in df_train: {max_history_length_train}\")\n",
    "print(f\"Longest history length in df_validation: {max_history_length_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with exactly one clicked article in df_train: 23427\n",
      "Number of rows with exactly one clicked article in df_validation: 24336\n"
     ]
    }
   ],
   "source": [
    "# Function to filter rows with exactly one clicked article\n",
    "def filter_rows_with_one_clicked_article(df, clicked_articles_col):\n",
    "    # Manually filter rows where the array has exactly one element\n",
    "    filtered_rows = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        if len(row[clicked_articles_col]) == 1:\n",
    "            filtered_rows.append(row)\n",
    "    return pl.DataFrame(filtered_rows)\n",
    "\n",
    "\n",
    "# Filter rows in df_train and df_validation\n",
    "df_train = filter_rows_with_one_clicked_article(df_train, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "df_validation = filter_rows_with_one_clicked_article(df_validation, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of rows with exactly one clicked article in df_train: {df_train.shape[0]}\")\n",
    "print(f\"Number of rows with exactly one clicked article in df_validation: {df_validation.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>impression_time</th><th>labels</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>2245261</td><td>[0, 0, … 9778902]</td><td>[9778796, 9782487, … 9774733]</td><td>[9782315]</td><td>185858493</td><td>468084</td><td>[0, 0, … 0]</td></tr><tr><td>2009884</td><td>[9779748, 9778902, … 9779150]</td><td>[9268227, 9782421, … 9782361]</td><td>[9782133]</td><td>89040376</td><td>468083</td><td>[0, 0, … 0]</td></tr><tr><td>2400369</td><td>[9778220, 9775596, … 9779430]</td><td>[9781855, 9781785, … 9781558]</td><td>[9781859]</td><td>521900210</td><td>468080</td><td>[0, 0, … 0]</td></tr><tr><td>2209151</td><td>[9779642, 9779141, … 9779045]</td><td>[9780849, 9783379, … 9780476]</td><td>[9781998]</td><td>449052651</td><td>468103</td><td>[0, 0, … 0]</td></tr><tr><td>188693</td><td>[9774430, 9774527, … 9780096]</td><td>[9787499, 9462356, … 9788362]</td><td>[9780702]</td><td>327759373</td><td>468182</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌─────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_f ┆ article_ids_ ┆ article_ids_ ┆ impression_i ┆ impression_t ┆ labels      │\n",
       "│ ---     ┆ ixed         ┆ inview       ┆ clicked      ┆ d            ┆ ime          ┆ ---         │\n",
       "│ i64     ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ ---          ┆ list[i64]   │\n",
       "│         ┆ list[i64]    ┆ list[i64]    ┆ list[i64]    ┆ i64          ┆ i64          ┆             │\n",
       "╞═════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪═════════════╡\n",
       "│ 2245261 ┆ [0, 0, …     ┆ [9778796,    ┆ [9782315]    ┆ 185858493    ┆ 468084       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778902]     ┆ 9782487, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆              ┆ 9774733]     ┆              ┆              ┆              ┆             │\n",
       "│ 2009884 ┆ [9779748,    ┆ [9268227,    ┆ [9782133]    ┆ 89040376     ┆ 468083       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9778902, …   ┆ 9782421, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779150]     ┆ 9782361]     ┆              ┆              ┆              ┆             │\n",
       "│ 2400369 ┆ [9778220,    ┆ [9781855,    ┆ [9781859]    ┆ 521900210    ┆ 468080       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9775596, …   ┆ 9781785, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779430]     ┆ 9781558]     ┆              ┆              ┆              ┆             │\n",
       "│ 2209151 ┆ [9779642,    ┆ [9780849,    ┆ [9781998]    ┆ 449052651    ┆ 468103       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9779141, …   ┆ 9783379, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9779045]     ┆ 9780476]     ┆              ┆              ┆              ┆             │\n",
       "│ 188693  ┆ [9774430,    ┆ [9787499,    ┆ [9780702]    ┆ 327759373    ┆ 468182       ┆ [0, 0, … 0] │\n",
       "│         ┆ 9774527, …   ┆ 9462356, …   ┆              ┆              ┆              ┆             │\n",
       "│         ┆ 9780096]     ┆ 9788362]     ┆              ┆              ┆              ┆             │\n",
       "└─────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴─────────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in df_train: 8908\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users in df_train: {df_train['user_id'].n_unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>2007-03-27 10:22:08</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>2001-10-19 12:30:00</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>2003-01-09 06:00:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>2003-06-17 07:10:00</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>2003-07-13 19:50:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = df_articles.with_columns([\n",
    "    (\n",
    "        pl.col(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL)\n",
    "        .cast(pl.Datetime)                   # Step 3: Cast to Datetime\n",
    "        .dt.epoch(time_unit='s')            # Step 4: Convert to Epoch Seconds\n",
    "        / 3600                               # Step 5: Convert Seconds to Hours\n",
    "    ).cast(pl.Int64)                         # Step 6: Cast to Integer\n",
    "    .alias(DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL)  # Step 7: Alias the Column\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>i64</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>321392</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>318952</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>318470</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>326312</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>324754</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>326386</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>278748</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>289470</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>293287</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>293923</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCVEC = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document vector parquet file\n",
    "document_vector_path = Path(\"./Ekstra_Bladet_word2vec/document_vector.parquet\")\n",
    "df_document_vector = pl.read_parquet(document_vector_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "\n",
    "article_mapping = create_article_id_to_value_mapping(df=df_document_vector, value_col=\"document_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>document_vector</th></tr><tr><td>i32</td><td>list[f32]</td></tr></thead><tbody><tr><td>3000022</td><td>[0.065424, -0.047425, … 0.035706]</td></tr><tr><td>3000063</td><td>[0.028815, -0.000166, … 0.027167]</td></tr><tr><td>3000613</td><td>[0.037971, 0.033923, … 0.063961]</td></tr><tr><td>3000700</td><td>[0.046524, 0.002913, … 0.023423]</td></tr><tr><td>3000840</td><td>[0.014737, 0.024068, … 0.045991]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌────────────┬─────────────────────────────────┐\n",
       "│ article_id ┆ document_vector                 │\n",
       "│ ---        ┆ ---                             │\n",
       "│ i32        ┆ list[f32]                       │\n",
       "╞════════════╪═════════════════════════════════╡\n",
       "│ 3000022    ┆ [0.065424, -0.047425, … 0.0357… │\n",
       "│ 3000063    ┆ [0.028815, -0.000166, … 0.0271… │\n",
       "│ 3000613    ┆ [0.037971, 0.033923, … 0.06396… │\n",
       "│ 3000700    ┆ [0.046524, 0.002913, … 0.02342… │\n",
       "│ 3000840    ┆ [0.014737, 0.024068, … 0.04599… │\n",
       "└────────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_document_vector.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding tokenized article title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality of embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uses existing function for both categories and topics\n",
    "* Handles array of topics by joining with separator\n",
    "* Limits to first 3 topics to avoid sequence length issues\n",
    "* Maintains consistent encoding approach across feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "MAX_TITLE_LENGTH = 30\n",
    "from transformers import ConvBertTokenizer, ConvBertModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "\n",
    "transformer_tokenizer = ConvBertTokenizer.from_pretrained(\"sarnikowski/convbert-small-da-cased\")\n",
    "transformer_model = ConvBertModel.from_pretrained(\"sarnikowski/convbert-small-da-cased\")\n",
    "\n",
    "\n",
    "# For categories (keep as is - works with single strings)\n",
    "df_articles, category_encoded_col_name = convert_text2encoding_with_transformers(\n",
    "    df_articles, \n",
    "    transformer_tokenizer,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# For topics - first join the array into single string\n",
    "df_articles = df_articles.with_columns(\n",
    "    pl.col(DEFAULT_TOPICS_COL).map_elements(lambda x: \" | \".join(x[:3])).alias(f\"{DEFAULT_TOPICS_COL}_joined\")\n",
    ")\n",
    "\n",
    "# Then encode the joined topics\n",
    "df_articles, topics_encoded_col_name = convert_text2encoding_with_transformers(\n",
    "    df_articles,\n",
    "    transformer_tokenizer, \n",
    "    f\"{DEFAULT_TOPICS_COL}_joined\",\n",
    "    max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "\n",
    "# Create mappings with encoded columns\n",
    "category_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=category_encoded_col_name\n",
    ")\n",
    "\n",
    "topic_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=topics_encoded_col_name\n",
    ")\n",
    "# Create mappings for numerical features\n",
    "pageviews_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_TOTAL_PAGEVIEWS_COL\n",
    ")\n",
    "\n",
    "read_time_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_TOTAL_READ_TIME_COL\n",
    ")\n",
    "\n",
    "sentiment_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, \n",
    "    value_col=DEFAULT_SENTIMENT_SCORE_COL\n",
    ")\n",
    "\n",
    "timestamp_mapping = create_article_id_to_value_mapping(\n",
    "    df_articles,\n",
    "    value_col=DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(23427, 7)\n",
      "Data preprocessing completed in 7.25 seconds.\n",
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(24336, 7)\n",
      "Data preprocessing completed in 8.60 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NRMSDataSet(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    category_mapping=category_mapping,\n",
    "    topic_mapping=topic_mapping,\n",
    "    pageviews_mapping=pageviews_mapping,\n",
    "    read_time_mapping=read_time_mapping,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    timestamp_mapping=timestamp_mapping\n",
    "\n",
    ")\n",
    "val_dataset = NRMSDataSet(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    category_mapping=category_mapping,\n",
    "    topic_mapping=topic_mapping,\n",
    "    pageviews_mapping=pageviews_mapping,\n",
    "    read_time_mapping=read_time_mapping,\n",
    "    sentiment_mapping=sentiment_mapping,\n",
    "    timestamp_mapping=timestamp_mapping,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 143742031\n",
      "Sample 1:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 406393631\n",
      "Sample 2:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 333126948\n",
      "Sample 3:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 294334127\n",
      "Sample 4:\n",
      "his_input_title shape: torch.Size([20, 300])\n",
      "pred_input_title shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_category shape: torch.Size([20, 128]) 0.0\n",
      "pred_input_topic shape: torch.Size([20]) 0.0\n",
      "pred_input_pageviews shape: torch.Size([20]) 0.0\n",
      "Targets shape: torch.Size([5]) , torch.float32 1.0\n",
      "impression id: 258248879\n"
     ]
    }
   ],
   "source": [
    "for idx in range(5):\n",
    "    sample = train_dataset[idx]\n",
    "    print(f\"Sample {idx}:\")\n",
    "    print(f\"his_input_title shape: {sample[0][0].shape}\")\n",
    "    print(f\"pred_input_title shape: {sample[0][1].shape} {sample[0][1].sum()}\")\n",
    "    print(f\"pred_input_category shape: {sample[0][2].shape} {sample[0][2].sum()}\")\n",
    "    print(f\"pred_input_topic shape: {sample[0][3].shape} {sample[0][3].sum()}\")\n",
    "    print(f\"pred_input_pageviews shape: {sample[0][4].shape} {sample[0][4].sum()}\")\n",
    "    print(f\"Targets shape: {sample[1].shape} , {sample[1].dtype} {sample[1].sum()}\")\n",
    "    print(f\"impression id: {sample[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch\n",
    "\n",
    "def collate_fn_with_global_padding(batch, max_len_pred, apply_padding_to_targets=True):\n",
    "    try:\n",
    "        # Unpack all features including timestamps from dataset samples\n",
    "        his_input_titles = [item[0][0] for item in batch]\n",
    "        his_category_emb = [item[0][1] for item in batch]\n",
    "        his_topic_emb = [item[0][2] for item in batch]\n",
    "        his_sentiment_scores = [item[0][3] for item in batch]\n",
    "        his_read_times = [item[0][4] for item in batch]\n",
    "        his_pageviews = [item[0][5] for item in batch]\n",
    "        his_timestamps = [item[0][6] for item in batch]\n",
    "\n",
    "        pred_input_titles = [item[0][7] for item in batch]\n",
    "        pred_category_emb = [item[0][8] for item in batch]\n",
    "        pred_topic_emb = [item[0][9] for item in batch]\n",
    "        pred_sentiment_scores = [item[0][10] for item in batch]\n",
    "        pred_read_times = [item[0][11] for item in batch]\n",
    "        pred_pageviews = [item[0][12] for item in batch]\n",
    "        pred_timestamps = [item[0][13] for item in batch]\n",
    "        impression_timestamps = [item[0][14] for item in batch]\n",
    "\n",
    "        batch_ys = [item[1] for item in batch]\n",
    "        impression_id = torch.tensor([item[2] for item in batch], dtype=torch.int64)\n",
    "\n",
    "        # Pad user history features\n",
    "        his_input_titles_padded = pad_sequence(his_input_titles, batch_first=True, padding_value=0)\n",
    "        his_category_emb_padded = pad_sequence(his_category_emb, batch_first=True, padding_value=0)\n",
    "        his_topic_emb_padded = pad_sequence(his_topic_emb, batch_first=True, padding_value=0)\n",
    "        his_sentiment_padded = pad_sequence(his_sentiment_scores, batch_first=True, padding_value=0)\n",
    "        his_read_times_padded = pad_sequence(his_read_times, batch_first=True, padding_value=0)\n",
    "        his_pageviews_padded = pad_sequence(his_pageviews, batch_first=True, padding_value=0)\n",
    "        his_timestamps_padded = pad_sequence(his_timestamps, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Pad candidate features\n",
    "        pred_input_titles_padded = pad_sequence(pred_input_titles, batch_first=True, padding_value=0)\n",
    "        pred_category_emb_padded = pad_sequence(pred_category_emb, batch_first=True, padding_value=0)\n",
    "        pred_topic_emb_padded = pad_sequence(pred_topic_emb, batch_first=True, padding_value=0)\n",
    "        pred_sentiment_padded = pad_sequence(pred_sentiment_scores, batch_first=True, padding_value=0)\n",
    "        pred_read_times_padded = pad_sequence(pred_read_times, batch_first=True, padding_value=0)\n",
    "        pred_pageviews_padded = pad_sequence(pred_pageviews, batch_first=True, padding_value=0)\n",
    "        pred_timestamps_padded = pad_sequence(pred_timestamps, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # Convert impression timestamps to tensor\n",
    "        impression_timestamps = torch.stack(impression_timestamps)\n",
    "\n",
    "        # Handle max_len_pred for candidate sequences\n",
    "        if pred_input_titles_padded.size(1) < max_len_pred:\n",
    "            pad_size = max_len_pred - pred_input_titles_padded.size(1)\n",
    "            \n",
    "            pred_input_titles_padded = torch.nn.functional.pad(pred_input_titles_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_category_emb_padded = torch.nn.functional.pad(pred_category_emb_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_topic_emb_padded = torch.nn.functional.pad(pred_topic_emb_padded, (0, 0, 0, pad_size), value=0)\n",
    "            pred_sentiment_padded = torch.nn.functional.pad(pred_sentiment_padded, (0, pad_size), value=0)\n",
    "            pred_read_times_padded = torch.nn.functional.pad(pred_read_times_padded, (0, pad_size), value=0)\n",
    "            pred_pageviews_padded = torch.nn.functional.pad(pred_pageviews_padded, (0, pad_size), value=0)\n",
    "            pred_timestamps_padded = torch.nn.functional.pad(pred_timestamps_padded, (0, pad_size), value=0)\n",
    "\n",
    "        elif pred_input_titles_padded.size(1) > max_len_pred:\n",
    "            pred_input_titles_padded = pred_input_titles_padded[:, :max_len_pred, :]\n",
    "            pred_category_emb_padded = pred_category_emb_padded[:, :max_len_pred, :]\n",
    "            pred_topic_emb_padded = pred_topic_emb_padded[:, :max_len_pred, :]\n",
    "            pred_sentiment_padded = pred_sentiment_padded[:, :max_len_pred]\n",
    "            pred_read_times_padded = pred_read_times_padded[:, :max_len_pred]\n",
    "            pred_pageviews_padded = pred_pageviews_padded[:, :max_len_pred]\n",
    "            pred_timestamps_padded = pred_timestamps_padded[:, :max_len_pred]\n",
    "\n",
    "        # Handle targets padding\n",
    "        if apply_padding_to_targets:\n",
    "            batch_ys_padded = pad_sequence(batch_ys, batch_first=True, padding_value=-1)\n",
    "            if batch_ys_padded.size(1) < max_len_pred:\n",
    "                pad_size = max_len_pred - batch_ys_padded.size(1)\n",
    "                batch_ys_padded = torch.nn.functional.pad(batch_ys_padded, (0, pad_size), value=-1)\n",
    "            elif batch_ys_padded.size(1) > max_len_pred:\n",
    "                batch_ys_padded = batch_ys_padded[:, :max_len_pred]\n",
    "\n",
    "            return (\n",
    "                his_input_titles_padded,\n",
    "                his_category_emb_padded,\n",
    "                his_topic_emb_padded, \n",
    "                his_sentiment_padded,\n",
    "                his_read_times_padded,\n",
    "                his_pageviews_padded,\n",
    "                his_timestamps_padded,\n",
    "                pred_input_titles_padded,\n",
    "                pred_category_emb_padded,\n",
    "                pred_topic_emb_padded,\n",
    "                pred_sentiment_padded,\n",
    "                pred_read_times_padded,\n",
    "                pred_pageviews_padded,\n",
    "                pred_timestamps_padded,\n",
    "                impression_timestamps\n",
    "            ), batch_ys_padded, impression_id\n",
    "        else:\n",
    "            return (\n",
    "                his_input_titles_padded,\n",
    "                his_category_emb_padded,\n",
    "                his_topic_emb_padded,\n",
    "                his_sentiment_padded,\n",
    "                his_read_times_padded,\n",
    "                his_pageviews_padded,\n",
    "                his_timestamps_padded,\n",
    "                pred_input_titles_padded,\n",
    "                pred_category_emb_padded,\n",
    "                pred_topic_emb_padded,\n",
    "                pred_sentiment_padded,\n",
    "                pred_read_times_padded,\n",
    "                pred_pageviews_padded,\n",
    "                pred_timestamps_padded,\n",
    "                impression_timestamps\n",
    "            ), batch_ys, impression_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the dataset with DataLoader\n",
    "train_dataloader_temp = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,    # Set your desired batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_train)\n",
    ")\n",
    "\n",
    "val_dataloader_temp = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,    # Set your desired batch size\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History features shapes:\n",
      "his_input_titles: torch.Size([64, 20, 300])\n",
      "his_category_emb: torch.Size([64, 20, 128])\n",
      "his_topic_emb: torch.Size([64, 20, 128])\n",
      "his_sentiment: torch.Size([64, 20])\n",
      "his_read_times: torch.Size([64, 20])\n",
      "his_pageviews: torch.Size([64, 20])\n",
      "his_timestamps: torch.Size([64, 20])\n",
      "\n",
      "Candidate features shapes:\n",
      "pred_input_titles: torch.Size([64, 89, 300])\n",
      "pred_category_emb: torch.Size([64, 89, 128])\n",
      "pred_topic_emb: torch.Size([64, 89, 128])\n",
      "pred_sentiment: torch.Size([64, 89])\n",
      "pred_read_times: torch.Size([64, 89])\n",
      "pred_pageviews: torch.Size([64, 89])\n",
      "pred_timestamps: torch.Size([64, 89])\n",
      "\n",
      "Other tensors:\n",
      "impression_timestamps: torch.Size([64])\n",
      "batch_ys: torch.Size([64, 89])\n",
      "impression_id: torch.Size([64])\n",
      "\n",
      "Batch loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataloader_temp:\n",
    "    (\n",
    "        his_input_titles_padded, \n",
    "        his_category_emb_padded,\n",
    "        his_topic_emb_padded,\n",
    "        his_sentiment_padded,\n",
    "        his_read_times_padded,\n",
    "        his_pageviews_padded,\n",
    "        his_timestamps_padded,\n",
    "        pred_input_titles_padded,\n",
    "        pred_category_emb_padded,\n",
    "        pred_topic_emb_padded,\n",
    "        pred_sentiment_padded,\n",
    "        pred_read_times_padded,\n",
    "        pred_pageviews_padded,\n",
    "        pred_timestamps_padded,\n",
    "        impression_timestamps\n",
    "    ), batch_ys_padded, impression_id = batch\n",
    "\n",
    "    # Original tensor shapes\n",
    "    print(\"History features shapes:\")\n",
    "    print(f\"his_input_titles: {his_input_titles_padded.shape}\")\n",
    "    print(f\"his_category_emb: {his_category_emb_padded.shape}\")\n",
    "    print(f\"his_topic_emb: {his_topic_emb_padded.shape}\")\n",
    "    print(f\"his_sentiment: {his_sentiment_padded.shape}\")\n",
    "    print(f\"his_read_times: {his_read_times_padded.shape}\")\n",
    "    print(f\"his_pageviews: {his_pageviews_padded.shape}\")\n",
    "    print(f\"his_timestamps: {his_timestamps_padded.shape}\")\n",
    "\n",
    "    print(\"\\nCandidate features shapes:\")\n",
    "    print(f\"pred_input_titles: {pred_input_titles_padded.shape}\")\n",
    "    print(f\"pred_category_emb: {pred_category_emb_padded.shape}\")\n",
    "    print(f\"pred_topic_emb: {pred_topic_emb_padded.shape}\")\n",
    "    print(f\"pred_sentiment: {pred_sentiment_padded.shape}\")\n",
    "    print(f\"pred_read_times: {pred_read_times_padded.shape}\")\n",
    "    print(f\"pred_pageviews: {pred_pageviews_padded.shape}\")\n",
    "    print(f\"pred_timestamps: {pred_timestamps_padded.shape}\")\n",
    "    \n",
    "    print(\"\\nOther tensors:\")\n",
    "    print(f\"impression_timestamps: {impression_timestamps.shape}\")\n",
    "    print(f\"batch_ys: {batch_ys_padded.shape}\")\n",
    "    print(f\"impression_id: {impression_id.shape}\")\n",
    "\n",
    "    print(\"\\nBatch loaded successfully!\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the shapes.\n",
    "\n",
    "1. `his_input_titles_padded: [128, 20, 300]`\n",
    "   - 128: batch size\n",
    "   - 20: max history length (user's reading history)\n",
    "   - 300: title embedding dimension from ConvBERT\n",
    "\n",
    "2. `pred_input_titles_padded: [128, 90, 300]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles to predict\n",
    "   - 300: title embedding dimension from ConvBERT\n",
    "\n",
    "3. `pred_category_emb_padded: [128, 90, 128]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - 128: category embedding dimension from ConvBERT\n",
    "\n",
    "4. `pred_topic_emb_padded: [128, 90, 128]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - 128: topic embedding dimension from ConvBERT\n",
    "\n",
    "5. `pred_sentiment_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single sentiment score per article\n",
    "\n",
    "6. `pred_read_times_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single read time value per article\n",
    "\n",
    "7. `pred_pageviews_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Single pageview count per article\n",
    "\n",
    "8. `batch_ys_padded: [128, 90]`\n",
    "   - 128: batch size\n",
    "   - 90: max candidate articles\n",
    "   - Binary labels (1 for clicked, 0 for not clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'models_pytorch.model_config', '__annotations__': {'title_size': <class 'int'>, 'embedding_dim': <class 'int'>, 'word_emb_dim': <class 'int'>, 'vocab_size': <class 'int'>, 'head_num': <class 'int'>, 'head_dim': <class 'int'>, 'attention_hidden_dim': <class 'int'>, 'optimizer': <class 'str'>, 'loss': <class 'str'>, 'dropout': <class 'float'>, 'learning_rate': <class 'float'>, 'weight_decay': <class 'float'>, 'units_per_layer': list[int], 'use_category': <class 'bool'>, 'use_topic': <class 'bool'>, 'use_numeric': <class 'bool'>, 'use_session_discount': <class 'bool'>, 'use_publication_discount': <class 'bool'>, 'doc_out_dim': <class 'int'>, 'cat_out_dim': <class 'int'>, 'top_out_dim': <class 'int'>, 'numeric_proj_dim': <class 'int'>}, 'title_size': 300, 'embedding_dim': 32, 'word_emb_dim': 8, 'vocab_size': 10000, 'head_num': 16, 'head_dim': 128, 'attention_hidden_dim': 128, 'hidden_dim': 4, 'optimizer': 'adam', 'loss': 'cross_entropy_loss', 'dropout': 0.3, 'learning_rate': 0.0001, 'weight_decay': 0.001, 'news_output_dim': 128, 'units_per_layer': [512, 256], 'use_category': True, 'use_topic': True, 'use_numeric': True, 'use_session_discount': True, 'use_publication_discount': True, 'doc_out_dim': 128, 'cat_out_dim': 128, 'top_out_dim': 128, 'numeric_proj_dim': 16, '__dict__': <attribute '__dict__' of 'hparams_nrms' objects>, '__weakref__': <attribute '__weakref__' of 'hparams_nrms' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# see the model parameters: \n",
    "hparams_nrms.attention_hidden_dim = 128\n",
    "hparams_nrms.title_size = 300\n",
    "hparams_nrms.head_num = 16\n",
    "hparams_nrms.head_dim = 128\n",
    "hparams_nrms.units_per_layer = [512,256]\n",
    "hparams_nrms.news_output_dim = 128\n",
    "hparams_nrms.dropout = 0.3\n",
    "hparams_nrms.learning_rate = 1e-4\n",
    "hparams_nrms.use_category = True\n",
    "hparams_nrms.use_topic = True\n",
    "hparams_nrms.use_numeric = True\n",
    "hparams_nrms.use_publication_discount = True\n",
    "hparams_nrms.use_session_discount = True\n",
    "print(hparams_nrms.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best trial:\n",
    "  Value:  3.8567059058842696\n",
    "  Params: \n",
    "    head_num: 16\n",
    "    shared_dim: 99\n",
    "    dropout: 0.17498541169326048\n",
    "    learning_rate: 1.0454050068420554e-05\n",
    "    weight_decay: 0.006587407554797856\n",
    "    unit_layer_1: 421\n",
    "    unit_layer_2: 386\n",
    "    use_category: False\n",
    "    use_topic: False\n",
    "    use_numeric: True\n",
    "    use_publication_discount: False\n",
    "    use_session_discount: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters with best trial results\n",
    "\n",
    "# Keep original parameters\n",
    "hparams_nrms.title_size = 300\n",
    "\n",
    "# Update with optimized parameters\n",
    "hparams_nrms.head_num = 4\n",
    "shared_dim = 140  # Rounded up 137 to nearest multiple of head_num\n",
    "hparams_nrms.head_dim = shared_dim\n",
    "hparams_nrms.attention_hidden_dim = shared_dim\n",
    "hparams_nrms.news_output_dim = shared_dim\n",
    "\n",
    "# Update layers\n",
    "hparams_nrms.units_per_layer = [257, 475]  # From optimization\n",
    "\n",
    "# Update learning parameters\n",
    "hparams_nrms.dropout = 0.208\n",
    "hparams_nrms.learning_rate = 8.486e-4\n",
    "hparams_nrms.weight_decay = 1.697e-3\n",
    "\n",
    "# Update feature flags based on optimization\n",
    "hparams_nrms.use_category = True\n",
    "hparams_nrms.use_topic = False\n",
    "hparams_nrms.use_numeric = False\n",
    "hparams_nrms.use_publication_discount = False\n",
    "hparams_nrms.use_session_discount = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update hyperparameters with best trial results\n",
    "\n",
    "# Keep original parameters\n",
    "hparams_nrms.title_size = 300\n",
    "\n",
    "# Update with optimized parameters\n",
    "hparams_nrms.head_num = 16\n",
    "shared_dim = 128  # Rounded up 137 to nearest multiple of head_num\n",
    "hparams_nrms.head_dim = shared_dim\n",
    "hparams_nrms.attention_hidden_dim = shared_dim\n",
    "hparams_nrms.news_output_dim = shared_dim\n",
    "\n",
    "# Update layers\n",
    "hparams_nrms.units_per_layer = [421, 386]  # From optimization\n",
    "\n",
    "# Update learning parameters\n",
    "hparams_nrms.dropout = 0.1749\n",
    "hparams_nrms.learning_rate = 1.0454050068420554e-5\n",
    "hparams_nrms.weight_decay = 0.006587407554797856\n",
    "\n",
    "# Update feature flags based on optimization\n",
    "hparams_nrms.use_category = False\n",
    "hparams_nrms.use_topic = False\n",
    "hparams_nrms.use_numeric = False\n",
    "hparams_nrms.use_publication_discount = True\n",
    "hparams_nrms.use_session_discount = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define paths\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = os.path.join(\"downloads\", \"runs\", MODEL_NAME)\n",
    "MODEL_WEIGHTS = os.path.join(\"downloads\", \"data\", \"state_dict\", MODEL_NAME, \"weights.pth\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_WEIGHTS), exist_ok=True)\n",
    "\n",
    "# Define ModelCheckpoint class\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Saves the model after every epoch if it has the best performance so far.\"\"\"\n",
    "    def __init__(self, filepath, verbose=False, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath (str): Path to save the model checkpoint.\n",
    "            verbose (bool): If True, prints a message when the model is saved.\n",
    "            save_best_only (bool): If True, saves only when the model is better than before.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_loss = None\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.filepath)\n",
    "        if self.verbose:\n",
    "            print(f\"Model saved to {self.filepath}\")\n",
    "\n",
    "# Define EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve by a given percentage over a patience period.\"\"\"\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after last time validation loss improved by min_delta.\n",
    "            min_delta (float): Minimum percentage improvement required to reset patience.\n",
    "            verbose (bool): If True, prints a message when early stopping is triggered.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta  # Minimum percentage improvement\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            # Initialize best_loss with the first validation loss\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss < self.best_loss * (1 - self.min_delta):\n",
    "            # Significant improvement found\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved by at least {self.min_delta*100:.1f}%\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No significant improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "# Initialize callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_WEIGHTS, verbose=True, save_best_only=True)\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "\n",
    "# Initialize your model\n",
    "# Ensure that NRMSModel is a PyTorch nn.Module\n",
    "\n",
    "# CUDA checks\n",
    "#print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "#print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "#print(f\"Device Name: {torch.cuda.get_device_name()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "# model = NRMSModel(\n",
    "#     hparams=hparams_nrms.__dict__,\n",
    "#     word2vec_embedding=word2vec_embedding,\n",
    "#     vocab_size=30000,\n",
    "#     word_emb_dim=8,\n",
    "#     device=device,\n",
    "#     feed_forward_layers_after_3rd_layer=False,\n",
    "# )\n",
    "\n",
    "model = NRMSDocVecModel(hparams=hparams_nrms.__dict__,\n",
    "                        device=device)\n",
    "\n",
    "# model = NRMSModel(hparams=hparams_nrms.__dict__,\n",
    "#                   word2vec_embedding=word2vec_embedding,\n",
    "#                         device=device)\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSDocVecModel(\n",
      "  (newsencoder): NewsEncoderDocVec(\n",
      "    (doc_encoder): DocEncoder(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (3): Dropout(p=0.1749, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (feature_fusion): FeatureFusion(\n",
      "      (linears): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (gates): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (activation): Sigmoid()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (time_discount): TimeDiscount(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (userencoder): UserEncoderDocVec(\n",
      "    (titleencoder): NewsEncoderDocVec(\n",
      "      (doc_encoder): DocEncoder(\n",
      "        (layer): Sequential(\n",
      "          (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Dropout(p=0.1749, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (feature_fusion): FeatureFusion(\n",
      "        (linears): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (gates): ModuleList(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (activation): Sigmoid()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      (time_discount): TimeDiscount(\n",
      "        (layer): Sequential(\n",
      "          (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "          (1): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (self_attention): SelfAttention(\n",
      "      (multihead_attention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (attention_layer): AttLayer2(\n",
      "      (V_w): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (q_w): Linear(in_features=128, out_features=1, bias=False)\n",
      "    )\n",
      "    (user_projection): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "    (time_discount): TimeDiscount(\n",
      "      (layer): Sequential(\n",
      "        (0): Linear(in_features=1, out_features=1, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer: newsencoder.doc_encoder.layer.0.weight | Size: torch.Size([128, 300])\n",
      "Layer: newsencoder.doc_encoder.layer.0.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.doc_encoder.layer.2.weight | Size: torch.Size([128])\n",
      "Layer: newsencoder.doc_encoder.layer.2.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.feature_fusion.linears.0.weight | Size: torch.Size([128, 128])\n",
      "Layer: newsencoder.feature_fusion.linears.0.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.feature_fusion.gates.0.weight | Size: torch.Size([128, 128])\n",
      "Layer: newsencoder.feature_fusion.gates.0.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.layer_norm.weight | Size: torch.Size([128])\n",
      "Layer: newsencoder.layer_norm.bias | Size: torch.Size([128])\n",
      "Layer: newsencoder.time_discount.layer.0.weight | Size: torch.Size([1, 1])\n",
      "Layer: newsencoder.time_discount.layer.0.bias | Size: torch.Size([1])\n",
      "Layer: userencoder.self_attention.multihead_attention.in_proj_weight | Size: torch.Size([384, 128])\n",
      "Layer: userencoder.self_attention.multihead_attention.in_proj_bias | Size: torch.Size([384])\n",
      "Layer: userencoder.self_attention.multihead_attention.out_proj.weight | Size: torch.Size([128, 128])\n",
      "Layer: userencoder.self_attention.multihead_attention.out_proj.bias | Size: torch.Size([128])\n",
      "Layer: userencoder.attention_layer.V_w.weight | Size: torch.Size([128, 128])\n",
      "Layer: userencoder.attention_layer.V_w.bias | Size: torch.Size([128])\n",
      "Layer: userencoder.attention_layer.q_w.weight | Size: torch.Size([1, 128])\n",
      "Layer: userencoder.user_projection.weight | Size: torch.Size([128, 128])\n",
      "Layer: userencoder.user_projection.bias | Size: torch.Size([128])\n",
      "Layer: userencoder.layer_norm.weight | Size: torch.Size([128])\n",
      "Layer: userencoder.layer_norm.bias | Size: torch.Size([128])\n",
      "Layer: userencoder.time_discount.layer.0.weight | Size: torch.Size([1, 1])\n",
      "Layer: userencoder.time_discount.layer.0.bias | Size: torch.Size([1])\n",
      "\n",
      "Total parameters: 171,524\n"
     ]
    }
   ],
   "source": [
    "# 1. Print model architecture\n",
    "print(model)\n",
    "\n",
    "# 2. Print specific layer sizes\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")\n",
    "\n",
    "# 3. Get total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "\n",
    "# 4. Print layer by layer with shapes\n",
    "def print_model_structure(model):\n",
    "    print(\"\\nDetailed Model Structure:\")\n",
    "    for name, module in model.named_children():\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Type: {type(module).__name__}\")\n",
    "        if hasattr(module, 'weight'):\n",
    "            print(f\"Shape: {module.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Added gradient clipping to avoid exploiding gradients. The paramter MAX_GRAD_NORM is set to 5.0 as this is a common value used in transformers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperoptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# NUM_EPOCHS = 8\n",
    "# WEIGHT_DECAY = 1e-3\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define fixed valid head numbers\n",
    "#     possible_head_nums = [2, 4, 8, 16, 32]\n",
    "    \n",
    "#     # First suggest head_num from fixed choices\n",
    "#     head_num = trial.suggest_categorical('head_num', possible_head_nums)\n",
    "    \n",
    "#     # Suggest shared_dim that's divisible by head_num\n",
    "#     min_dim = max(64, head_num)  # Ensure minimum dimension works with head_num\n",
    "#     max_dim = 256\n",
    "#     shared_dim = trial.suggest_int('shared_dim', min_dim, max_dim)\n",
    "    \n",
    "#     # Round shared_dim to nearest multiple of head_num\n",
    "#     shared_dim = (shared_dim // head_num) * head_num\n",
    "    \n",
    "#     # Skip if dimensions don't work\n",
    "#     if shared_dim < head_num:\n",
    "#         raise optuna.TrialPruned()\n",
    "    \n",
    "#     hparams = {\n",
    "#         'title_size': 300,\n",
    "#         'head_num': head_num,\n",
    "#         'head_dim': shared_dim,\n",
    "#         'attention_hidden_dim':shared_dim,\n",
    "#         'news_output_dim': shared_dim,\n",
    "#         'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n",
    "#         'weight_decay': trial.suggest_float('weight_decay', 1e-4, 1e-2, log=True),\n",
    "#         'units_per_layer': [\n",
    "#             trial.suggest_int('unit_layer_1', 256, 512),\n",
    "#             trial.suggest_int('unit_layer_2', 256, 512),\n",
    "#         ],\n",
    "#         'use_category': trial.suggest_categorical('use_category', [True, False]),\n",
    "#         'use_topic': trial.suggest_categorical('use_topic', [True, False]),\n",
    "#         'use_numeric': trial.suggest_categorical('use_numeric', [True, False]),\n",
    "#         'use_publication_discount': trial.suggest_categorical('use_publication_discount', [True, False]),\n",
    "#         'use_session_discount': trial.suggest_categorical('use_session_discount', [True, False])\n",
    "#     }\n",
    "\n",
    "#     # Initialize model and training components\n",
    "#     model = NRMSDocVecModel(hparams=hparams, device=device)\n",
    "#     criterion = model.get_loss().to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), \n",
    "#                           lr=hparams['learning_rate'], \n",
    "#                           weight_decay=hparams['weight_decay'])\n",
    "    \n",
    "#     # Initialize EarlyStopping\n",
    "#     early_stopping = EarlyStopping(patience=4, min_delta=0.025, verbose=True)\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         running_loss = 0.0\n",
    "#         train_batch_count = 0\n",
    "\n",
    "#         for batch in train_dataloader_temp:\n",
    "#             inputs, targets, impression_id = batch\n",
    "#             inputs = [inp.to(device) for inp in inputs]\n",
    "#             targets = targets.to(device)\n",
    "#             positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#             targets = positive_indices[:, 1].long()\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(*inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item()\n",
    "#             train_batch_count += 1\n",
    "\n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         val_loss = 0.0\n",
    "#         val_batch_count = 0\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for batch in val_dataloader_temp:\n",
    "#                 inputs, targets, impression_id = batch\n",
    "#                 inputs = [inp.to(device) for inp in inputs]\n",
    "#                 targets = targets.to(device)\n",
    "#                 positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#                 targets = positive_indices[:, 1].long()\n",
    "#                 outputs = model(*inputs)\n",
    "#                 loss = criterion(outputs, targets)\n",
    "#                 val_loss += loss.item()\n",
    "#                 val_batch_count += 1\n",
    "\n",
    "#         avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "\n",
    "#         # Update best validation loss\n",
    "#         if avg_val_loss < best_val_loss:\n",
    "#             best_val_loss = avg_val_loss\n",
    "\n",
    "#         # Early stopping check\n",
    "#         early_stopping(avg_val_loss)\n",
    "#         if early_stopping.early_stop:\n",
    "#             break\n",
    "\n",
    "#         # Report to Optuna\n",
    "#         trial.report(avg_val_loss, epoch)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "\n",
    "#     return best_val_loss\n",
    "\n",
    "# # Create study and optimize\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=15)  # Increased from 3 to 50 trials\n",
    "\n",
    "# # Print results\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  67%|██████▋   | 10/15 [03:05<01:33, 18.75s/it, train_loss=1.6867, val_loss=2.7739]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint saved at epoch 10 with validation loss: 2.7739\n",
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  80%|████████  | 12/15 [03:43<00:56, 18.98s/it, train_loss=1.5886, val_loss=2.8200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 15/15 [04:44<00:00, 18.96s/it, train_loss=1.5134, val_loss=2.7128]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure you have defined or imported the EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "        elif current_score < self.best_score - self.min_delta:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Define model_checkpoint function if not already defined\n",
    "def model_checkpoint(model, val_loss, epoch, path='model_checkpoint.pth'):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'val_loss': val_loss,\n",
    "    }, path)\n",
    "    print(f\"Model checkpoint saved at epoch {epoch} with validation loss: {val_loss:.4f}\")\n",
    "\n",
    "# Initialize components\n",
    "NUM_EPOCHS = 15\n",
    "early_stopping = EarlyStopping(patience=4, min_delta=0.025, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Use appropriate loss function\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=hparams_nrms.learning_rate,  # Ensure hparams_nrms is defined and has learning_rate\n",
    "    weight_decay=hparams_nrms.weight_decay  # Ensure hparams_nrms has weight_decay\n",
    ")\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=True\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Ensure your dataloaders are defined\n",
    "# train_dataloader_temp = ...\n",
    "# val_dataloader_temp = ...\n",
    "\n",
    "epoch_pbar = tqdm(range(1, NUM_EPOCHS + 1), desc=\"Training Progress\", dynamic_ncols=True)\n",
    "for epoch in epoch_pbar:\n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch in train_dataloader_temp:\n",
    "        inputs, targets, _ = batch  # Assuming the third element is not used\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Extract positive indices\n",
    "        positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "        if positive_indices.numel() == 0:\n",
    "            raise ValueError(\"No positive samples in the batch\")\n",
    "            continue  # Skip if no positive samples in the batch\n",
    "        targets = positive_indices[:, 1].long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs)  # Shape: (N, C)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    avg_train_loss = running_loss / train_batch_count if train_batch_count > 0 else float('inf')\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batch_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader_temp:\n",
    "            inputs, targets, _ = batch\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "            if positive_indices.numel() == 0:\n",
    "                continue\n",
    "            targets = positive_indices[:, 1].long()\n",
    "\n",
    "            outputs = model(*inputs)  # Shape: (N, C)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_batch_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Logging\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "\n",
    "    # Update Progress Bar\n",
    "    epoch_pbar.set_postfix({\n",
    "        'train_loss': f'{avg_train_loss:.4f}',\n",
    "        'val_loss': f'{avg_val_loss:.4f}',\n",
    "    })\n",
    "\n",
    "    # Save Checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        model_checkpoint(model, avg_val_loss, epoch)\n",
    "\n",
    "    # Scheduler Step\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Summary:\n",
      "Initial Training Loss: 9.4003\n",
      "Final Training Loss: 1.5134\n",
      "Best Training Loss: 1.5134\n",
      "\n",
      "Initial Validation Loss: 12.0907\n",
      "Final Validation Loss: 2.7128\n",
      "Best Validation Loss: 2.5744\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"nrms_training_loss.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print final statistics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Initial Training Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Training Loss: {min(train_losses):.4f}\")\n",
    "print(f\"\\nInitial Validation Loss: {val_losses[0]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Validation Loss: {min(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def evaluate_model(model, dataloader, device):\n",
    "#     \"\"\"Evaluate the model and return predictions and labels for metric calculation.\"\"\"\n",
    "#     model.eval()\n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     print(\"\\nEvaluating DataLoader...\")\n",
    "#     total_samples = len(dataloader.dataset)\n",
    "#     print(f\"Total samples in DataLoader: {total_samples}\")\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets, impression_ids) in enumerate(dataloader):\n",
    "#             his_input_title, pred_input_title = inputs\n",
    "\n",
    "#             if batch_idx == 0:  # Debug first batch shapes\n",
    "#                 print(\"\\nFirst batch shapes:\")\n",
    "#                 print(f\"  - his_input_title: {his_input_title.shape}\")\n",
    "#                 print(f\"  - pred_input_title: {pred_input_title.shape}\")\n",
    "#                 print(f\"  - targets: {targets.shape}\")\n",
    "\n",
    "#             # Move data to device\n",
    "#             his_input_title = his_input_title.to(device)\n",
    "#             pred_input_title = pred_input_title.to(device)\n",
    "#             targets = targets.to(device)\n",
    "\n",
    "#             # Get predictions\n",
    "#             predictions = model.predict(his_input_title, pred_input_title)\n",
    "#             predictions = predictions.cpu().numpy()\n",
    "#             targets = targets.cpu().numpy()\n",
    "\n",
    "#             # Process each sample in the batch\n",
    "#             batch_size = predictions.shape[0]\n",
    "#             for sample_idx in range(batch_size):\n",
    "#                 pred = predictions[sample_idx]\n",
    "#                 label = targets[sample_idx]\n",
    "\n",
    "#                 # Create valid_mask where label is not equal to the padding value (-1)\n",
    "#                 valid_mask = (label != -1)\n",
    "#                 sample_preds = pred[valid_mask]\n",
    "#                 sample_labels = label[valid_mask]\n",
    "\n",
    "#                 if len(sample_labels) == 0:\n",
    "#                     continue  # Skip empty samples\n",
    "\n",
    "#                 # Ensure that there is at least one positive and one negative label\n",
    "#                 if len(np.unique(sample_labels)) < 2:\n",
    "#                     continue  # Skip samples with only one class\n",
    "\n",
    "#                 all_predictions.append(sample_preds.tolist())\n",
    "#                 all_labels.append(sample_labels.tolist())\n",
    "\n",
    "#     print(\"\\nEvaluation completed.\")\n",
    "#     print(f\"Total predictions generated: {len(all_predictions)}\")\n",
    "#     print(f\"First few prediction lengths: {[len(x) for x in all_predictions[:15]]}\")\n",
    "#     return all_labels, all_predictions\n",
    "\n",
    "\n",
    "# # Evaluate the model\n",
    "# labels_list, scores_list = evaluate_model(model, val_dataloader_temp, device)\n",
    "\n",
    "# # Validate predictions against the DataFrame\n",
    "# print(\"\\nValidation against DataFrame:\")\n",
    "# if len(scores_list) != len(df_validation):\n",
    "#     print(\"WARNING: Length mismatch!\")\n",
    "#     print(f\"  - Number of predictions: {len(scores_list)}\")\n",
    "#     print(f\"  - Number of rows in DataFrame: {len(df_validation)}\")\n",
    "\n",
    "# # Compute metrics\n",
    "# metrics = MetricEvaluator(\n",
    "#     labels=labels_list,\n",
    "#     predictions=scores_list,\n",
    "#     metric_functions=[\n",
    "#         AucScore(),\n",
    "#         MrrScore(),\n",
    "#         NdcgScore(k=5),\n",
    "#         NdcgScore(k=10)\n",
    "#     ],\n",
    "# )\n",
    "# results = metrics.evaluate()\n",
    "# print(\"\\nMetrics:\", results.evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRACTION: 0.1, HISTORY_SIZE: 20\n",
      "Hyperparameters:\n",
      "title_size: 300\n",
      "embedding_dim: 32\n",
      "word_emb_dim: 8\n",
      "vocab_size: 10000\n",
      "head_num: 16\n",
      "head_dim: 128\n",
      "attention_hidden_dim: 128\n",
      "hidden_dim: 4\n",
      "optimizer: adam\n",
      "loss: cross_entropy_loss\n",
      "dropout: 0.1749\n",
      "learning_rate: 1.0454050068420554e-05\n",
      "weight_decay: 0.006587407554797856\n",
      "news_output_dim: 128\n",
      "units_per_layer: [421, 386]\n",
      "use_category: False\n",
      "use_topic: False\n",
      "use_numeric: False\n",
      "use_session_discount: True\n",
      "use_publication_discount: True\n",
      "doc_out_dim: 128\n",
      "cat_out_dim: 128\n",
      "top_out_dim: 128\n",
      "numeric_proj_dim: 16\n"
     ]
    }
   ],
   "source": [
    "print(f\"FRACTION: {FRACTION}, HISTORY_SIZE: {HISTORY_SIZE}\")\n",
    "\n",
    "# Filter out special Python attributes and print parameters\n",
    "params = {k: v for k, v in hparams_nrms.__dict__.items() if not k.startswith('__')}\n",
    "print(\"Hyperparameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_labels(df: pl.DataFrame, impression_id: int) -> int:\n",
    "    # Filter for matching impression_id\n",
    "    filtered = df.filter(pl.col('impression_id') == impression_id)\n",
    "    \n",
    "    if filtered.height == 0:\n",
    "        raise ValueError(f\"No row found for impression_id {impression_id}\")\n",
    "    \n",
    "    # Get labels from first row\n",
    "    labels = filtered.select('labels').row(0)[0]\n",
    "    \n",
    "    return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_length_of_labels(df_validation, 349992000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "Label 1: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "Label 2: [0, 0, 0, 1, 0, 0]\n",
      "Label 3: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Label 4: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 labels\n",
    "first_5_labels = df_validation.select('labels').head(5)\n",
    "\n",
    "# Print each label with index\n",
    "for i, row in enumerate(first_5_labels.iter_rows()):\n",
    "    print(f\"Label {i}: {row[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples with only one class\n",
      "Remaining valid samples: 24336\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize lists\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "skipped_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_dataloader_temp:\n",
    "        inputs, targets, impression_ids = batch\n",
    "        \n",
    "        # Move to device\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(*inputs)\n",
    "        \n",
    "        # Convert to probabilities if needed\n",
    "        if not torch.is_floating_point(predictions):\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Convert to lists while preserving structure\n",
    "        batch_preds = predictions.cpu().numpy().tolist()\n",
    "        batch_labels = targets.cpu().numpy().tolist()\n",
    "        impression_ids = impression_ids.cpu().numpy().tolist()\n",
    "        \n",
    "        batch_preds_without_padding = []\n",
    "        batch_labels_without_padding = []\n",
    "        \n",
    "        for pred_sample, label_sample, impression_id_sample in zip(batch_preds, batch_labels, impression_ids):\n",
    "            # Remove padding\n",
    "            actual_length = get_length_of_labels(df_validation, impression_id_sample)\n",
    "            pred_sample = pred_sample[:actual_length]\n",
    "            \n",
    "            # Check if sample has both classes before adding\n",
    "            if 1 in label_sample[:actual_length] and 0 in label_sample[:actual_length]:\n",
    "                batch_preds_without_padding.append(pred_sample)\n",
    "                batch_labels_without_padding.append(label_sample[:actual_length])\n",
    "            else:\n",
    "                skipped_samples += 1\n",
    "        \n",
    "        # Add batch predictions and labels\n",
    "        all_predictions.extend(batch_preds_without_padding)\n",
    "        all_labels.extend(batch_labels_without_padding)\n",
    "\n",
    "print(f\"Skipped {skipped_samples} samples with only one class\")\n",
    "print(f\"Remaining valid samples: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug: Print label distribution for first 5 samples\n",
    "# for i, (preds, labels) in enumerate(zip(all_predictions[:5], all_labels[:5])):\n",
    "#     print(f\"\\nSample {i}:\")\n",
    "#     print(f\"Labels length:      {len(labels)}\")\n",
    "#     print(f\"Predictions length: {len(preds)}\")\n",
    "#     print(f\"Num positives: {sum(labels)}\")\n",
    "#     print(f\"Num negatives: {len(labels) - sum(labels)}\")\n",
    "#     print(f\"Label distribution: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(all_predictions))\n",
    "# print(type(all_labels))\n",
    "\n",
    "# print(f\"Number of predictions: {len(all_predictions)}\")\n",
    "# print(f\"example prediction: {all_predictions[0:2]}\")\n",
    "# print(f\"Number of labels: {len(all_labels)}\")\n",
    "# print(f\"example label: {all_labels[0:2]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1662\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "correct_predictions = 0\n",
    "total_samples = len(all_predictions)\n",
    "\n",
    "# Iterate over samples\n",
    "for idx, _ in enumerate(all_predictions):\n",
    "    # print(f\"Sample {idx}: Prediction: {all_predictions[idx]}\")\n",
    "    # print(f\"Sample {idx}: Label:      {all_labels[idx]}\")\n",
    "    \n",
    "    # Extract index of maximum value in predictions and labels\n",
    "    pred_max_index = np.argmax(all_predictions[idx])\n",
    "    label_max_index = np.argmax(all_labels[idx])\n",
    "    \n",
    "    # Compare indices to determine if the prediction was correct\n",
    "    if pred_max_index == label_max_index:\n",
    "        # print(f\"Sample {idx}: Prediction was correct.\")\n",
    "        correct_predictions += 1\n",
    "  #  else:\n",
    "        # print(f\"Sample {idx}: Prediction was wrong.\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.5861\n",
      "Number of valid AUC calculations: 24336\n"
     ]
    }
   ],
   "source": [
    "from evaluation import AucScore\n",
    "\n",
    "# auc_score = AucScore()\n",
    "\n",
    "# auc_score.calculate(all_predictions, all_labels)\n",
    "# print(f\"AUC: {auc_score.score}\")\n",
    "# # Calculate AUC per sample\n",
    "aucs = []\n",
    "for preds, labels in zip(all_predictions, all_labels):\n",
    "    try:\n",
    "        # Only calculate if we have both positive and negative samples\n",
    "        if sum(labels) > 0 and sum(labels) < len(labels):\n",
    "            auc = roc_auc_score(labels, preds)\n",
    "            aucs.append(auc)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Only one class present in labels. Cannot calculate AUC.\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(aucs):.4f}\")\n",
    "print(f\"Number of valid AUC calculations: {len(aucs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
