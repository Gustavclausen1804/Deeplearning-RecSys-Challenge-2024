{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Python version: 3.12.5\n",
      "PyTorch version: 2.5.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "#import optuna\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL\n",
    ")\n",
    "\n",
    "from utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "from utils._articles import convert_text2encoding_with_transformers\n",
    "from utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from utils._articles import create_article_id_to_value_mapping\n",
    "from utils._nlp import get_transformers_word_embeddings, generate_embeddings_with_transformers\n",
    "from utils._python import write_submission_file, rank_predictions_by_score\n",
    "from models_pytorch.model_config import hparams_nrms\n",
    "\n",
    "from models_pytorch.nrms import NRMSModel\n",
    "from models_pytorch.NRMSDocVecModel import NRMSDocVecModel\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from models_pytorch.dataloader import NRMSDataSet\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 64\n",
    "\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at behaviours and history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebnerd_small\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"./ebnerd_small\")  # Base path for your data directory\n",
    "print(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>740433</td><td>[9757162, 9758025, … 9765545]</td><td>[9772099, 9772805, … 9772805]</td><td>[9772099]</td><td>476847549</td><td>[1, 0, … 0]</td></tr><tr><td>1539443</td><td>[9745793, 9669928, … 9769367]</td><td>[9771888, 9771896, … 9771125]</td><td>[9771846]</td><td>453507149</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 740433  ┆ [9757162,         ┆ [9772099,         ┆ [9772099]        ┆ 476847549     ┆ [1, 0, … 0] │\n",
       "│         ┆ 9758025, …        ┆ 9772805, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9765545]          ┆ 9772805]          ┆                  ┆               ┆             │\n",
       "│ 1539443 ┆ [9745793,         ┆ [9771888,         ┆ [9771846]        ┆ 453507149     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9669928, …        ┆ 9771896, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9769367]          ┆ 9771125]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 40 # TODO: History size. \n",
    "FRACTION = 0.2\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of article_ids_inview in df_train: 5.0\n",
      "Average length of article_ids_inview in df_validation: 12.005068568742464\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_length(df, column):\n",
    "    total_length = sum(len(row) for row in df[column])\n",
    "    average_length = total_length / len(df)\n",
    "    return average_length\n",
    "\n",
    "# Calculate average length for df_train\n",
    "average_length_inview_train = calculate_average_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_train: {average_length_inview_train}\")\n",
    "\n",
    "# Calculate average length for df_validation\n",
    "average_length_inview_validation = calculate_average_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "print(f\"Average length of article_ids_inview in df_validation: {average_length_inview_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest inview article length in df_train: 5\n",
      "Longest inview article length in df_validation: 88\n",
      "Longest history length in df_train: 40\n",
      "Longest history length in df_validation: 40\n"
     ]
    }
   ],
   "source": [
    "# Function to find the maximum length of arrays in a column\n",
    "def find_max_length(df, column):\n",
    "    max_length = 0\n",
    "    for row in df[column]:\n",
    "        max_length = max(max_length, len(row))\n",
    "    return max_length\n",
    "\n",
    "# Find the longest inview article length in df_train\n",
    "max_inview_length_train = find_max_length(df_train, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "# Find the longest inview article length in df_validation\n",
    "max_inview_length_validation = find_max_length(df_validation, DEFAULT_INVIEW_ARTICLES_COL)\n",
    "\n",
    "print(f\"Longest inview article length in df_train: {max_inview_length_train}\")\n",
    "print(f\"Longest inview article length in df_validation: {max_inview_length_validation}\")\n",
    "\n",
    "max_history_length_train = find_max_length(df_train, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "max_history_length_validation = find_max_length(df_validation, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "\n",
    "print(f\"Longest history length in df_train: {max_history_length_train}\")\n",
    "print(f\"Longest history length in df_validation: {max_history_length_validation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with exactly one clicked article in df_train: 46855\n",
      "Number of rows with exactly one clicked article in df_validation: 48659\n"
     ]
    }
   ],
   "source": [
    "# Function to filter rows with exactly one clicked article\n",
    "def filter_rows_with_one_clicked_article(df, clicked_articles_col):\n",
    "    # Manually filter rows where the array has exactly one element\n",
    "    filtered_rows = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        if len(row[clicked_articles_col]) == 1:\n",
    "            filtered_rows.append(row)\n",
    "    return pl.DataFrame(filtered_rows)\n",
    "\n",
    "\n",
    "# Filter rows in df_train and df_validation\n",
    "df_train = filter_rows_with_one_clicked_article(df_train, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "df_validation = filter_rows_with_one_clicked_article(df_validation, DEFAULT_CLICKED_ARTICLES_COL)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of rows with exactly one clicked article in df_train: {df_train.shape[0]}\")\n",
    "print(f\"Number of rows with exactly one clicked article in df_validation: {df_validation.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>i64</td><td>list[i64]</td><td>list[i64]</td><td>list[i64]</td><td>i64</td><td>list[i64]</td></tr></thead><tbody><tr><td>2326954</td><td>[0, 0, … 9774079]</td><td>[6741781, 9785076, … 9484153]</td><td>[9785076]</td><td>103850774</td><td>[0, 1, … 0]</td></tr><tr><td>1297073</td><td>[9771242, 9769917, … 9779648]</td><td>[9788898, 9788823, … 9696697]</td><td>[9788823]</td><td>361906390</td><td>[0, 1, … 0]</td></tr><tr><td>1247845</td><td>[9775846, 9777296, … 9779427]</td><td>[9785596, 9786566, … 9786378]</td><td>[9786139]</td><td>504765231</td><td>[0, 0, … 0]</td></tr><tr><td>1095253</td><td>[9773877, 9773877, … 9780195]</td><td>[9781158, 9780921, … 9779225]</td><td>[9781057]</td><td>380153523</td><td>[0, 0, … 0]</td></tr><tr><td>971347</td><td>[9777475, 9777406, … 9779748]</td><td>[9785923, 9786111, … 9785835]</td><td>[9785835]</td><td>505770366</td><td>[0, 0, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ i64     ┆ list[i64]         ┆ ---               ┆ ---              ┆ i64           ┆ list[i64]   │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 2326954 ┆ [0, 0, … 9774079] ┆ [6741781,         ┆ [9785076]        ┆ 103850774     ┆ [0, 1, … 0] │\n",
       "│         ┆                   ┆ 9785076, …        ┆                  ┆               ┆             │\n",
       "│         ┆                   ┆ 9484153]          ┆                  ┆               ┆             │\n",
       "│ 1297073 ┆ [9771242,         ┆ [9788898,         ┆ [9788823]        ┆ 361906390     ┆ [0, 1, … 0] │\n",
       "│         ┆ 9769917, …        ┆ 9788823, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9779648]          ┆ 9696697]          ┆                  ┆               ┆             │\n",
       "│ 1247845 ┆ [9775846,         ┆ [9785596,         ┆ [9786139]        ┆ 504765231     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9777296, …        ┆ 9786566, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9779427]          ┆ 9786378]          ┆                  ┆               ┆             │\n",
       "│ 1095253 ┆ [9773877,         ┆ [9781158,         ┆ [9781057]        ┆ 380153523     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9773877, …        ┆ 9780921, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9780195]          ┆ 9779225]          ┆                  ┆               ┆             │\n",
       "│ 971347  ┆ [9777475,         ┆ [9785923,         ┆ [9785835]        ┆ 505770366     ┆ [0, 0, … 1] │\n",
       "│         ┆ 9777406, …        ┆ 9786111, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9779748]          ┆ 9785835]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in df_train: 11289\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of users in df_train: {df_train['user_id'].n_unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr><tr><td>3012771</td><td>&quot;Morten Bruun fyret i Sønderjys…</td><td>&quot;FODBOLD: Morten Bruun fyret me…</td><td>2023-06-29 06:20:39</td><td>false</td><td>&quot;Kemien mellem spillerne i Supe…</td><td>2006-05-01 14:28:40</td><td>[3177953]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sport/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Kendt&quot;, … &quot;Ansættelsesforhold&quot;]</td><td>142</td><td>[196, 199]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8241</td><td>&quot;Negative&quot;</td></tr><tr><td>3023463</td><td>&quot;Luderne flytter på landet&quot;</td><td>&quot;I landets tyndest befolkede om…</td><td>2023-06-29 06:20:43</td><td>false</td><td>&quot;Det frække erhverv rykker på l…</td><td>2007-03-24 08:27:59</td><td>[3184029]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Erotik&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7053</td><td>&quot;Neutral&quot;</td></tr><tr><td>3032577</td><td>&quot;Cybersex: Hvornår er man utro?&quot;</td><td>&quot;En flirtende sms til den flott…</td><td>2023-06-29 06:20:46</td><td>false</td><td>&quot;De fleste af os mener, at et t…</td><td>2007-01-18 10:30:37</td><td>[3030463]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/sex_og…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Partnerskab&quot;]</td><td>565</td><td>[]</td><td>&quot;sex_og_samliv&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9307</td><td>&quot;Neutral&quot;</td></tr><tr><td>3033563</td><td>&quot;Kniven for struben-vært får se…</td><td>&quot;I aftenens udgave af &#x27;Med kniv…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fjerde program i T…</td><td>2007-03-27 10:22:08</td><td>[3005524, 3005525]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Livsstil&quot;, &quot;Underholdning&quot;, … &quot;Mad og drikke&quot;]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9371</td><td>&quot;Neutral&quot;</td></tr><tr><td>3034608</td><td>&quot;Willy Strube har begået selvmo…</td><td>&quot;Den tidligere SiD-chef tog sit…</td><td>2023-06-29 06:20:49</td><td>false</td><td>&quot;Den tidligere formand for Indu…</td><td>2001-10-19 12:30:00</td><td>[3204848]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/nyhede…</td><td>[&quot;Willy Strube&quot;, &quot;Willy Strube&quot;, &quot;Willy Strube&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Erhverv&quot;, … &quot;Offentlig instans&quot;]</td><td>118</td><td>[130]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9971</td><td>&quot;Negative&quot;</td></tr><tr><td>3034849</td><td>&quot;Venner for livet&quot;</td><td>&quot;VK-REGERINGEN&quot;</td><td>2023-06-29 06:20:50</td><td>false</td><td>&quot;VK-REGERINGEN\n",
       "håndplukkede Bjø…</td><td>2003-01-09 06:00:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/incomi…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>2</td><td>[]</td><td>&quot;incoming&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8454</td><td>&quot;Neutral&quot;</td></tr><tr><td>3035648</td><td>&quot;Dronning af escort-branchen&quot;</td><td>&quot;Trine Michelsen hjælper københ…</td><td>2023-06-29 06:20:52</td><td>false</td><td>&quot;En af escortbranchens største …</td><td>2003-06-17 07:10:00</td><td>[3082573]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Livsstil&quot;, … &quot;Erotik&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.8814</td><td>&quot;Neutral&quot;</td></tr><tr><td>3036444</td><td>&quot;Mia kendte sandsynligvis sin m…</td><td>&quot;Hun var ikke den type, der søg…</td><td>2023-06-29 06:20:54</td><td>false</td><td>&quot;Den 12-årige Mia Teglgaard Spr…</td><td>2003-07-13 19:50:00</td><td>null</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[&quot;Mia Teglgaard Sprotte&quot;, &quot;Erik Andersen&quot;, … &quot;Mia Teglgaard Sprotte&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
       "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
       "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
       "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9371    ┆ Neutral  │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ får se…   ┆ 'Med      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ kniv…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034608   ┆ Willy     ┆ Den       ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9971    ┆ Negative │\n",
       "│           ┆ Strube    ┆ tidligere ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ har       ┆ SiD-chef  ┆ 06:20:49  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ begået    ┆ tog sit…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ selvmo…   ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3034849   ┆ Venner    ┆ VK-REGERI ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8454    ┆ Neutral  │\n",
       "│           ┆ for livet ┆ NGEN      ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆           ┆ 06:20:50  ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3035648   ┆ Dronning  ┆ Trine     ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8814    ┆ Neutral  │\n",
       "│           ┆ af escort ┆ Michelsen ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ -branchen ┆ hjælper   ┆ 06:20:52  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ københ…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3036444   ┆ Mia       ┆ Hun var   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ kendte    ┆ ikke den  ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ sandsynli ┆ type, der ┆ 06:20:54  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gvis sin  ┆ søg…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ m…        ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "DataFrame after tokenization:\n",
      "shape: (20_738, 21)\n",
      "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
      "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
      "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
      "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
      "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
      "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
      "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
      "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3012771   ┆ Morten    ┆ FODBOLD:  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.8241    ┆ Negative │\n",
      "│           ┆ Bruun     ┆ Morten    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ fyret i   ┆ Bruun     ┆ 06:20:39  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Sønderjys ┆ fyret me… ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ …         ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3023463   ┆ Luderne   ┆ I landets ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7053    ┆ Neutral  │\n",
      "│           ┆ flytter   ┆ tyndest   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ på landet ┆ befolkede ┆ 06:20:43  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ om…       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 3032577   ┆ Cybersex: ┆ En        ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9307    ┆ Neutral  │\n",
      "│           ┆ Hvornår   ┆ flirtende ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ er man    ┆ sms til   ┆ 06:20:46  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ utro?     ┆ den       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆           ┆ flott…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
      "│ 9803492   ┆ Vilde     ┆ Der er    ┆ 2023-06-2 ┆ … ┆ 100120    ┆ 4.112624e ┆ 0.6095    ┆ Neutral  │\n",
      "│           ┆ billeder: ┆ gang i    ┆ 9         ┆   ┆           ┆ 6         ┆           ┆          │\n",
      "│           ┆ Vulkan i  ┆ vulkanen  ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ udbru…    ┆ på Hawa…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803505   ┆ Flyvende  ┆ Verdens   ┆ 2023-06-2 ┆ … ┆ 959       ┆ 55691.0   ┆ 0.8884    ┆ Positive │\n",
      "│           ┆ Antonsen  ┆ nummer    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ knuser    ┆ syv, Chou ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ topsp…    ┆ Tien-…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803525   ┆ Dansk sku ┆ Julie R.  ┆ 2023-06-2 ┆ … ┆ 50361     ┆ 2.550671e ┆ 0.7737    ┆ Negative │\n",
      "│           ┆ espiller: ┆ Ølgaard   ┆ 9         ┆   ┆           ┆ 6         ┆           ┆          │\n",
      "│           ┆ - Jeg     ┆ fik akut  ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ nægte…    ┆ kejs…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803560   ┆ Så slemt  ┆ Tusindvis ┆ 2023-06-2 ┆ … ┆ 1237      ┆ 67514.0   ┆ 0.9927    ┆ Negative │\n",
      "│           ┆ er det:   ┆ af huse   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ 14.000    ┆ står      ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ huse e…   ┆ under v…  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "│ 9803607   ┆ Aktion    ┆ Flere     ┆ 2023-06-2 ┆ … ┆ 79590     ┆ 3.69476e6 ┆ 0.9948    ┆ Negative │\n",
      "│           ┆ mod svind ┆ kvinder   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ lere:     ┆ er ifølge ┆ 06:49:26  ┆   ┆           ┆           ┆           ┆          │\n",
      "│           ┆ Seks per… ┆ politi…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
      "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# LOAD HUGGINGFACE and move to device immediately:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME).to(device)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# # We'll init the word embeddings using the\n",
    "# word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "\n",
    "# # Concatenate text columns\n",
    "# df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "\n",
    "# # Get tokenized version\n",
    "# df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "#     df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    "# )\n",
    "\n",
    "print(\"DataFrame after tokenization:\")\n",
    "print(df_articles)\n",
    "\n",
    "# print(df_articles[token_col_title][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding tokenized article title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|██████████| 649/649 [01:29<00:00,  7.28text/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from utils._python import batch_items_generator\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "n_batches = int(np.ceil(df_articles.height / BATCH_SIZE))\n",
    "\n",
    "chunked_text_list = batch_items_generator(df_articles[DEFAULT_TITLE_COL].to_list(), BATCH_SIZE)\n",
    "embeddings = (\n",
    "    generate_embeddings_with_transformers(\n",
    "        model=transformer_model,\n",
    "        tokenizer=transformer_tokenizer,\n",
    "        text_list=text_list,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "    for text_list in tqdm(\n",
    "        chunked_text_list, desc=\"Encoding\", total=n_batches, unit=\"text\"\n",
    "    )\n",
    ")\n",
    "embeddings = torch.vstack(list(embeddings))\n",
    "# print(embeddings.shape)\n",
    "# embedded_title = f\"{DEFAULT_TITLE_COL}_embedded\"\n",
    "\n",
    "# df_articles = df_articles.with_columns(pl.Series(embedded_title, embeddings.to(\"cpu\").numpy()))\n",
    "\n",
    "# article_mapping = create_article_id_to_value_mapping(\n",
    "#     df=df_articles, value_col=embedded_title\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce dimensionality of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensionality Reduction to 24 dimensions:\n",
      "Explained variance ratio (PCA): 89.16%\n",
      "Shape after reduction: (20738, 24)\n",
      "\n",
      "Dimensionality Reduction to 32 dimensions:\n",
      "Explained variance ratio (PCA): 90.54%\n",
      "Shape after reduction: (20738, 32)\n",
      "\n",
      "Dimensionality Reduction to 64 dimensions:\n",
      "Explained variance ratio (PCA): 94.02%\n",
      "Shape after reduction: (20738, 64)\n",
      "\n",
      "Dimensionality Reduction to 128 dimensions:\n",
      "Explained variance ratio (PCA): 97.20%\n",
      "Shape after reduction: (20738, 128)\n",
      "\n",
      "Dimensionality Reduction to 256 dimensions:\n",
      "Explained variance ratio (PCA): 99.17%\n",
      "Shape after reduction: (20738, 256)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "def reduce_and_analyze_dimensionality(embeddings_array, target_dims=[24, 32, 64, 128, 256]):\n",
    "    \"\"\"\n",
    "    Reduce dimensionality using different methods and analyze information retention\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # PCA Analysis for different dimensions\n",
    "    for dim in target_dims:\n",
    "        # PCA\n",
    "        pca = PCA(n_components=dim)\n",
    "        reduced_data_pca = pca.fit_transform(embeddings_array)\n",
    "        \n",
    "        # Calculate explained variance ratio\n",
    "        explained_var = np.sum(pca.explained_variance_ratio_) * 100\n",
    "        \n",
    "        results[dim] = {\n",
    "            'method': 'PCA',\n",
    "            'explained_variance_ratio': explained_var,\n",
    "            'reduced_data': reduced_data_pca\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nDimensionality Reduction to {dim} dimensions:\")\n",
    "        print(f\"Explained variance ratio (PCA): {explained_var:.2f}%\")\n",
    "        print(f\"Shape after reduction: {reduced_data_pca.shape}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Convert embeddings to numpy array if it's not already\n",
    "embeddings_numpy = embeddings.cpu().numpy()\n",
    "\n",
    "# Analyze different dimensionality reductions\n",
    "reduction_results = reduce_and_analyze_dimensionality(embeddings_numpy)\n",
    "\n",
    "# Choose the dimension that provides good balance \n",
    "# between compression and information retention\n",
    "chosen_dim = hparams_nrms.__dict__['title_size']  # Adjust based on analysis results\n",
    "pca = PCA(n_components=chosen_dim)\n",
    "reduced_embeddings = pca.fit_transform(embeddings_numpy)\n",
    "\n",
    "# Update the dataframe with reduced embeddings\n",
    "embedded_title = f\"{DEFAULT_TITLE_COL}_embedded_reduced\"\n",
    "df_articles = df_articles.with_columns(pl.Series(embedded_title, reduced_embeddings))\n",
    "\n",
    "# Create new article mapping with reduced embeddings\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=embedded_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(46855, 6)\n",
      "Data preprocessing completed in 5.10 seconds.\n",
      "Starting preprocessing...\n",
      "Preprocessing data...\n",
      "(48659, 6)\n",
      "Data preprocessing completed in 5.80 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NRMSDataSet(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    ")\n",
    "val_dataset = NRMSDataSet(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(5):\n",
    "#     sample = train_dataset[idx]\n",
    "#     print(f\"Sample {idx}:\")\n",
    "#     print(f\"his_input_title shape: {sample[0][0].shape}\")\n",
    "#     print(f\"pred_input_title shape: {sample[0][1].shape} {sample[0][1].sum()}\")\n",
    "#     print(f\"Targets shape: {sample[1].shape} , {sample[1].dtype} {sample[1].sum()}\")\n",
    "#     print(f\"impression id: {sample[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "def collate_fn_with_global_padding(batch, max_len_pred, apply_padding_to_targets : bool = True):\n",
    "    try:\n",
    "        his_input_titles = [item[0][0] for item in batch]  # History inputs\n",
    "        pred_input_titles = [item[0][1] for item in batch]  # Prediction inputs\n",
    "        batch_ys = [item[1] for item in batch]  # Targets\n",
    "        impression_id = torch.tensor([item[2] for item in batch], dtype=torch.int64)  # Impression ID\n",
    "        \n",
    "\n",
    "        # Pad sequences to the global maximum length\n",
    "        his_input_titles_padded = pad_sequence(his_input_titles, batch_first=True, padding_value=0)\n",
    "\n",
    "        # Pad prediction inputs and adjust to the global maximum length\n",
    "        pred_input_titles_padded = pad_sequence(pred_input_titles, batch_first=True, padding_value=0)\n",
    "        if pred_input_titles_padded.size(1) < max_len_pred:\n",
    "            # Add padding if sequence length is shorter than max_len_pred\n",
    "            pad_size = max_len_pred - pred_input_titles_padded.size(1)\n",
    "            pred_input_titles_padded = torch.nn.functional.pad(\n",
    "                pred_input_titles_padded, (0, 0, 0, pad_size), value=0\n",
    "            )\n",
    "        elif pred_input_titles_padded.size(1) > max_len_pred:\n",
    "            # Trim if sequence length exceeds max_len_pred\n",
    "            pred_input_titles_padded = pred_input_titles_padded[:, :max_len_pred, :]\n",
    "\n",
    "        # Pad targets to the global maximum length\n",
    "        if apply_padding_to_targets:\n",
    "            batch_ys_padded = pad_sequence(batch_ys, batch_first=True, padding_value=-1)\n",
    "            if batch_ys_padded.size(1) < max_len_pred:\n",
    "                pad_size = max_len_pred - batch_ys_padded.size(1)\n",
    "                batch_ys_padded = torch.nn.functional.pad(batch_ys_padded, (0, pad_size), value=-1)\n",
    "            elif batch_ys_padded.size(1) > max_len_pred:\n",
    "                batch_ys_padded = batch_ys_padded[:, :max_len_pred]\n",
    "\n",
    "            return (his_input_titles_padded, pred_input_titles_padded), batch_ys_padded, impression_id\n",
    "        else:\n",
    "            return (his_input_titles_padded, pred_input_titles_padded), batch_ys, impression_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the dataset with DataLoader\n",
    "train_dataloader_temp = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,    # Set your desired batch size\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")\n",
    "\n",
    "val_dataloader_temp = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,    # Set your desired batch size\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=lambda batch: collate_fn_with_global_padding(batch, max_inview_length_validation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 88, 24])\n",
      "torch.Size([128, 88])\n",
      "tensor([103850774, 361906390, 504765231, 380153523, 505770366, 236127553,\n",
      "        264088776, 503851641, 277588950, 431707990, 206748854, 480970521,\n",
      "        433108575, 417023909, 434155625, 249531782,  68709150, 548545459,\n",
      "         82328837,  95001745, 185002768,  66799852, 277895986,  40417696,\n",
      "        178877236, 140277130,  68752397, 542476021, 313770718,  46625102,\n",
      "        124597273, 216799247, 262725017, 231228210,  97349427,  64544566,\n",
      "        502896866, 296970044, 324070599, 156570854, 101817158, 481932692,\n",
      "        541174342, 546028791, 449472828, 183255329, 258372090, 560573695,\n",
      "        261006641, 444823498, 122923561, 128429832, 136481598, 242117638,\n",
      "        161182818, 570510614, 469128962, 157211741, 531627930, 244404768,\n",
      "        220627964,  24462772, 291910731, 315534651, 433824447, 244314071,\n",
      "        245304027, 107864861, 201806681, 379553118,  72371477, 242082315,\n",
      "        130940226, 275936784, 282602500, 278434886, 395638147, 102487685,\n",
      "         76952353, 552939383, 467161115, 280015602, 228879603, 343275275,\n",
      "         39543098, 129042831, 194569529, 129156064, 328062389, 414234931,\n",
      "        394287350,  72266706, 253103862, 361261979, 493901470,  26250353,\n",
      "        504575685, 340205828, 354954627, 394937959, 427158070, 525773391,\n",
      "        253232882, 188636591, 337968596,  47908924, 300027675, 500987025,\n",
      "        427863538, 226379489, 357245533, 449876301, 100911337, 178383966,\n",
      "        315266375, 460471766, 128564873,  74497048, 487116963, 278400426,\n",
      "        139328904, 544956932, 504016343, 548820611, 454690116,  98435335,\n",
      "        150844799, 386312438])\n",
      "Batch loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "for batch in val_dataloader_temp:\n",
    "    (his_input_titles_padded, pred_input_titles_padded), batch_ys_padded, impression_id = batch\n",
    "    print(pred_input_titles_padded.shape)  # Look at one padded sequence\n",
    "    print(batch_ys_padded.shape)  # Look at one padded sequence\n",
    "    print(impression_id)\n",
    "\n",
    "    print(\"Batch loaded successfully!\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THIS CODE SHOULD ONLY RUN WHEN GENERATING THE DATA FOR THE FIRST TIME\n",
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Function to preprocess and save data\n",
    "# def preprocess_and_save(dataloader, filepath, device=\"cuda\"):\n",
    "#     all_inputs_his = []\n",
    "#     all_inputs_pred = []\n",
    "#     all_targets = []\n",
    "#     all_impression_ids = []\n",
    "\n",
    "#     # Iterate over DataLoader and collect data\n",
    "#     for (his_inputs, pred_inputs), targets, impressionID in tqdm(dataloader, desc=\"Processing Data\"):\n",
    "#         all_inputs_his.append(his_inputs)\n",
    "#         all_inputs_pred.append(pred_inputs)\n",
    "#         all_targets.append(targets)\n",
    "#         all_impression_ids.append(impressionID)\n",
    "\n",
    "#     # Concatenate all batches into a single tensor\n",
    "#     all_inputs_his = torch.cat(all_inputs_his).to(device)\n",
    "#     all_inputs_pred = torch.cat(all_inputs_pred).to(device)\n",
    "#     all_targets = torch.cat(all_targets).to(device)\n",
    "#     all_impression_ids = torch.cat(all_impression_ids).to(device)\n",
    "\n",
    "#     # Save the preprocessed data as a tuple\n",
    "#     torch.save((all_inputs_his, all_inputs_pred, all_targets, all_impression_ids), filepath)\n",
    "#     print(f\"Data saved to {filepath}\")\n",
    "\n",
    "# # Save train and validation data\n",
    "# preprocess_and_save(val_dataloader_temp, \"val_data_small_dataset_with_impression_ids.pt\", device=\"cuda\")\n",
    "\n",
    "# preprocess_and_save(train_dataloader_temp, \"train_data_small_dataset_with_impression_ids.pt\", device=\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_preprocessed_data(filepath, device=\"cuda\"):\n",
    "#     # Load the data from the .pt file\n",
    "#     data = torch.load(filepath)\n",
    "\n",
    "#     # Unpack the data\n",
    "#     his_inputs, pred_inputs, targets, impression_ids = data\n",
    "\n",
    "#     # Move the data to the specified device\n",
    "#     his_inputs = his_inputs.to(device, non_blocking=True)\n",
    "#     pred_inputs = pred_inputs.to(device, non_blocking=True)\n",
    "#     targets = targets.to(device, non_blocking=True)\n",
    "#     impression_ids = impression_ids.to(device, non_blocking=True)\n",
    "\n",
    "#     return his_inputs, pred_inputs, targets, impression_ids\n",
    "\n",
    "# # Example: Load train and validation data\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# train_his_inputs, train_pred_inputs, train_targets, impression_ids = load_preprocessed_data(\"train_data_small_dataset_with_impression_ids.pt\", device)\n",
    "# val_his_inputs, val_pred_inputs, val_targets, impression_ids = load_preprocessed_data(\"val_data_small_dataset_with_impression_ids.pt\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_batches(inputs, targets, impression_ids, batch_size):\n",
    "#     his_inputs, pred_inputs = inputs\n",
    "#     for i in range(0, his_inputs.size(0), batch_size):\n",
    "#         his_batch = his_inputs[i:i+batch_size]\n",
    "#         pred_batch = pred_inputs[i:i+batch_size]\n",
    "#         target_batch = targets[i:i+batch_size]\n",
    "#         impression_id_batch = impression_ids[i:i+batch_size]\n",
    "#         yield (his_batch, pred_batch), target_batch, impression_id_batch\n",
    "\n",
    "# # Set the batch size\n",
    "# batch_size = 64\n",
    "\n",
    "# # Example: Create batches for train and validation data\n",
    "# #train_batches = create_batches((train_his_inputs, train_pred_inputs), train_targets, batch_size)\n",
    "# #val_batches = create_batches((val_his_inputs, val_pred_inputs), val_targets, batch_size)\n",
    "\n",
    "# train_batches = list(create_batches((train_his_inputs, train_pred_inputs), train_targets, impression_ids, batch_size))\n",
    "# val_batches = list(create_batches((val_his_inputs, val_pred_inputs), val_targets, impression_ids, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (his_batch, pred_batch), target_batch, impression_ids_batch in train_batches:\n",
    "#     print(f\"his_batch device: {his_batch.device}\")\n",
    "#     print(f\"pred_batch device: {pred_batch.device}\")\n",
    "#     print(f\"target_batch device: {target_batch.device}\")\n",
    "#     print(f\"impression_ids_batch device: {impression_ids_batch.device}\")\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__module__': 'models_pytorch.model_config', '__annotations__': {'title_size': <class 'int'>, 'embedding_dim': <class 'int'>, 'word_emb_dim': <class 'int'>, 'vocab_size': <class 'int'>, 'head_num': <class 'int'>, 'head_dim': <class 'int'>, 'attention_hidden_dim': <class 'int'>, 'optimizer': <class 'str'>, 'loss': <class 'str'>, 'dropout': <class 'float'>, 'learning_rate': <class 'float'>, 'weight_decay': <class 'float'>, 'units_per_layer': list[int]}, 'title_size': 24, 'embedding_dim': 32, 'word_emb_dim': 8, 'vocab_size': 10000, 'head_num': 4, 'head_dim': 8, 'attention_hidden_dim': 50, 'hidden_dim': 32, 'optimizer': 'adam', 'loss': 'cross_entropy_loss', 'dropout': 0.2, 'learning_rate': 0.0001, 'weight_decay': 0.001, 'news_output_dim': 64, 'units_per_layer': [64, 64, 64], '__dict__': <attribute '__dict__' of 'hparams_nrms' objects>, '__weakref__': <attribute '__weakref__' of 'hparams_nrms' objects>, '__doc__': None}\n"
     ]
    }
   ],
   "source": [
    "# see the model parameters: \n",
    "print(hparams_nrms.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model device: mps:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavsiphone/Documents/GitHub/Deeplearning-RecSys-Challenge-2024/models_pytorch/nrms.py:142: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = amp.GradScaler()\n",
      "/Users/gustavsiphone/Documents/GitHub/Deeplearning-RecSys-Challenge-2024/.venv/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Define paths\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = os.path.join(\"downloads\", \"runs\", MODEL_NAME)\n",
    "MODEL_WEIGHTS = os.path.join(\"downloads\", \"data\", \"state_dict\", MODEL_NAME, \"weights.pth\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_WEIGHTS), exist_ok=True)\n",
    "\n",
    "# Define ModelCheckpoint class\n",
    "class ModelCheckpoint:\n",
    "    \"\"\"Saves the model after every epoch if it has the best performance so far.\"\"\"\n",
    "    def __init__(self, filepath, verbose=False, save_best_only=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            filepath (str): Path to save the model checkpoint.\n",
    "            verbose (bool): If True, prints a message when the model is saved.\n",
    "            save_best_only (bool): If True, saves only when the model is better than before.\n",
    "        \"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.best_loss = None\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.filepath)\n",
    "        if self.verbose:\n",
    "            print(f\"Model saved to {self.filepath}\")\n",
    "\n",
    "# Define EarlyStopping class\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve by a given percentage over a patience period.\"\"\"\n",
    "    def __init__(self, patience=3, min_delta=0.05, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): Number of epochs to wait after last time validation loss improved by min_delta.\n",
    "            min_delta (float): Minimum percentage improvement required to reset patience.\n",
    "            verbose (bool): If True, prints a message when early stopping is triggered.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta  # Minimum percentage improvement\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            # Initialize best_loss with the first validation loss\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        elif val_loss < self.best_loss * (1 - self.min_delta):\n",
    "            # Significant improvement found\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved by at least {self.min_delta*100:.1f}%\")\n",
    "        else:\n",
    "            # No significant improvement\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"No significant improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "\n",
    "# Initialize callbacks\n",
    "model_checkpoint = ModelCheckpoint(filepath=MODEL_WEIGHTS, verbose=True, save_best_only=True)\n",
    "# Initialize EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "\n",
    "# Initialize your model\n",
    "# Ensure that NRMSModel is a PyTorch nn.Module\n",
    "\n",
    "# CUDA checks\n",
    "#print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "#print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "#print(f\"Device Name: {torch.cuda.get_device_name()}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize model\n",
    "# model = NRMSModel(\n",
    "#     hparams=hparams_nrms.__dict__,\n",
    "#     word2vec_embedding=word2vec_embedding,\n",
    "#     vocab_size=1000,\n",
    "#     word_emb_dim=8,\n",
    "#     seed=seed,\n",
    "#     device=device\n",
    "# )\n",
    "\n",
    "# model = NRMSDocVecModel(hparams=hparams_nrms.__dict__,\n",
    "#                         device=device)\n",
    "\n",
    "model = NRMSModel(hparams=hparams_nrms.__dict__,\n",
    "                        device=device)\n",
    "print(f\"Model device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_prediction_details(outputs, targets, k=5):\n",
    "#     \"\"\"Print detailed prediction information for the first k samples\"\"\"\n",
    "#     # Get predicted class (highest score)\n",
    "#     _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "#     # Calculate accuracy for this batch\n",
    "#     correct = (predicted == targets).sum().item()\n",
    "#     total = targets.size(0)\n",
    "#     accuracy = 100 * correct / total\n",
    "    \n",
    "#     # Print details for k samples\n",
    "#     for i in range(min(k, len(targets))):\n",
    "#         print(f\"\\nSample {i}:\")\n",
    "#         print(f\"Predicted probabilities: {torch.softmax(outputs[i], dim=0)}\")\n",
    "#         print(f\"Predicted class: {predicted[i]}, True class: {targets[i]}\")\n",
    "#         print(f\"Correct: {predicted[i] == targets[i]}\")\n",
    "    \n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSModel(\n",
      "  (newsencoder): NewsEncoder(\n",
      "    (self_attention): SelfAttention()\n",
      "    (attention_layer): AttLayer2(\n",
      "      (q): Linear(in_features=50, out_features=1, bias=False)\n",
      "    )\n",
      "    (fc1): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (fc2): Linear(in_features=50, out_features=64, bias=True)\n",
      "  )\n",
      "  (userencoder): UserEncoder(\n",
      "    (titleencoder): NewsEncoder(\n",
      "      (self_attention): SelfAttention()\n",
      "      (attention_layer): AttLayer2(\n",
      "        (q): Linear(in_features=50, out_features=1, bias=False)\n",
      "      )\n",
      "      (fc1): Linear(in_features=50, out_features=50, bias=True)\n",
      "      (relu): ReLU()\n",
      "      (fc2): Linear(in_features=50, out_features=64, bias=True)\n",
      "    )\n",
      "    (self_attention): SelfAttention()\n",
      "    (attention_layer): AttLayer2(\n",
      "      (q): Linear(in_features=64, out_features=1, bias=False)\n",
      "    )\n",
      "    (user_projection): Linear(in_features=64, out_features=64, bias=True)\n",
      "  )\n",
      ")\n",
      "Layer: newsencoder.attention_layer.b | Size: torch.Size([50])\n",
      "Layer: newsencoder.attention_layer.q.weight | Size: torch.Size([1, 50])\n",
      "Layer: newsencoder.fc1.weight | Size: torch.Size([50, 50])\n",
      "Layer: newsencoder.fc1.bias | Size: torch.Size([50])\n",
      "Layer: newsencoder.fc2.weight | Size: torch.Size([64, 50])\n",
      "Layer: newsencoder.fc2.bias | Size: torch.Size([64])\n",
      "Layer: userencoder.attention_layer.b | Size: torch.Size([64])\n",
      "Layer: userencoder.attention_layer.q.weight | Size: torch.Size([1, 64])\n",
      "Layer: userencoder.user_projection.weight | Size: torch.Size([64, 64])\n",
      "Layer: userencoder.user_projection.bias | Size: torch.Size([64])\n",
      "\n",
      "Total parameters: 10,202\n"
     ]
    }
   ],
   "source": [
    "# 1. Print model architecture\n",
    "print(model)\n",
    "\n",
    "# 2. Print specific layer sizes\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()}\")\n",
    "\n",
    "# 3. Get total number of parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "\n",
    "# 4. Print layer by layer with shapes\n",
    "def print_model_structure(model):\n",
    "    print(\"\\nDetailed Model Structure:\")\n",
    "    for name, module in model.named_children():\n",
    "        print(f\"\\nLayer: {name}\")\n",
    "        print(f\"Type: {type(module).__name__}\")\n",
    "        if hasattr(module, 'weight'):\n",
    "            print(f\"Shape: {module.weight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"Layer: {name} | Size: {param.size()} | Parameters: {param.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_GRAD_NORM = np.sqrt(sum(p.numel() for p in model.parameters()))\n",
    "# print(f\"Max grad norm: {MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\n",
    "Added gradient clipping to avoid exploiding gradients. The paramter MAX_GRAD_NORM is set to 5.0 as this is a common value used in transformers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # Variables to track counts\n",
    "# total_inputs = 0\n",
    "# total_targets = 0\n",
    "\n",
    "# # Iterate over the DataLoader\n",
    "# for batch_idx, (inputs, targets, impression_ids) in enumerate(train_dataloader_temp):\n",
    "#     # Move data to GPU\n",
    "#     inputs = [inp.to(device) for inp in inputs]\n",
    "#     targets = targets.to(device)\n",
    "#     impression_ids = impression_ids.to(device)\n",
    "    \n",
    "#     # Print information for the first few batches to avoid delays\n",
    "#     if batch_idx < 5:  # Adjust the number of batches to print as needed\n",
    "#         print(f\"Batch {batch_idx + 1} (on {device}):\")\n",
    "#         print(f\"  - Number of inputs: {len(inputs[0])}\")  # History input\n",
    "#         print(f\"  - Number of targets: {len(targets)}\")   # Target labels\n",
    "#         print(f\"  - Impression IDs: {len(impression_ids)}\")\n",
    "    \n",
    "#     # Update total counts\n",
    "#     total_inputs += len(inputs[0])\n",
    "#     total_targets += len(targets)\n",
    "\n",
    "# # Final counts after iteration\n",
    "# print(f\"\\nTotal number of inputs in train_dataloader_temp: {total_inputs}\")\n",
    "# print(f\"Total number of targets in train_dataloader_temp: {total_targets}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperoptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_EPOCHS = 30\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Define hyperparameter search space\n",
    "#     hparams = {\n",
    "#         'title_size': 768,\n",
    "#         'history_size': trial.suggest_int('history_size', 5, 20),\n",
    "#         'head_num': trial.suggest_int('head_num', 2, 8),\n",
    "#         'head_dim': trial.suggest_int('head_dim', 4, 16),\n",
    "#         'attention_hidden_dim': trial.suggest_int('attention_hidden_dim', 32, 128),\n",
    "#         'dropout': trial.suggest_float('dropout', 0.1, 0.5),\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n",
    "#         'news_output_dim': trial.suggest_int('news_output_dim', 32, 128),\n",
    "#         'units_per_layer': [trial.suggest_int(f'unit_layer_{i}', 32, 128) for i in range(3)]\n",
    "#     }\n",
    "\n",
    "#     # Initialize model and training components\n",
    "#     model = NRMSDocVecModel(hparams=hparams, device=device)\n",
    "#     criterion = model.get_loss().to(device)\n",
    "#     optimizer = optim.Adam(model.parameters(), \n",
    "#                           lr=hparams['learning_rate'], \n",
    "#                           weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "#     # Initialize EarlyStopping\n",
    "#     early_stopping = EarlyStopping(patience=3, min_delta=0.05, verbose=True)\n",
    "#     best_val_loss = float('inf')\n",
    "\n",
    "#     for epoch in range(NUM_EPOCHS):\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         train_loss = train_one_epoch(model, train_dataloader_temp, optimizer, criterion)\n",
    "        \n",
    "#         # Validation phase\n",
    "#         val_loss = validate(model, val_dataloader_temp, criterion)\n",
    "        \n",
    "#         # Update best validation loss\n",
    "#         if val_loss < best_val_loss:\n",
    "#             best_val_loss = val_loss\n",
    "\n",
    "#         # Early stopping check\n",
    "#         early_stopping(val_loss)\n",
    "#         if early_stopping.early_stop:\n",
    "#             print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "#             break\n",
    "\n",
    "#         # Report to Optuna\n",
    "#         trial.report(val_loss, epoch)\n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "\n",
    "#     return best_val_loss\n",
    "\n",
    "# def train_one_epoch(model, dataloader, optimizer, criterion):\n",
    "#     running_loss = 0.0\n",
    "#     batch_count = 0\n",
    "    \n",
    "#     for inputs, targets, impression_ids in dataloader:\n",
    "#         inputs = [inp.to(device) for inp in inputs]\n",
    "#         targets = targets.to(device)\n",
    "#         positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#         targets = positive_indices[:, 1].long()\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(*inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#         batch_count += 1\n",
    "    \n",
    "#     return running_loss / batch_count\n",
    "\n",
    "# def validate(model, dataloader, criterion):\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     batch_count = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for inputs, targets, impression_ids in dataloader:\n",
    "#             inputs = [inp.to(device) for inp in inputs]\n",
    "#             targets = targets.to(device)\n",
    "#             positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "#             targets = positive_indices[:, 1].long()\n",
    "#             outputs = model(*inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             val_loss += loss.item()\n",
    "#             batch_count += 1\n",
    "    \n",
    "#     return val_loss / batch_count\n",
    "\n",
    "# # Create study and optimize\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=3)  # Run 50 trials\n",
    "\n",
    "# # Print results\n",
    "# print(\"Best trial:\")\n",
    "# trial = study.best_trial\n",
    "\n",
    "# print(\"  Value: \", trial.value)\n",
    "# print(\"  Params: \")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/30 [00:00<?, ?it/s]/var/folders/by/z4t2j23n5qb8_7scg2s_mjg00000gn/T/ipykernel_71241/1070524649.py:24: UserWarning: MPS: nonzero op is supported natively starting from macOS 14.0. Falling back on CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Indexing.mm:361.)\n",
      "  positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
      "/Users/gustavsiphone/Documents/GitHub/Deeplearning-RecSys-Challenge-2024/models_pytorch/nrms.py:159: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/Users/gustavsiphone/Documents/GitHub/Deeplearning-RecSys-Challenge-2024/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Training Progress:   7%|▋         | 2/30 [03:50<1:01:38, 132.08s/it, train_loss=2.3682, val_loss=2.6805]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved by at least 5.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 3/30 [04:11<36:38, 81.43s/it, train_loss=1.9844, val_loss=2.5315]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved by at least 5.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  13%|█▎        | 4/30 [04:31<24:43, 57.06s/it, train_loss=1.8848, val_loss=2.4958]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  17%|█▋        | 5/30 [04:51<18:11, 43.68s/it, train_loss=1.8371, val_loss=2.5326]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  17%|█▋        | 5/30 [05:11<25:56, 62.25s/it, train_loss=1.8073, val_loss=2.4682]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No significant improvement in validation loss. Counter: 3/3\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = model.get_loss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=hparams_nrms.__dict__['learning_rate'], weight_decay=hparams_nrms.__dict__['weight_decay'])\n",
    "\n",
    "# Training parameters\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Epoch progress bar\n",
    "epoch_pbar = tqdm(range(1, NUM_EPOCHS + 1), desc=\"Training Progress\", dynamic_ncols=True)\n",
    "for epoch in epoch_pbar:\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_batch_count = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets, impression_ids) in enumerate(train_dataloader_temp):\n",
    "        # Prepare data\n",
    "        inputs = [inp.to(device) for inp in inputs]\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Get positive labels\n",
    "        positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "        targets = positive_indices[:, 1].long()\n",
    "\n",
    "        # Forward and backward passes\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(*inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running statistics\n",
    "        running_loss += loss.item()\n",
    "        train_batch_count += 1\n",
    "\n",
    "    # Compute average training loss\n",
    "    avg_train_loss = running_loss / train_batch_count if train_batch_count > 0 else float('inf')\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_batch_count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, impression_ids in val_dataloader_temp:\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            targets = targets.to(device)\n",
    "            positive_indices = (targets == 1).nonzero(as_tuple=False)\n",
    "            targets = positive_indices[:, 1].long()\n",
    "            outputs = model(*inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_batch_count += 1\n",
    "\n",
    "    avg_val_loss = val_loss / val_batch_count if val_batch_count > 0 else float('inf')\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Update tensorboard\n",
    "    writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "\n",
    "    # Update epoch progress bar with metrics\n",
    "    epoch_pbar.set_postfix({\n",
    "        'train_loss': f'{avg_train_loss:.4f}',\n",
    "        'val_loss': f'{avg_val_loss:.4f}',\n",
    "    })\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        model_checkpoint(model, avg_val_loss)\n",
    "\n",
    "    # Check early stopping condition\n",
    "    early_stopping(avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break  # Exit the training loop\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Summary:\n",
      "Initial Training Loss: 3.4879\n",
      "Final Training Loss: 1.8073\n",
      "Best Training Loss: 1.8073\n",
      "\n",
      "Initial Validation Loss: 3.2091\n",
      "Final Validation Loss: 2.4682\n",
      "Best Validation Loss: 2.4682\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print final statistics\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(f\"Initial Training Loss: {train_losses[0]:.4f}\")\n",
    "print(f\"Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"Best Training Loss: {min(train_losses):.4f}\")\n",
    "print(f\"\\nInitial Validation Loss: {val_losses[0]:.4f}\")\n",
    "print(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "print(f\"Best Validation Loss: {min(val_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating DataLoader...\n",
      "Total samples in DataLoader: 48659\n",
      "\n",
      "First batch shapes:\n",
      "  - his_input_title: torch.Size([128, 40, 24])\n",
      "  - pred_input_title: torch.Size([128, 88, 24])\n",
      "  - targets: torch.Size([128, 88])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavsiphone/Documents/GitHub/Deeplearning-RecSys-Challenge-2024/models_pytorch/nrms.py:159: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/Users/gustavsiphone/Documents/GitHub/Deeplearning-RecSys-Challenge-2024/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed.\n",
      "Total predictions generated: 48659\n",
      "First few prediction lengths: [6, 6, 5, 8, 8, 18, 8, 5, 5, 11, 23, 5, 6, 10, 7]\n",
      "\n",
      "Validation against DataFrame:\n",
      "\n",
      "Metrics: {'auc': 0.5, 'mrr': 0.3116388486443017, 'ndcg@5': 0.34370753589904296, 'ndcg@10': 0.4284414072471252}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"Evaluate the model and return predictions and labels for metric calculation.\"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    print(\"\\nEvaluating DataLoader...\")\n",
    "    total_samples = len(dataloader.dataset)\n",
    "    print(f\"Total samples in DataLoader: {total_samples}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets, impression_ids) in enumerate(dataloader):\n",
    "            his_input_title, pred_input_title = inputs\n",
    "\n",
    "            if batch_idx == 0:  # Debug first batch shapes\n",
    "                print(\"\\nFirst batch shapes:\")\n",
    "                print(f\"  - his_input_title: {his_input_title.shape}\")\n",
    "                print(f\"  - pred_input_title: {pred_input_title.shape}\")\n",
    "                print(f\"  - targets: {targets.shape}\")\n",
    "\n",
    "            # Move data to device\n",
    "            his_input_title = his_input_title.to(device)\n",
    "            pred_input_title = pred_input_title.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            predictions = model.predict(his_input_title, pred_input_title)\n",
    "            predictions = predictions.cpu().numpy()\n",
    "            targets = targets.cpu().numpy()\n",
    "\n",
    "            # Process each sample in the batch\n",
    "            batch_size = predictions.shape[0]\n",
    "            for sample_idx in range(batch_size):\n",
    "                pred = predictions[sample_idx]\n",
    "                label = targets[sample_idx]\n",
    "\n",
    "                # Create valid_mask where label is not equal to the padding value (-1)\n",
    "                valid_mask = (label != -1)\n",
    "                sample_preds = pred[valid_mask]\n",
    "                sample_labels = label[valid_mask]\n",
    "\n",
    "                if len(sample_labels) == 0:\n",
    "                    continue  # Skip empty samples\n",
    "\n",
    "                # Ensure that there is at least one positive and one negative label\n",
    "                if len(np.unique(sample_labels)) < 2:\n",
    "                    continue  # Skip samples with only one class\n",
    "\n",
    "                all_predictions.append(sample_preds.tolist())\n",
    "                all_labels.append(sample_labels.tolist())\n",
    "\n",
    "    print(\"\\nEvaluation completed.\")\n",
    "    print(f\"Total predictions generated: {len(all_predictions)}\")\n",
    "    print(f\"First few prediction lengths: {[len(x) for x in all_predictions[:15]]}\")\n",
    "    return all_labels, all_predictions\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "labels_list, scores_list = evaluate_model(model, val_dataloader_temp, device)\n",
    "\n",
    "# Validate predictions against the DataFrame\n",
    "print(\"\\nValidation against DataFrame:\")\n",
    "if len(scores_list) != len(df_validation):\n",
    "    print(\"WARNING: Length mismatch!\")\n",
    "    print(f\"  - Number of predictions: {len(scores_list)}\")\n",
    "    print(f\"  - Number of rows in DataFrame: {len(df_validation)}\")\n",
    "\n",
    "# Compute metrics\n",
    "metrics = MetricEvaluator(\n",
    "    labels=labels_list,\n",
    "    predictions=scores_list,\n",
    "    metric_functions=[\n",
    "        AucScore(),\n",
    "        MrrScore(),\n",
    "        NdcgScore(k=5),\n",
    "        NdcgScore(k=10)\n",
    "    ],\n",
    ")\n",
    "results = metrics.evaluate()\n",
    "print(\"\\nMetrics:\", results.evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRACTION: 0.2, HISTORY_SIZE: 40\n",
      "Hyperparameters:\n",
      "title_size: 24\n",
      "embedding_dim: 32\n",
      "word_emb_dim: 8\n",
      "vocab_size: 10000\n",
      "head_num: 4\n",
      "head_dim: 8\n",
      "attention_hidden_dim: 50\n",
      "hidden_dim: 32\n",
      "optimizer: adam\n",
      "loss: cross_entropy_loss\n",
      "dropout: 0.2\n",
      "learning_rate: 0.0001\n",
      "weight_decay: 0.001\n",
      "news_output_dim: 64\n",
      "units_per_layer: [64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "print(f\"FRACTION: {FRACTION}, HISTORY_SIZE: {HISTORY_SIZE}\")\n",
    "\n",
    "# Filter out special Python attributes and print parameters\n",
    "params = {k: v for k, v in hparams_nrms.__dict__.items() if not k.startswith('__')}\n",
    "print(\"Hyperparameters:\")\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_of_labels(df: pl.DataFrame, impression_id: int) -> int:\n",
    "    # Filter for matching impression_id\n",
    "    filtered = df.filter(pl.col('impression_id') == impression_id)\n",
    "    \n",
    "    if filtered.height == 0:\n",
    "        raise ValueError(f\"No row found for impression_id {impression_id}\")\n",
    "    \n",
    "    # Get labels from first row\n",
    "    labels = filtered.select('labels').row(0)[0]\n",
    "    \n",
    "    return len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_length_of_labels(df_validation, 349992000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: [0, 1, 0, 0, 0, 0]\n",
      "Label 1: [0, 1, 0, 0, 0, 0]\n",
      "Label 2: [0, 0, 1, 0, 0]\n",
      "Label 3: [0, 0, 0, 0, 1, 0, 0, 0]\n",
      "Label 4: [0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Get first 5 labels\n",
    "first_5_labels = df_validation.select('labels').head(5)\n",
    "\n",
    "# Print each label with index\n",
    "for i, row in enumerate(first_5_labels.iter_rows()):\n",
    "    print(f\"Label {i}: {row[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavsiphone/Documents/GitHub/Deeplearning-RecSys-Challenge-2024/models_pytorch/nrms.py:159: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/Users/gustavsiphone/Documents/GitHub/Deeplearning-RecSys-Challenge-2024/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples with only one class\n",
      "Remaining valid samples: 48659\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Initialize lists\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "skipped_samples = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (his_input_title, pred_input_title), targets, impression_ids in val_dataloader_temp:\n",
    "        # Move to device\n",
    "        his_input_title = his_input_title.to(device)\n",
    "        pred_input_title = pred_input_title.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = model.predict(his_input_title, pred_input_title)\n",
    "        \n",
    "        \n",
    "        # Convert to probabilities if needed\n",
    "        if not torch.is_floating_point(predictions):\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Convert to lists while preserving structure\n",
    "        batch_preds = predictions.cpu().numpy().tolist()\n",
    "        batch_labels = targets.cpu().numpy().tolist()\n",
    "        impression_ids = impression_ids.cpu().numpy().tolist()\n",
    "        \n",
    "        batch_preds_without_padding = []\n",
    "        batch_labels_without_padding = []\n",
    "        \n",
    "        for pred_sample, label_sample, impression_id_sample in zip(batch_preds, batch_labels, impression_ids):\n",
    "            # Remove padding\n",
    "            actual_length = get_length_of_labels(df_validation, impression_id_sample)\n",
    "            pred_sample = pred_sample[:actual_length]\n",
    "            \n",
    "            # Check if sample has both classes before adding\n",
    "            if 1 in label_sample[:actual_length] and 0 in label_sample[:actual_length]:\n",
    "                batch_preds_without_padding.append(pred_sample)\n",
    "                batch_labels_without_padding.append(label_sample[:actual_length])\n",
    "            else:\n",
    "                skipped_samples += 1\n",
    "        \n",
    "        # Add batch predictions and labels\n",
    "        all_predictions.extend(batch_preds_without_padding)\n",
    "        all_labels.extend(batch_labels_without_padding)\n",
    "print(f\"Skipped {skipped_samples} samples with only one class\")\n",
    "print(f\"Remaining valid samples: {len(all_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample 0:\n",
      "Labels length:      6\n",
      "Predictions length: 6\n",
      "Num positives: 1.0\n",
      "Num negatives: 5.0\n",
      "Label distribution: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 1:\n",
      "Labels length:      6\n",
      "Predictions length: 6\n",
      "Num positives: 1.0\n",
      "Num negatives: 5.0\n",
      "Label distribution: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 2:\n",
      "Labels length:      5\n",
      "Predictions length: 5\n",
      "Num positives: 1.0\n",
      "Num negatives: 4.0\n",
      "Label distribution: [0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "\n",
      "Sample 3:\n",
      "Labels length:      8\n",
      "Predictions length: 8\n",
      "Num positives: 1.0\n",
      "Num negatives: 7.0\n",
      "Label distribution: [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Sample 4:\n",
      "Labels length:      8\n",
      "Predictions length: 8\n",
      "Num positives: 1.0\n",
      "Num negatives: 7.0\n",
      "Label distribution: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Debug: Print label distribution for first 5 samples\n",
    "for i, (preds, labels) in enumerate(zip(all_predictions[:5], all_labels[:5])):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"Labels length:      {len(labels)}\")\n",
    "    print(f\"Predictions length: {len(preds)}\")\n",
    "    print(f\"Num positives: {sum(labels)}\")\n",
    "    print(f\"Num negatives: {len(labels) - sum(labels)}\")\n",
    "    print(f\"Label distribution: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "Number of predictions: 48659\n",
      "example prediction: [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]]\n",
      "Number of labels: 48659\n",
      "example label: [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "print(type(all_predictions))\n",
    "print(type(all_labels))\n",
    "\n",
    "print(f\"Number of predictions: {len(all_predictions)}\")\n",
    "print(f\"example prediction: {all_predictions[0:2]}\")\n",
    "print(f\"Number of labels: {len(all_labels)}\")\n",
    "print(f\"example label: {all_labels[0:2]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1180\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "correct_predictions = 0\n",
    "total_samples = len(all_predictions)\n",
    "\n",
    "# Iterate over samples\n",
    "for idx, _ in enumerate(all_predictions):\n",
    "    # print(f\"Sample {idx}: Prediction: {all_predictions[idx]}\")\n",
    "    # print(f\"Sample {idx}: Label:      {all_labels[idx]}\")\n",
    "    \n",
    "    # Extract index of maximum value in predictions and labels\n",
    "    pred_max_index = np.argmax(all_predictions[idx])\n",
    "    label_max_index = np.argmax(all_labels[idx])\n",
    "    \n",
    "    # Compare indices to determine if the prediction was correct\n",
    "    if pred_max_index == label_max_index:\n",
    "        # print(f\"Sample {idx}: Prediction was correct.\")\n",
    "        correct_predictions += 1\n",
    "  #  else:\n",
    "        # print(f\"Sample {idx}: Prediction was wrong.\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean AUC: 0.5000\n",
      "Number of valid AUC calculations: 48659\n"
     ]
    }
   ],
   "source": [
    "from evaluation import AucScore\n",
    "\n",
    "# auc_score = AucScore()\n",
    "\n",
    "# auc_score.calculate(all_predictions, all_labels)\n",
    "# print(f\"AUC: {auc_score.score}\")\n",
    "# # Calculate AUC per sample\n",
    "aucs = []\n",
    "for preds, labels in zip(all_predictions, all_labels):\n",
    "    try:\n",
    "        # Only calculate if we have both positive and negative samples\n",
    "        if sum(labels) > 0 and sum(labels) < len(labels):\n",
    "            auc = roc_auc_score(labels, preds)\n",
    "            aucs.append(auc)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Only one class present in labels. Cannot calculate AUC.\")\n",
    "\n",
    "print(f\"\\nMean AUC: {np.mean(aucs):.4f}\")\n",
    "print(f\"Number of valid AUC calculations: {len(aucs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
