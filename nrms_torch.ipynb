{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.12\n",
      "PyTorch version: 2.4.1+cu124\n",
      "CUDA available: True\n",
      "Current GPU device: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from evaluation import MetricEvaluator, AucScore, NdcgScore, MrrScore\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "\n",
    "from utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL,\n",
    "    DEFAULT_USER_COL,\n",
    ")\n",
    "\n",
    "from utils._behaviors import (\n",
    "    create_binary_labels_column,\n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history,\n",
    ")\n",
    "from utils._articles import convert_text2encoding_with_transformers\n",
    "from utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from utils._articles import create_article_id_to_value_mapping\n",
    "from utils._nlp import get_transformers_word_embeddings\n",
    "from utils._python import write_submission_file, rank_predictions_by_score\n",
    "\n",
    "from models_pytorch.model_config import hparams_nrms\n",
    "from models_pytorch.nrms import NRMSModel\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch version\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at behaviours and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behaviors columns: Index(['impression_id', 'article_id', 'impression_time', 'read_time',\n",
      "       'scroll_percentage', 'device_type', 'article_ids_inview',\n",
      "       'article_ids_clicked', 'user_id', 'is_sso_user', 'gender', 'postcode',\n",
      "       'age', 'is_subscriber', 'session_id', 'next_read_time',\n",
      "       'next_scroll_percentage'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Let's first check the data structure\n",
    "behaviors_path = Path(\"ebnerd_demo/train/behaviors.parquet\")\n",
    "df = pd.read_parquet(behaviors_path)\n",
    "print(\"Behaviors columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "History file columns: Index(['user_id', 'impression_time_fixed', 'scroll_percentage_fixed',\n",
      "       'article_id_fixed', 'read_time_fixed'],\n",
      "      dtype='object')\n",
      "\n",
      "First row of history: user_id                                                                13538\n",
      "impression_time_fixed      [2023-04-27T10:17:43.000000, 2023-04-27T10:18:...\n",
      "scroll_percentage_fixed    [100.0, 35.0, 100.0, 24.0, 100.0, 23.0, 100.0,...\n",
      "article_id_fixed           [9738663, 9738569, 9738663, 9738490, 9738663, ...\n",
      "read_time_fixed            [17.0, 12.0, 4.0, 5.0, 4.0, 9.0, 5.0, 46.0, 11...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Debug print for history file structure\n",
    "history_df = pd.read_parquet(\"ebnerd_demo/train/history.parquet\")\n",
    "print(\"\\nHistory file columns:\", history_df.columns)\n",
    "print(\"\\nFirst row of history:\", history_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ebnerd_demo\n"
     ]
    }
   ],
   "source": [
    "PATH = Path(\"./ebnerd_demo\")  # Base path for your data directory\n",
    "print(PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/miki/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>impression_id</th><th>labels</th></tr><tr><td>u32</td><td>list[i32]</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>list[i8]</td></tr></thead><tbody><tr><td>2386777</td><td>[9760735, 9761569, … 9766560]</td><td>[9774823, 9774823, … 9772957]</td><td>[9774708]</td><td>95268651</td><td>[0, 0, … 0]</td></tr><tr><td>1146933</td><td>[9742173, 9770491, … 9767697]</td><td>[9762122, 9769504, … 9773045]</td><td>[9772882]</td><td>289779601</td><td>[0, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌─────────┬───────────────────┬───────────────────┬──────────────────┬───────────────┬─────────────┐\n",
       "│ user_id ┆ article_id_fixed  ┆ article_ids_invie ┆ article_ids_clic ┆ impression_id ┆ labels      │\n",
       "│ ---     ┆ ---               ┆ w                 ┆ ked              ┆ ---           ┆ ---         │\n",
       "│ u32     ┆ list[i32]         ┆ ---               ┆ ---              ┆ u32           ┆ list[i8]    │\n",
       "│         ┆                   ┆ list[i64]         ┆ list[i64]        ┆               ┆             │\n",
       "╞═════════╪═══════════════════╪═══════════════════╪══════════════════╪═══════════════╪═════════════╡\n",
       "│ 2386777 ┆ [9760735,         ┆ [9774823,         ┆ [9774708]        ┆ 95268651      ┆ [0, 0, … 0] │\n",
       "│         ┆ 9761569, …        ┆ 9774823, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9766560]          ┆ 9772957]          ┆                  ┆               ┆             │\n",
       "│ 1146933 ┆ [9742173,         ┆ [9762122,         ┆ [9772882]        ┆ 289779601     ┆ [0, 0, … 0] │\n",
       "│         ┆ 9770491, …        ┆ 9769504, …        ┆                  ┆               ┆             │\n",
       "│         ┆ 9767697]          ┆ 9773045]          ┆                  ┆               ┆             │\n",
       "└─────────┴───────────────────┴───────────────────┴──────────────────┴───────────────┴─────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ebnerd_from_path(path: Path, history_size: int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function\n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "            enable_warning=False,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes,\n",
    "            df2=df_history.collect(),\n",
    "            on=DEFAULT_USER_COL,\n",
    "            how=\"left\",\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors\n",
    "\n",
    "# Get the current working directory\n",
    "CURRENT_DIR = Path.cwd()\n",
    "print(\"Current directory:\", CURRENT_DIR)\n",
    "\n",
    "# Set the path directly to ebnerd_small in your project\n",
    "PATH = CURRENT_DIR / \"ebnerd_small\"\n",
    "\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "]\n",
    "HISTORY_SIZE = 10\n",
    "FRACTION = 0.01\n",
    "\n",
    "df_train = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(\n",
    "        sampling_strategy_wu2019,\n",
    "        npratio=4,\n",
    "        shuffle=True,\n",
    "        with_replacement=True,\n",
    "        seed=123,\n",
    "    )\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "df_validation = (\n",
    "    ebnerd_from_path(PATH.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(fraction=FRACTION)\n",
    ")\n",
    "\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miki/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = NRMSDataLoader(\n",
    "#     behaviors=df_train,\n",
    "#     article_dict=article_mapping,\n",
    "#     unknown_representation=\"zeros\",\n",
    "#     history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#     eval_mode=False,\n",
    "#     batch_size=64,\n",
    "# )\n",
    "# val_dataloader = NRMSDataLoader(\n",
    "#     behaviors=df_validation,\n",
    "#     article_dict=article_mapping,\n",
    "#     unknown_representation=\"zeros\",\n",
    "#     history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#     eval_mode=True,\n",
    "#     batch_size=32,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3001353</td><td>&quot;Natascha var ikke den første&quot;</td><td>&quot;Politiet frygter nu, at Natasc…</td><td>2023-06-29 06:20:33</td><td>false</td><td>&quot;Sagen om den østriske Natascha…</td><td>2006-08-31 08:06:45</td><td>[3150850]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/krimi/…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9955</td><td>&quot;Negative&quot;</td></tr><tr><td>3003065</td><td>&quot;Kun Star Wars tjente mere&quot;</td><td>&quot;Biografgængerne strømmer ind f…</td><td>2023-06-29 06:20:35</td><td>false</td><td>&quot;Vatikanet har opfordret til at…</td><td>2006-05-21 16:57:00</td><td>[3006712]</td><td>&quot;article_default&quot;</td><td>&quot;https://ekstrabladet.dk/underh…</td><td>[]</td><td>[]</td><td>[&quot;Underholdning&quot;, &quot;Film og tv&quot;, &quot;Økonomi&quot;]</td><td>414</td><td>[433, 434]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.846</td><td>&quot;Positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3001353   ┆ Natascha  ┆ Politiet  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9955    ┆ Negative │\n",
       "│           ┆ var ikke  ┆ frygter   ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ den       ┆ nu, at    ┆ 06:20:33  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ første    ┆ Natasc…   ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3003065   ┆ Kun Star  ┆ Biografgæ ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.846     ┆ Positive │\n",
       "│           ┆ Wars      ┆ ngerne    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tjente    ┆ strømmer  ┆ 06:20:35  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ mere      ┆ ind f…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the\n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "#\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(\n",
    "    df=df_articles, value_col=token_col_title\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: X shape = 2342, y shape = 2342\n",
      "Loaded data: X shape = 2446, y shape = 2446\n",
      "Dataset length requested: 37\n",
      "Dataset length requested: 37\n"
     ]
    }
   ],
   "source": [
    "from models.dataloader import create_nrms_dataloaders\n",
    "\n",
    "\n",
    "train_dataloader, val_dataloader = create_nrms_dataloaders(\n",
    "    train_behaviors=df_train,\n",
    "    val_behaviors=df_validation, \n",
    "    article_dict=article_mapping,\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 14:32:30.303278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731850350.363314    9288 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731850350.380434    9288 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-17 14:32:30.524242: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from models.dataloader import NRMSDataset, DataLoader\n",
    "# import models.dataloader_tensorflow as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset creation...\n",
      "Loaded data: X shape = 2342, y shape = 2342\n",
      "\n",
      "Testing direct indexing...\n",
      "WTF------------------\n",
      "\n",
      "PyTorch Dataloader - Batch 0:\n",
      "Initial batch_X shape: 32\n",
      "Initial batch_y shape: 32\n",
      "Training batch_y shape: torch.Size([32, 5])\n",
      "his_input_title initial shape: torch.Size([32, 10, 1, 1, 30])\n",
      "pred_input_title initial shape: torch.Size([32, 5, 1, 1, 30])\n",
      "\n",
      "Final shapes:\n",
      "his_input_title: torch.Size([32, 10, 1, 30])\n",
      "pred_input_title: torch.Size([32, 5, 1, 30])\n",
      "batch_y: torch.Size([32, 5])\n",
      "\n",
      "Sample values:\n",
      "his_input_title first element: [[16148.0, 1360.0, 4620.0, 92.0, 3366.0, 17.0, 1368.0, 72.0, 122.0, 27882.0, 20356.0, 45887.0, 150065.0, 5.0, 49085.0, 138271.0, 33791.0, 18.0, 1459.0, 128102.0, 47640.0, 109.0, 14384.0, 1015.0, 45331.0, 1042.0, 4620.0, 33791.0, 18.0, 1459.0]]\n",
      "pred_input_title first element: [[18118.0, 449.0, 1272.0, 20928.0, 67.0, 50825.0, 757.0, 11565.0, 139.0, 35988.0, 1953.0, 22.0, 24792.0, 106543.0, 16749.0, 4034.0, 128.0, 48983.0, 18.0, 4444.0, 4.0, 106393.0, 7.0, 10237.0, 60.0, 61745.0, 9.0, 106543.0, 35988.0, 113.0]]\n",
      "batch_y first element: [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "\n",
      "Testing with NRMSDataset...\n",
      "Dataset length requested: 74\n",
      "Dataset length requested: 74\n",
      "Getting first batch...\n",
      "Dataset length requested: 74\n",
      "Dataset length requested: 74\n",
      "WTF------------------\n",
      "\n",
      "PyTorch Dataloader - Batch 36:\n",
      "Initial batch_X shape: 32\n",
      "Initial batch_y shape: 32\n",
      "Training batch_y shape: torch.Size([32, 5])\n",
      "his_input_title initial shape: torch.Size([32, 10, 1, 1, 30])\n",
      "pred_input_title initial shape: torch.Size([32, 5, 1, 1, 30])\n",
      "\n",
      "Final shapes:\n",
      "his_input_title: torch.Size([32, 10, 1, 30])\n",
      "pred_input_title: torch.Size([32, 5, 1, 30])\n",
      "batch_y: torch.Size([32, 5])\n",
      "\n",
      "Sample values:\n",
      "his_input_title first element: [[72542.0, 146288.0, 88032.0, 545.0, 100.0, 242988.0, 4.0, 5101.0, 1926.0, 261.0, 16274.0, 56.0, 35068.0, 43764.0, 4.0, 83499.0, 22.0, 193014.0, 4271.0, 3810.0, 6.0, 190819.0, 4196.0, 6.0, 85939.0, 555.0, 12.0, 36630.0, 7.0, 27808.0]]\n",
      "pred_input_title first element: [[3868.0, 27882.0, 5077.0, 94419.0, 9038.0, 16471.0, 7465.0, 2759.0, 11.0, 149.0, 44.0, 115233.0, 4896.0, 1368.0, 161927.0, 58.0, 128.0, 80632.0, 5465.0, 68413.0, 60.0, 3082.0, 171.0, 57038.0, 29630.0, 78464.0, 102831.0, 24708.0, 4574.0, 33791.0]]\n",
      "batch_y first element: [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "Testing TensorFlow loader:\n",
      "\n",
      "TensorFlow Dataloader - Batch 0:\n",
      "Initial batch_X shape: 32\n",
      "Initial batch_y shape: 32\n",
      "Training batch_y shape: (32, 5)\n",
      "his_input_title initial shape: (32, 10, 1, 30)\n",
      "pred_input_title initial shape: (32, 5, 1, 30)\n",
      "\n",
      "Final shapes:\n",
      "his_input_title: (32, 10, 30)\n",
      "pred_input_title: (32, 5, 30)\n",
      "batch_y: (32, 5)\n",
      "\n",
      "Sample values:\n",
      "his_input_title first element: [16148  1360  4620    92  3366]\n",
      "pred_input_title first element: [18118   449  1272 20928    67]\n",
      "batch_y first element: [0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing dataset creation...\")\n",
    "dataset = NRMSDataset(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    unknown_representation=\"zeros\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "print(\"\\nTesting direct indexing...\")\n",
    "first_item = dataset[0]\n",
    "\n",
    "print(\"\\nTesting with NRMSDataset...\")\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=None,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "# print(\"Getting first batch...\")\n",
    "# first_batch = next(iter(loader))\n",
    "\n",
    "# print(\"\\nTesting TensorFlow loader:\")\n",
    "# tf_loader = df.NRMSDataLoader(\n",
    "#     behaviors=df_train,\n",
    "#     article_dict=article_mapping,\n",
    "#     history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "#     unknown_representation=\"zeros\",\n",
    "#     eval_mode=False,\n",
    "# )\n",
    "# batch = tf_loader[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Debugging initial batch shapes:\n",
      "\n",
      "Batch 0:\n",
      "Number of inputs: 2\n",
      "Input 0 shape: torch.Size([64, 1, 10, 30])\n",
      "Input 1 shape: torch.Size([64, 1, 5, 30])\n",
      "Targets shape: torch.Size([64, 1, 5])\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/37 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in batch 0:\n",
      "Input shapes when error occurred:\n",
      "Input 0 shape: torch.Size([64, 1, 10, 30])\n",
      "Input 1 shape: torch.Size([64, 1, 5, 30])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 175\u001b[0m\n\u001b[1;32m    168\u001b[0m model \u001b[38;5;241m=\u001b[39m NRMSModel(\n\u001b[1;32m    169\u001b[0m     hparams\u001b[38;5;241m=\u001b[39mhparams_nrms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m,\n\u001b[1;32m    170\u001b[0m     word2vec_embedding\u001b[38;5;241m=\u001b[39mword2vec_embedding,\n\u001b[1;32m    171\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nrms_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 117\u001b[0m, in \u001b[0;36mtrain_nrms_model\u001b[0;34m(model, train_dataloader, val_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, inp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inputs):\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minp\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    119\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[1;32m    120\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss/Train\u001b[39m\u001b[38;5;124m'\u001b[39m, avg_train_loss, epoch)\n",
      "Cell \u001b[0;32mIn[37], line 100\u001b[0m, in \u001b[0;36mtrain_nrms_model\u001b[0;34m(model, train_dataloader, val_dataloader, num_epochs)\u001b[0m\n\u001b[1;32m     98\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024/models_pytorch/nrms.py:204\u001b[0m, in \u001b[0;36mNRMSModel.forward\u001b[0;34m(self, his_input_title, pred_input_title)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, his_input_title, pred_input_title):\n\u001b[1;32m    194\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m    Forward pass of the NRMSModel.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m        torch.Tensor: Output probabilities of shape (batch_size, npratio_plus_1).\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 204\u001b[0m     user_present \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muserencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhis_input_title\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, output_dim)\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     batch_size, npratio_plus_1, title_size \u001b[38;5;241m=\u001b[39m pred_input_title\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    206\u001b[0m     device \u001b[38;5;241m=\u001b[39m pred_input_title\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Study/2_second/deep learning/Deeplearning-RecSys-Challenge-2024/models_pytorch/nrms.py:172\u001b[0m, in \u001b[0;36mNRMSModel._build_userencoder.<locals>.UserEncoder.forward\u001b[0;34m(self, his_input_title)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, his_input_title):\n\u001b[1;32m    163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    Forward pass of the UserEncoder.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m        torch.Tensor: Aggregated user representation tensor of shape (batch_size, attention_hidden_dim).\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     batch_size, history_size, title_size \u001b[38;5;241m=\u001b[39m his_input_title\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    173\u001b[0m     device \u001b[38;5;241m=\u001b[39m his_input_title\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Encode each historical title\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = os.path.join(\"downloads\", \"runs\", MODEL_NAME)\n",
    "MODEL_WEIGHTS = os.path.join(\"downloads\", \"data\", \"state_dict\", MODEL_NAME, \"weights.pth\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(MODEL_WEIGHTS), exist_ok=True)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=2, verbose=True, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            if self.verbose:\n",
    "                print(f\"Initial validation loss: {val_loss:.6f}\")\n",
    "        elif val_loss > self.best_loss + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss did not improve from {self.best_loss:.6f}. Counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            if self.verbose:\n",
    "                print(f\"Validation loss improved from {self.best_loss:.6f} to {val_loss:.6f}\")\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "class ModelCheckpoint:\n",
    "    def __init__(self, filepath, verbose=True):\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "\n",
    "    def save_checkpoint(self, model):\n",
    "        torch.save(model.state_dict(), self.filepath)\n",
    "        if self.verbose:\n",
    "            print(f\"Model checkpoint saved: {self.filepath}\")\n",
    "\n",
    "def train_nrms_model(model, train_dataloader, val_dataloader, num_epochs=100):\n",
    "    # Setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Initialize callbacks\n",
    "    writer = SummaryWriter(log_dir=LOG_DIR)\n",
    "    early_stopping = EarlyStopping(patience=2)\n",
    "    model_checkpoint = ModelCheckpoint(filepath=MODEL_WEIGHTS)\n",
    "\n",
    "    # Debug first batch shapes\n",
    "    print(\"\\nDebugging initial batch shapes:\")\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_dataloader):\n",
    "        print(f\"\\nBatch {batch_idx}:\")\n",
    "        print(f\"Number of inputs: {len(inputs)}\")\n",
    "        for i, inp in enumerate(inputs):\n",
    "            print(f\"Input {i} shape: {inp.shape}\")\n",
    "        print(f\"Targets shape: {targets.shape}\")\n",
    "        break\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"\\nEpoch {epoch}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_bar = tqdm(train_dataloader, desc=\"Training\")\n",
    "        \n",
    "        for batch_idx, (inputs, targets) in enumerate(train_bar):\n",
    "            # Move data to device\n",
    "            inputs = [inp.to(device) for inp in inputs]\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            try:\n",
    "                outputs = model(*inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Update metrics\n",
    "                train_loss += loss.item()\n",
    "                avg_train_loss = train_loss / (batch_idx + 1)\n",
    "                train_bar.set_postfix(loss=f\"{avg_train_loss:.4f}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\nError in batch {batch_idx}:\")\n",
    "                print(f\"Input shapes when error occurred:\")\n",
    "                for i, inp in enumerate(inputs):\n",
    "                    print(f\"Input {i} shape: {inp.shape}\")\n",
    "                raise e\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_dataloader)\n",
    "        writer.add_scalar('Loss/Train', avg_train_loss, epoch)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_bar = tqdm(val_dataloader, desc=\"Validation\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_bar:\n",
    "                # Move data to device\n",
    "                inputs = [inp.to(device) for inp in inputs]\n",
    "                targets = targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(*inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                \n",
    "                # Update metrics\n",
    "                val_loss += loss.item()\n",
    "                avg_val_loss = val_loss / len(val_dataloader)\n",
    "                val_bar.set_postfix(loss=f\"{avg_val_loss:.4f}\")\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_dataloader)\n",
    "        writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch} summary:\")\n",
    "        print(f\"Training Loss: {avg_train_loss:.6f}\")\n",
    "        print(f\"Validation Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "        # Check for improvement\n",
    "        model_checkpoint(model, avg_val_loss)\n",
    "        early_stopping(avg_val_loss)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(MODEL_WEIGHTS))\n",
    "    print(f\"Loaded best model weights from {MODEL_WEIGHTS}\")\n",
    "    writer.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Use the training function\n",
    "# Initialize your model and data\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms.__dict__,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model = train_nrms_model(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_validation = model.predict(val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the predictions to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = add_prediction_scores(df_validation, pred_validation.tolist()).pipe(\n",
    "    add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    ")\n",
    "df_validation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricEvaluator(\n",
    "    labels=df_validation[\"labels\"].to_list(),\n",
    "    predictions=df_validation[\"scores\"].to_list(),\n",
    "    metric_functions=[AucScore(), MrrScore(), NdcgScore(k=5), NdcgScore(k=10)],\n",
    ")\n",
    "metrics.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://github.com/ebanalyse/ebnerd-benchmark/blob/main/examples/00_quick_start/nrms_ebnerd.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
